import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io, urllib.parse, re, json
from PIL import Image

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„Ù…ØªÙ‚Ø¯Ù…Ø© V13.0 - Ù†Ø³Ø®Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙˆØ«Ù‚
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ Ù„Ù„Ø¨Ø­Ø« Ø§Ù„Ø°ÙƒÙŠ V13.0", layout="wide", page_icon="ğŸ”")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)
else:
    st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯!")
    st.stop()

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø± ---
def draw_image_logic(query):
    clean_prompt = re.sub(r'[^\w\s]', '', query)[:60]
    encoded = urllib.parse.quote(clean_prompt)
    return f"https://pollinations.ai/p/{encoded}?width=1024&height=1024&seed=130"

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø¹ Ù…ÙŠØ²Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª (Google Search) ---
def generate_search_response(prompt, selected_model, persona_info):
    # Ø®Ø±ÙŠØ·Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª
    model_map = {
        "Gemini 2.5 Flash (Ø§Ù„Ø£Ø³Ø±Ø¹)": "gemini-2.5-flash-exp",
        "Gemini 3 Pro (Ø§Ù„Ø£Ø°ÙƒÙ‰)": "gemini-3-pro-preview",
        "Gemma 3 27B (Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚)": "gemma-3-27b-it"
    }
    
    model_id = model_map.get(selected_model, "gemini-2.5-flash-exp")
    
    try:
        # ØªÙØ¹ÙŠÙ„ Ø£Ø¯Ø§Ø© Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø¬ÙˆØ¬Ù„ (Google Search Tool)
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…ÙŠØ²Ø© Ø§Ù„Ø¨Ø­Ø« Ù…ØªØ§Ø­Ø© Ø¨Ø´ÙƒÙ„ Ø£Ø³Ø§Ø³ÙŠ ÙÙŠ Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Gemini
        model = genai.GenerativeModel(
            model_name=model_id,
            tools=[{"google_search_retrieval": {}}] # Ù‡Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ù‡Ùˆ Ø³Ø± Ù…ÙŠØ²Ø© Perplexity
        )
        
        full_query = f"Ø¨ØµÙØªÙƒ {persona_info}ØŒ Ø§Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØ£Ø¬Ø¨ Ø¨Ø¯Ù‚Ø©: {prompt}"
        response = model.generate_content(full_query)
        
        return response.text, model_id
    except Exception as e:
        # ÙÙŠ Ø­Ø§Ù„ ÙØ´Ù„ Ø§Ù„Ø¨Ø­Ø« Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ØŒ Ù†Ø¹ÙˆØ¯ Ù„Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¹Ø§Ø¯ÙŠ
        model = genai.GenerativeModel("gemini-1.5-flash")
        response = model.generate_content(prompt)
        return response.text, "Fallback-Flash"

# 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² ØªØ­ÙƒÙ… Ù…ØµØ¹Ø¨")
    selected_engine = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:", [
        "Gemini 2.5 Flash (Ø§Ù„Ø£Ø³Ø±Ø¹)",
        "Gemini 3 Pro (Ø§Ù„Ø£Ø°ÙƒÙ‰)",
        "Gemma 3 27B (Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚)"
    ])
    
    persona = st.selectbox("ğŸ‘¤ Ø§Ù„ØªØ®ØµØµ:", ["Ø¨Ø§Ø­Ø« Ø°ÙƒÙŠ ÙˆÙ…ÙˆØ«Ù‚", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ù…Ø­ØªØ±Ù", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø© Ubuntu", "Ù…ØµÙ…Ù… ØµÙˆØ±"])
    
    persona_instr = {
        "Ø¨Ø§Ø­Ø« Ø°ÙƒÙŠ ÙˆÙ…ÙˆØ«Ù‚": "Ø£Ù†Øª Ù…Ø­Ø±Ùƒ Ø¨Ø­Ø« Ù…ØªØ·ÙˆØ±. Ù‚Ø¯Ù… Ø¥Ø¬Ø§Ø¨Ø§Øª Ù…ÙˆØ«Ù‚Ø© Ø¨Ù…ØµØ§Ø¯Ø± ÙˆØ±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª.",
        "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ù…Ø­ØªØ±Ù": "Ø£Ù†Øª Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ø®Ø¨ÙŠØ±. ØµØ­Ø­ ÙˆØ§Ù†Ø·Ù‚ Ø¨ÙˆØ¶ÙˆØ­.",
        "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø© Ubuntu": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù„ÙŠÙ†ÙƒØ³ Ù„Ø¬Ù‡Ø§Ø² HP.",
        "Ù…ØµÙ…Ù… ØµÙˆØ±": "Ø£Ù†Øª ÙÙ†Ø§Ù† Ø±Ù‚Ù…ÙŠ."
    }

    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    uploaded_image = st.file_uploader("ØªØ­Ù„ÙŠÙ„ ØµÙˆØ±Ø©:", type=['jpg', 'png', 'jpeg'])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []; st.rerun()

# 3. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "img" in msg and msg["img"]: st.image(msg["img"])

# 4. Ø§Ù„ØªÙ†ÙÙŠØ°
user_input = st.chat_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø£Ø®Ø¨Ø§Ø± Ø§Ù„ÙŠÙˆÙ… Ø£Ùˆ Ø§Ø¨Ø­Ø« Ø¹Ù† Ù…Ø¹Ù„ÙˆÙ…Ø© Ù…ÙˆØ«Ù‚Ø©...")

if user_input or (audio_record and audio_record['bytes']) or uploaded_image:
    query = user_input if user_input else "Ø­Ù„Ù„ Ø§Ù„Ù…Ø±ÙÙ‚"
    with st.chat_message("user"): st.markdown(query)
    
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª ÙˆØªØ¬Ù…ÙŠØ¹ Ø§Ù„Ù…ØµØ§Ø¯Ø±..."):
            # Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ø¹ Ø§Ù„Ø¨Ø­Ø«
            ai_text, m_used = generate_search_response(query, selected_engine, persona_instr[persona])
            
            if ai_text:
                # Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø³Ù…
                img_url = None
                if any(w in query for w in ["Ø§Ø±Ø³Ù…", "ØµÙˆØ±Ø©"]) or persona == "Ù…ØµÙ…Ù… ØµÙˆØ±":
                    img_url = draw_image_logic(query)
                    st.image(img_url)
                
                st.markdown(ai_text)
                st.caption(f"ğŸ“ Ù…ØµØ¯Ø± Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª: Ø¨Ø­Ø« Google Ù…Ø¨Ø§Ø´Ø± Ø¹Ø¨Ø± {m_used}")
                
                # Ù…ÙŠØ²Ø© Ø§Ù„Ù†Ø·Ù‚ (Ø­ØªÙ‰ 2000 Ø­Ø±Ù)
                try:
                    clean_txt = re.sub(r'[^\w\s.,!?]', '', ai_text)[:2000]
                    lang = 'en' if re.search(r'[a-zA-Z]', clean_txt) else 'ar'
                    tts = gTTS(text=clean_txt, lang=lang)
                    audio_io = io.BytesIO()
                    tts.write_to_fp(audio_io)
                    st.audio(audio_io)
                except: pass
                
                st.session_state.messages.append({"role": "assistant", "content": ai_text, "img": img_url})
