import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from streamlit_mic_recorder import mic_recorder  # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
from gtts import gTTS
import io

# 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©", layout="wide")
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

if not api_key:
    st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© GEMINI_API_KEY")
    st.stop()

genai.configure(api_key=api_key)

# 2. ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØª (Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ)
def speak(text):
    try:
        clean_text = text.replace('*', '').replace('#', '')
        tts = gTTS(text=clean_text, lang='ar')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

# 3. ÙˆØ¸ÙŠÙØ© Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø°ÙƒÙŠ
def draw_smart_image(user_prompt):
    try:
        # ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ Ø£ÙˆÙ„Ø§Ù‹
        desc_model = genai.GenerativeModel("gemini-3-flash-preview")
        enhanced_prompt = desc_model.generate_content(f"Enhance this for Imagen 3: {user_prompt}").text
        # Ø§Ù„Ø±Ø³Ù…
        paint_model = genai.GenerativeModel("imagen-3.0-generate-001")
        response = paint_model.generate_content(enhanced_prompt)
        return response.candidates[0].content.parts[0].inline_data.data
    except Exception as e: return f"error: {e}"

# 4. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ù‡Ù†Ø§ ØªØ¸Ù‡Ø± Ø§Ù„Ù†ÙˆØ§ÙØ° Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©)
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ø·")
    mode = st.radio("Ø§Ø®ØªØ± Ø§Ù„ÙˆØ¶Ø¹:", ["Ø¯Ø±Ø¯Ø´Ø© ÙˆØ±Ø¤ÙŠØ© ğŸ’¬", "Ø±Ø³Ù… Ø§Ø­ØªØ±Ø§ÙÙŠ ğŸ¨"])
    
    st.divider()
    
    # Ù†Ø§ÙØ°Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Ø§Ù„Ù…ØºØ±ÙŠÙÙˆÙ†)
    st.subheader("ğŸ™ï¸ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ")
    audio_record = mic_recorder(
        start_prompt="Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ ğŸ¤",
        stop_prompt="Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª ğŸ“¤",
        key='recorder'
    )
    
    st.divider()
    
    # Ù†Ø§ÙØ°Ø© Ø§Ù„Ø±Ø¤ÙŠØ© (Vision)
    st.subheader("ğŸ–¼ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø©:", type=["jpg", "png"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# 5. Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¹Ù…Ù„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title("âš¡ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ø°ÙƒÙŠ")

if mode == "Ø±Ø³Ù… Ø§Ø­ØªØ±Ø§ÙÙŠ ğŸ¨":
    prompt = st.text_input("Ù…Ø§Ø°Ø§ ØªØ±ÙŠØ¯Ù†ÙŠ Ø£Ù† Ø£Ø±Ø³Ù…ØŸ")
    if st.button("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù„ÙˆØ­Ø©"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…..."):
            result = draw_smart_image(prompt)
            if isinstance(result, str) and "error" in result:
                st.error("ÙØ´Ù„ Ø§Ù„Ø±Ø³Ù…. ØªØ£ÙƒØ¯ Ù…Ù† VPN Ø£Ù…Ø±ÙŠÙƒÙŠ.")
            else: st.image(result)

else:
    if "messages" not in st.session_state: st.session_state.messages = []
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    user_input = st.chat_input("Ø§ÙƒØªØ¨ Ø±Ø³Ø§Ù„ØªÙƒ Ù‡Ù†Ø§...")
    
    # Ø§Ù„ØªÙ‚Ø§Ø· Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª Ø§Ù„ØµÙˆØªÙŠØ©
    current_audio = audio_record['bytes'] if audio_record else None

    if user_input or current_audio or uploaded_file:
        query = user_input if user_input else ("Ø­Ù„Ù„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø±ÙÙ‚" if current_audio else "Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø©")
        
        with st.chat_message("user"):
            st.markdown(query)
            if uploaded_file: st.image(uploaded_file, width=300)
            if current_audio: st.audio(current_audio)

        with st.chat_message("assistant"):
            try:
                model = genai.GenerativeModel("gemini-3-flash-preview")
                content = [query]
                if uploaded_file: content.append(Image.open(uploaded_file))
                if current_audio: content.append({"mime_type": "audio/wav", "data": current_audio})
                
                response = model.generate_content(content)
                st.markdown(response.text)
                
                # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ
                audio_fp = speak(response.text)
                if audio_fp: st.audio(audio_fp, autoplay=True)
                
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")
