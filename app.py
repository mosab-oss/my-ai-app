import streamlit as st
import google.generativeai as genai
import io
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø±Ø¨Ø· ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.12.2", layout="wide")

api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

if "messages" not in st.session_state:
    st.session_state.messages = []

# --- 2. Ø¯Ø§Ù„Ø© Ø¬Ù„Ø¨ Ø§Ù„Ø³ÙŠØ§Ù‚ (Ù„Ø£Ù†Ùƒ Ø·Ù„Ø¨Øª Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø³ÙŠØ§Ù‚) ---
def get_history():
    return [{"role": "user" if m["role"] == "user" else "model", 
             "parts": [m["content"]]} for m in st.session_state.messages]

# --- 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.title("ğŸŒ ÙˆØ¶Ø¹ Ø§Ù„Ø¨Ø« Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙŠ")
    web_search_on = st.toggle("ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª (Live)", value=True)
    engine_choice = st.selectbox("Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["gemini-2.0-flash", "gemini-1.5-flash"])
    persona = st.selectbox("Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ†", "Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠØ©", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬"])
    
    st.divider()
    audio_record = mic_recorder(start_prompt="ğŸ¤ ØªÙƒÙ„Ù… Ø§Ù„Ø¢Ù†", stop_prompt="âœ… Ø¥Ø±Ø³Ø§Ù„", just_once=True)

# --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

prompt = st.chat_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø£ÙŠ Ø´ÙŠØ¡ Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª...")

if prompt or audio_record:
    user_txt = prompt if prompt else "ğŸ¤ [Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©]"
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"): st.markdown(user_txt)

    with st.chat_message("assistant"):
        res_placeholder = st.empty()
        full_res = ""
        
        # ØªÙØ¹ÙŠÙ„ Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø« Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®ÙŠØ§Ø± Ù…ÙØ¹Ù„Ø§Ù‹
        tools = [{"google_search_retrieval": {}}] if web_search_on else []
        
        try:
            model = genai.GenerativeModel(
                model_name=engine_choice,
                tools=tools # Ù‡Ù†Ø§ Ø¯Ù…Ø¬Ù†Ø§ "Ø§Ù„Ø¨Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± Ù…Ù† Ø§Ù„Ø¥Ù†ØªØ±Ù†Øª"
            )
            
            # Ø¨Ø¯Ø¡ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚ (History)
            chat = model.start_chat(history=get_history())
            
            # Ø§Ù„Ø·Ù„Ø¨ Ù…Ø¹ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø´Ø®ØµÙŠØ©
            full_prompt = f"Ø¨ØµÙØªÙƒ {persona}ØŒ Ø£Ø¬Ø¨ Ø¨Ø°ÙƒØ§Ø¡: {user_txt}"
            
            # Ø§Ù„Ø¨Ø« (Streaming)
            response = chat.send_message(full_prompt, stream=True)
            
            for chunk in response:
                if chunk.text:
                    full_res += chunk.text
                    res_placeholder.markdown(full_res + "â–Œ")
            
            res_placeholder.markdown(full_res)
            
            # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„Ø³ÙŠØ§Ù‚
            st.session_state.messages.append({"role": "assistant", "content": full_res})
            
            # ØµÙˆØª Ø§Ø®ØªÙŠØ§Ø±ÙŠ
            tts = gTTS(text=full_res[:200], lang='ar')
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            st.audio(audio_fp)

        except Exception as e:
            st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
