import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙØªØ§Ø­ ÙˆØ§Ù„Ø¨ÙŠØ¦Ø©
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# 2. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø°ÙƒÙŠØ© (ØªÙ†ØªÙ‚Ù„ Ø¨ÙŠÙ† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹)
def generate_content_with_fallback(contents):
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø­Ø³Ø¨ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©
    models_to_try = ["gemini-3-flash", "gemini-2.0-flash", "gemini-1.5-flash"]
    
    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(contents)
            return response.text, model_name  # Ù†Ø¹ÙŠØ¯ Ø§Ù„Ù†Øµ ÙˆØ§Ø³Ù… Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø°ÙŠ Ù†Ø¬Ø­
        except Exception as e:
            # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ø®Ø·Ø£ Ù‡Ùˆ Ø§Ù†ØªÙ‡Ø§Ø¡ Ø§Ù„Ø­ØµØ© (429)ØŒ Ù†Ø¬Ø±Ø¨ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ
            if "429" in str(e) or "quota" in str(e).lower():
                continue 
            else:
                return f"Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {e}", None
    
    return "Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø§Ù†ØªÙ‡Øª Ø­ØµØ© Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø© Ù„Ù„ÙŠÙˆÙ….", None

# 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¨Ø³Ø·Ø©
st.title("ğŸš€ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ø°ÙƒÙŠ (Ø§Ù„Ù…Ø¶Ø§Ø¯ Ù„Ù„ØªÙˆÙ‚Ù)")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
user_input = st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡...")

if user_input:
    st.session_state.messages.append({"role": "user", "content": user_input})
    with st.chat_message("user"):
        st.markdown(user_input)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± (Ù†Ø¨Ø­Ø« Ø¹Ù† Ù…ÙˆØ¯ÙŠÙ„ Ù…ØªØ§Ø­)..."):
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ù…Ø¹ Ø®Ø§ØµÙŠØ© Ø§Ù„Ù€ Fallback
            answer, successful_model = generate_content_with_fallback([user_input])
            
            if successful_model:
                st.markdown(answer)
                st.caption(f"ØªÙ…Øª Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ù…Ø­Ø±Ùƒ: {successful_model}")
                st.session_state.messages.append({"role": "assistant", "content": answer})
            else:
                st.error(answer)
