import streamlit as st
import os
import time
import io
import base64
from google import genai
from google.genai import types
from openai import OpenAI
from PIL import Image
import arabic_reshaper
from bidi.algorithm import get_display
import fitz  # Ù…ÙƒØªØ¨Ø© PyMuPDF Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PDF Ø¨Ø§Ø­ØªØ±Ø§ÙÙŠØ©

# --- [1] Ø£Ø³Ø·ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ÙˆÙ…Ø¬Ù„Ø³ Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡ Ø§Ù„ÙƒØ§Ù…Ù„ ---
model_map = {
    "Gemini 3 Flash": "gemini-3-flash-preview",
    "Gemini 3 Pro": "gemini-3-pro-preview",
    "Gemini 2.5 Pro": "gemini-2.5-pro",
    "Gemini 1.5 Flash": "gemini-flash-latest"
}

expert_map = {
    "ğŸŒ Ø®Ø¨ÙŠØ± Ø¹Ø§Ù…": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø¹Ø§Ù… Ø°ÙƒÙŠØŒ ØªØ¬ÙŠØ¨ Ø¨Ø¯Ù‚Ø© ÙˆÙˆØ¶ÙˆØ­ ÙˆÙ„Ø¨Ø§Ù‚Ø©. ØªØ°ÙƒØ± Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­ÙˆØ§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚.",
    "ğŸ’» Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§ØªØŒ ØªØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØ·ÙˆÙŠØ± Ø§Ù„Ø£ÙƒÙˆØ§Ø¯.",
    "ğŸ“ˆ Ù…Ø­Ù„Ù„ Ø£Ø³ÙˆØ§Ù‚": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù…Ø§Ù„ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ Ù„Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ ÙˆØ§Ù„Ø¨ÙˆØ±ØµØ© ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§.",
    "ğŸ“§ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø±Ø§Ø³Ù„Ø§Øª": "Ø£Ù†Øª Ø³ÙƒØ±ØªÙŠØ± ØªÙ†ÙÙŠØ°ÙŠØŒ ØµØº Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆØ±Ø¯ÙˆØ¯ Ø¯Ø¨Ù„ÙˆÙ…Ø§Ø³ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª.",
    "ğŸ“Š Ù…Ø­Ù„Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠ": "Ø£Ù†Øª Ø¨Ø±ÙˆÙÙŠØ³ÙˆØ± Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø­Ù„Ù„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ÙˆÙ‚Ø¯Ù… Ø±Ø¤ÙŠØ© Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø©.",
    "âœï¸ Ø®Ø¨ÙŠØ± Ù…Ø­ØªÙˆÙ‰": "Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªØ±ÙØŒ Ø­ÙˆÙ„ Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„Ù…Ø³ÙˆØ¯Ø§Øª Ø¥Ù„Ù‰ ØªÙ‚Ø§Ø±ÙŠØ± ÙˆÙ…Ù‚Ø§Ù„Ø§Øª Ù…ØªÙƒØ§Ù…Ù„Ø©.",
    "ğŸ“š Ø®Ø¨ÙŠØ± Ù„ØºÙˆÙŠ": "Ø£Ù†Øª Ø¨Ø±ÙˆÙÙŠØ³ÙˆØ± Ù„ØºÙˆÙŠØŒ Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø­Ùˆ ÙˆØ§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù„ØºÙˆÙŠ.",
    "ğŸ›¡ï¸ Ø®Ø¨ÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ø¬ÙŠÙˆØ³ÙŠØ§Ø³ÙŠ ÙˆØ¹Ø³ÙƒØ±ÙŠØŒ Ø­Ù„Ù„ Ø§Ù„Ù…ÙˆØ§Ù‚Ù Ù…Ù† Ù…Ù†Ø¸ÙˆØ± Ù‚ÙŠØ§Ø¯ÙŠ.",
    "âš–ï¸ Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠØŒ Ù…Ø±Ø§Ø¬Ø¹ Ù„Ù„Ø¹Ù‚ÙˆØ¯ ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø±Ø³Ù…ÙŠØ© ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„."
}

# Ø¯Ø§Ù„Ø© ØªØµØ­ÙŠØ­ Ø¹Ø±Ø¶ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
def fix_ar(text):
    try:
        reshaped_text = arabic_reshaper.reshape(text)
        return get_display(reshaped_text)
    except:
        return text

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„ÙØ§Øª PDF
def extract_pdf_content(file_bytes):
    doc = fitz.open(stream=file_bytes, filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text()
    return text

if "request_count" not in st.session_state: st.session_state.request_count = 0
if "messages" not in st.session_state: st.session_state.messages = []

# --- [2] Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ (Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ù…Ù„ÙØ§Øª) ---
def get_gemini_client():
    try:
        return genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
    except:
        return None

def run_engine(prompt_data, is_voice=False, image_data=None, pdf_text=None):
    target_model = model_map.get(selected_model, "gemini-flash-latest")
    expert_instruction = expert_map.get(selected_expert, "Ø®Ø¨ÙŠØ± Ø¹Ø§Ù…")

    try:
        if provider == "Google Gemini":
            client = get_gemini_client()
            if not client: return "ğŸš¨ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…."

            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© (Chat History) Ù„ØªØ°ÙƒØ± Ø§Ù„Ø³ÙŠØ§Ù‚
            history = []
            for msg in st.session_state.messages[-6:]: # ØªØ°ÙƒØ± Ø¢Ø®Ø± 6 Ø±Ø³Ø§Ø¦Ù„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø³Ø±Ø¹Ø©
                role = "user" if msg["role"] == "user" else "model"
                history.append(types.Content(role=role, parts=[types.Part.from_text(text=msg["content"])]))

            config = types.GenerateContentConfig(
                system_instruction=expert_instruction,
                tools=[types.Tool(google_search=types.GoogleSearch())] if live_search else None,
                temperature=0.7
            )

            content_list = []
            
            # 1. Ø¥Ø¶Ø§ÙØ© Ù†Øµ Ø§Ù„Ù€ PDF Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯
            if pdf_text:
                content_list.append(f"Ù…Ø­ØªÙˆÙ‰ Ù…Ø³ØªÙ†Ø¯ PDF Ø§Ù„Ù…Ø±ÙÙ‚:\n{pdf_text}\n\nØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:")

            # 2. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙˆÙØ¬Ø¯Øª
            if image_data and not pdf_text: # Gemini ÙŠØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„ØµÙˆØ± ÙˆØ§Ù„Ù€ PDF Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©
                content_list.append(Image.open(image_data))
            
            # 3. Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØª Ø£Ùˆ Ø§Ù„Ù†Øµ
            if is_voice:
                content_list.append(types.Part.from_bytes(data=prompt_data['bytes'], mime_type="audio/wav"))
            else:
                content_list.append(prompt_data)

            # Ø¥Ù†Ø´Ø§Ø¡ Ø¬Ù„Ø³Ø© Ø¯Ø±Ø¯Ø´Ø© Ø¨Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            chat = client.chats.create(model=target_model, config=config, history=history)
            response = chat.send_message(content_list)
            
            st.session_state.request_count += 1 
            return response.text

        elif provider == "DeepSeek AI":
            # Ù…Ù„Ø§Ø­Ø¸Ø©: DeepSeek Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„Ø§ ÙŠØ¯Ø¹Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ Ø£Ùˆ Ø§Ù„ØµÙˆØª Ø¨Ù†ÙØ³ Ø·Ø±ÙŠÙ‚Ø© Gemini ÙÙŠ Ù‡Ø°Ø§ Ø§Ù„ÙƒÙˆØ¯
            client = OpenAI(api_key=st.secrets.get("DEEPSEEK_API_KEY"), base_url="https://api.deepseek.com")
            
            # Ø¨Ù†Ø§Ø¡ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ù€ DeepSeek
            ds_messages = [{"role": "system", "content": expert_instruction}]
            for msg in st.session_state.messages[-5:]:
                ds_messages.append({"role": msg["role"], "content": msg["content"]})
            ds_messages.append({"role": "user", "content": str(prompt_data)})

            response = client.chat.completions.create(
                model="deepseek-chat",
                messages=ds_messages
            )
            st.session_state.request_count += 1
            return response.choices[0].message.content

    except Exception as e:
        if "429" in str(e):
            st.warning("ğŸ”„ Ù†Ø¸Ø§Ù… Ø§Ù„ØªÙ‡Ø¯Ø¦Ø©: Ø§Ù†ØªØ¸Ø± 15 Ø«Ø§Ù†ÙŠØ©...")
            time.sleep(15)
            return "âš ï¸ ÙŠØ¨Ø¯Ùˆ Ø£Ù† Ø§Ù„Ø¶ØºØ· ÙƒØ¨ÙŠØ± Ø­Ø§Ù„ÙŠØ§Ù‹ØŒ Ø£Ø¹Ø¯ Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø£Ù…Ø± Ù…Ù† ÙØ¶Ù„Ùƒ."
        return f"âŒ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}"

# --- [3] ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ---
st.set_page_config(page_title="Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ© Ø§Ù„ØªØ­Ø§Ù„Ù 2026", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #0e1117; color: #ffffff !important; direction: rtl; text-align: right; }
    .stChatMessage { background-color: #262730 !important; border-right: 5px solid #007bff !important; border-radius: 15px !important; color: #ffffff !important; margin-bottom: 10px; }
    .stMarkdown p, .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 { color: #ffffff !important; }
    .stDownloadButton button { background-color: #155724 !important; color: #d4edda !important; border: 1px solid #c3e6cb !important; font-weight: bold !important; }
    </style>
    """, unsafe_allow_html=True) 

with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©")
    st.progress(min(st.session_state.request_count / 50, 1.0))
    st.caption(f"Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {st.session_state.request_count} / 50")
    
    st.divider()
    provider = st.radio("Ø§Ù„Ù…Ø²ÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ:", ["Google Gemini", "DeepSeek AI"])
    selected_model = st.selectbox("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:", list(model_map.keys()), index=0)
    selected_expert = st.selectbox("Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ:", list(expert_map.keys()))
    
    st.divider()
    live_search = st.toggle("Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ ğŸ“¡", value=True)
    uploaded_file = st.file_uploader("ğŸ“¦ Ø±ÙØ¹ (PNG, JPG, PDF)", type=['png', 'jpg', 'jpeg', 'pdf'])
    
    if st.button("ğŸ—‘ï¸ ØªØ·Ù‡ÙŠØ± Ø§Ù„Ø³Ø¬Ù„"):
        st.session_state.messages = []
        st.rerun()

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

# --- [4] Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø°ÙƒÙŠØ© ---
from streamlit_mic_recorder import mic_recorder
col_mic, col_txt = st.columns([1, 10])

with col_mic:
    audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="ğŸ“¤", key='unified_mic_v7')

with col_txt:
    text_input = st.chat_input("Ø£ØµØ¯Ø± Ø£ÙˆØ§Ù…Ø±Ùƒ Ù‡Ù†Ø§ ÙŠØ§ Ù‚Ø§Ø¦Ø¯...")

input_val = None
voice_flag = False

if audio:
    input_val, voice_flag = audio, True
elif text_input:
    input_val = text_input

if input_val:
    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙ‚Ø© (PDF)
    pdf_text = None
    if uploaded_file and uploaded_file.type == "application/pdf":
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø³Ø­ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¶ÙˆØ¦ÙŠØ§Ù‹..."):
            pdf_text = extract_pdf_content(uploaded_file.read())

    label = "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ]" if voice_flag else input_val
    st.session_state.messages.append({"role": "user", "content": label})
    
    with st.chat_message("user"):
        st.markdown(label)
        if uploaded_file and uploaded_file.type != "application/pdf": 
            st.image(uploaded_file, width=300)
        elif pdf_text:
            st.info("ğŸ“„ ØªÙ… Ø¥Ø±ÙØ§Ù‚ Ù…Ø³ØªÙ†Ø¯ PDF ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡.")

    with st.chat_message("assistant"):
        with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø© {selected_expert}..."):
            res = run_engine(input_val, is_voice=voice_flag, image_data=uploaded_file, pdf_text=pdf_text)
            st.markdown(res)
            st.session_state.messages.append({"role": "assistant", "content": res})
            st.download_button("ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ", res, file_name="alliance_empire_report.txt")
