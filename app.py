import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, time
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 
from PIL import Image

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø³Ù…Ø§Øª ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.39.0", layout="wide", page_icon="ğŸ›¡ï¸")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; background-color: #0e1117; color: white; }
    [data-testid="stSidebar"] { background-color: #000c18; border-left: 2px solid #00d4ff; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: monospace; }
    .status-badge { background-color: #1a1a1a; color: #00d4ff; border: 1px solid #00d4ff; padding: 2px 10px; border-radius: 20px; font-size: 12px; }
    </style>
    """, unsafe_allow_html=True)

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø³Ø±ÙŠØ©
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY")
KIMI_KEY = st.secrets.get("KIMI_API_KEY")
ERNIE_KEY = st.secrets.get("ERNIE_API_KEY")

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ø·ÙˆØ± (Ø§Ù„Ø­ÙØ¸ Ø§Ù„Ø¥Ø¬Ø¨Ø§Ø±ÙŠ v16.39) ---
def run_execution_logic(text):
    clean_txt = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† ÙƒÙˆØ¯ Ø¨Ø§ÙŠØ«ÙˆÙ† Ø¨ÙŠÙ† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ø§Ù„Ù‚ÙŠØ§Ø³ÙŠØ©
    code_blocks = re.findall(r'```python(.*?)```', text, flags=re.DOTALL)
    
    exec_out = ""
    if code_blocks:
        for i, code in enumerate(code_blocks):
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ù…Ù„Ù Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ø³Ù… Ø§ÙØªØ±Ø§Ø¶ÙŠ
            name_match = re.search(r'([\w\.-]+\.py)', text)
            fname = name_match.group(1) if name_match else f"auto_script_{i}.py"
            
            try:
                # Ø¥Ø¬Ø¨Ø§Ø± Ø§Ù„Ù†Ø¸Ø§Ù… Ø¹Ù„Ù‰ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ù…Ù„Ù ÙÙŠ Ø§Ù„Ù…Ø¬Ù„Ø¯ Ø§Ù„Ø­Ø§Ù„ÙŠ
                with open(fname, 'w', encoding='utf-8') as f:
                    f.write(code.strip())
                
                # ØªÙ†ÙÙŠØ° Ø§Ù„Ù…Ù„Ù
                res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=10)
                exec_out += f"âœ… ØªÙ… Ø­ÙØ¸ {fname}\nğŸ–¥ï¸ Ù†Ø§ØªØ¬ Ø§Ù„ØªÙ†ÙÙŠØ°:\n{res.stdout}\n{res.stderr}"
            except Exception as e:
                exec_out += f"âŒ Ø®Ø·Ø£ ÙÙŠ {fname}: {e}\n"
    
    return clean_txt, exec_out

# --- 3. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø´Ø§Ù…Ù„Ø© ---
def get_super_response(engine, user_input, persona, image=None, use_search=False):
    client = genai.Client(api_key=GEMINI_KEY)
    search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None

    def gemini_router(target_model):
        try:
            contents = [user_input]
            if image: contents.append(image)
            config = types.GenerateContentConfig(system_instruction=f"Ø£Ù†Øª {persona}", tools=search_tool)
            r = client.models.generate_content(model=target_model, contents=contents, config=config)
            return r.text
        except Exception as e:
            if "429" in str(e):
                p = st.empty()
                for i in range(25, 0, -1):
                    p.warning(f"â³ Ø²Ø­Ø§Ù…! Ø§Ù†ØªØ¸Ø± {i} Ø«Ø§Ù†ÙŠØ©...")
                    time.sleep(1)
                p.empty()
                return client.models.generate_content(model=target_model, contents=[user_input]).text
            return f"âŒ Ø®Ø·Ø£: {e}"

    if "gemini" in engine or "gemma" in engine:
        return gemini_router(engine)
    elif "ernie" in engine and ERNIE_KEY:
        try:
            c = OpenAI(api_key=ERNIE_KEY, base_url="https://api.baidu.com/v1")
            res = c.chat.completions.create(model="ernie-5.0", messages=[{"role": "user", "content": user_input}])
            return res.choices[0].message.content
        except: return gemini_router("gemini-2.0-flash")
    return gemini_router("gemini-2.0-flash")

# --- 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ ØªØ­Ø§Ù„Ù Ù…ØµØ¹Ø¨ v16.39")
    audio = mic_recorder(start_prompt="ğŸ¤ ØªØ­Ø¯Ø«", stop_prompt="Ø¥Ø±Ø³Ø§Ù„", key='v39_mic')
    st.divider()
    
    # Ù…Ø³ØªØ¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª (Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„ØªÙŠ Ø·Ù„Ø¨ØªÙ‡Ø§ Ù„Ù„ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…Ù„ÙØ§Øª)
    st.subheader("ğŸ“ Ù…Ø³ØªØ¹Ø±Ø¶ Ø§Ù„Ù…Ù„ÙØ§Øª:")
    current_files = [f for f in os.listdir(".") if f.endswith(('.py', '.png', '.csv'))]
    st.write(current_files)
    
    st.divider()
    engine_choice = st.selectbox("ğŸ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["gemini-2.5-flash", "gemini-2.0-flash", "gemini-3-pro-preview", "gemma-3-27b", "deepseek-r1"])
    persona = st.selectbox("ğŸ‘¤ Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª", "Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª"])
    web_on = st.toggle("ğŸŒ Ø¨Ø­Ø« Ø¥Ù†ØªØ±Ù†Øª Ù…Ø¨Ø§Ø´Ø±")
    uploaded_file = st.file_uploader("ğŸ–¼ï¸ Ø±ÙØ¹ Ù…Ù„Ù:", type=['jpg', 'png', 'csv'])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„", type="primary"):
        st.session_state.messages = []; st.rerun()

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¶ ---
if "messages" not in st.session_state: st.session_state.messages = []
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ù†Ø¸Ø§Ù…Ùƒ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„...") or audio:
    txt = prompt if prompt else "ğŸ¤ [Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©]"
    st.session_state.messages.append({"role": "user", "content": txt})
    with st.chat_message("user"): st.markdown(txt)

    with st.chat_message("assistant"):
        img_obj = None
        if uploaded_file and uploaded_file.type.startswith('image'):
            img_obj = Image.open(uploaded_file)
        
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
            raw_res = get_super_response(engine_choice, txt, persona, img_obj, web_on)
        
        clean_res, code_res = run_execution_logic(raw_res)
        st.markdown(clean_res)
        
        if code_res:
            st.markdown(f'<div class="exec-box">{code_res}</div>', unsafe_allow_html=True)
            # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ø¨Ø¹Ø¯ Ø®Ù„Ù‚ Ù…Ù„Ù Ø¬Ø¯ÙŠØ¯
            st.rerun()
        
        st.session_state.messages.append({"role": "assistant", "content": clean_res})
