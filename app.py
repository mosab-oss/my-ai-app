import streamlit as st
import google.generativeai as genai
import os
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io
import urllib.parse
import re

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø§ØªØµØ§Ù„
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ø°ÙƒÙŠ", layout="wide", page_icon="âš¡")

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Secrets (Ø§Ù„Ø°ÙŠ ØªØ£ÙƒØ¯Ù†Ø§ Ù…Ù†Ù‡ ÙÙŠ ØµÙˆØ±ØªÙƒ Ø±Ù‚Ù… 9)
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)
else:
    st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
    st.stop()

# Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
def draw_image(description):
    encoded = urllib.parse.quote(description)
    return f"https://pollinations.ai/p/{encoded}?width=1024&height=1024&seed=42"

# 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©: Ø§Ù„ØªØ®ØµØµØ§Øª ÙˆØ§Ù„Ø£Ø¯ÙˆØ§Øª
with st.sidebar:
    st.header("âš™ï¸ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯")
    
    # Ù…ÙŠØ²Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ®ØµØµ (Ø§Ù„ØªÙŠ Ø·Ù„Ø¨ØªÙ‡Ø§)
    persona = st.selectbox(
        "Ø§Ø®ØªØ± ØªØ®ØµØµ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:",
        ["Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¹Ø§Ù…", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø© ÙˆØªØ·ÙˆÙŠØ±", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ù…Ø­ØªØ±Ù", "Ù…ØµÙ…Ù… ØµÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ"]
    )
    
    persona_instr = {
        "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø© ÙˆØªØ·ÙˆÙŠØ±": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø©. Ù‚Ø¯Ù… Ø­Ù„ÙˆÙ„Ø§Ù‹ Ø¨Ø±Ù…Ø¬ÙŠØ© ÙˆØ§Ø¶Ø­Ø© ÙˆØ§Ø´Ø±Ø­ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ.",
        "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ù…Ø­ØªØ±Ù": "Ø£Ù†Øª Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª. ØµØ­Ø­ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ ÙˆØ³Ø§Ø¹Ø¯ ÙÙŠ ØªØ¹Ù„Ù… ÙƒÙ„Ù…Ø§Øª Ø¬Ø¯ÙŠØ¯Ø©.",
        "Ù…ØµÙ…Ù… ØµÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ": "Ø£Ù†Øª ÙÙ†Ø§Ù† Ø±Ù‚Ù…ÙŠ. Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„ÙˆØµÙ Ø§Ù„Ø¨ØµØ±ÙŠ Ù„Ø¥Ù†ØªØ§Ø¬ Ø£ÙØ¶Ù„ Ø§Ù„ØµÙˆØ±.",
        "Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø¹Ø§Ù…": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø´Ø§Ù…Ù„ ØªØ¬ÙŠØ¨ Ø¨Ø¯Ù‚Ø© Ø¹Ù„Ù‰ ÙƒØ§ÙØ© Ø§Ù„Ø£Ø³Ø¦Ù„Ø©."
    }

    st.divider()
    st.subheader("ğŸ™ï¸ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    
    st.divider()
    uploaded_file = st.file_uploader("Ø±ÙØ¹ ØµÙˆØ±Ø©:", type=["jpg", "png", "jpeg"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# 3. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title(f"âš¡ {persona}")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "img_url" in msg: st.image(msg["img_url"])

# 4. Ù†Ø¸Ø§Ù… "Ø§Ù„Ø§Ù†ØªÙ‚Ø§Ù„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ" Ø§Ù„Ù…Ø·ÙˆØ± (The Core Logic)
def generate_smart_response(contents):
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù…Ø±ØªØ¨Ø©: Gemini 3 (Ø§Ù„Ø£Ù‚ÙˆÙ‰) -> Gemini 2 (Ø§Ù„Ø£Ø³Ø±Ø¹) -> Gemini 1.5 (Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ)
    model_hierarchy = [
        "gemini-3-pro-preview", 
        "gemini-2.0-flash-exp", 
        "gemini-1.5-flash", 
        "gemini-1.5-pro"
    ]
    
    for m_name in model_hierarchy:
        try:
            model = genai.GenerativeModel(m_name)
            response = model.generate_content(contents)
            return response.text, m_name
        except Exception as e:
            # Ø¥Ø°Ø§ Ø­Ø¯Ø« Ø®Ø·Ø£ (Ù…Ø«Ù„ Quota Exceeded ÙÙŠ ØµÙˆØ±ØªÙƒ 10)ØŒ Ø³ÙŠÙ†ØªÙ‚Ù„ Ù„Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØªØ§Ù„ÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
            continue
    return None, None

# 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
user_input = st.chat_input("Ø§Ø·Ù„Ø¨ Ù…Ø§ ØªØ´Ø§Ø¡...")
current_audio = audio_record['bytes'] if audio_record else None

if user_input or current_audio or uploaded_file:
    prompt = user_input if user_input else "Ø­Ù„Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙ‚"
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_file: st.image(uploaded_file, width=300)

    with st.chat_message("assistant"):
        with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ø®ØªÙŠØ§Ø± Ø£ÙØ¶Ù„ Ù…Ø­Ø±Ùƒ Ù…ØªØ§Ø­ Ù„Ù„Ø±Ø¯ ÙƒÙ€ {persona}..."):
            
            # Ø¯Ù…Ø¬ Ø§Ù„ØªØ®ØµØµ Ù…Ø¹ Ø§Ù„Ø·Ù„Ø¨
            full_prompt = f"ØªØ¹Ù„ÙŠÙ…Ø§ØªÙƒ: {persona_instr[persona]}\n\nØ·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: {prompt}"
            
            contents = [full_prompt]
            if uploaded_file: contents.append(Image.open(uploaded_file))
            if current_audio: contents.append({"mime_type": "audio/wav", "data": current_audio})
            
            raw_text, used_model = generate_smart_response(contents)
            
            if raw_text:
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø£ÙÙƒØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Thought) ÙƒÙ…Ø§ Ø¸Ù‡Ø± ÙÙŠ ØµÙˆØ±Ùƒ 1 Ùˆ 2
                clean_answer = re.sub(r'\{.*?\}', '', raw_text, flags=re.DOTALL)
                clean_answer = re.sub(r'thought:.*', '', clean_answer, flags=re.IGNORECASE).strip()

                # Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø³Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
                img_url = None
                if any(x in prompt for x in ["Ø§Ø±Ø³Ù…", "ØµÙˆØ±Ø©", "ØªØ®ÙŠÙ„"]) or persona == "Ù…ØµÙ…Ù… ØµÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ":
                    img_url = draw_image(prompt)
                    st.image(img_url, caption=f"ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© {used_model}")

                st.markdown(clean_answer)
                st.caption(f"ğŸš€ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø·: {used_model}")
                
                # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ
                try:
                    tts = gTTS(text=clean_answer[:200], lang='ar')
                    audio_fp = io.BytesIO()
                    tts.write_to_fp(audio_fp)
                    st.audio(audio_fp, autoplay=True)
                except: pass
                
                st.session_state.messages.append({"role": "assistant", "content": clean_answer, "img_url": img_url})
            else:
                st.error("âŒ Ø¹Ø°Ø±Ø§Ù‹ Ù…ØµØ¹Ø¨ØŒ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª (3.0 Ùˆ 2.0 Ùˆ 1.5) Ù…Ø´ØºÙˆÙ„Ø© Ø­Ø§Ù„ÙŠØ§Ù‹ Ø£Ùˆ Ø§Ù†ØªÙ‡Øª Ø­ØµØªÙ‡Ø§ Ø§Ù„ÙŠÙˆÙ…ÙŠØ©.")
