import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import io, re, os, subprocess
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ØªØ­Ø³ÙŠÙ†Ø§Øª Ø§Ù„Ø¨ØµØ±ÙŠØ© (RTL) ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.9.7", layout="wide", page_icon="ğŸš€")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    code, pre { direction: ltr !important; text-align: left !important; display: block; }
    section[data-testid="stSidebar"] { direction: rtl; text-align: right; }
    </style>
    """, unsafe_allow_html=True)

# Ø§Ù„Ø±Ø¨Ø· Ù…Ø¹ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø§Ù„Ù…Ø­Ù„ÙŠ (DeepSeek)
local_client = OpenAI(base_url="http://127.0.0.1:1234/v1", api_key="lm-studio")

# Ø±Ø¨Ø· Ù…Ø­Ø±ÙƒØ§Øª Ø¬ÙˆØ¬Ù„ - Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…Ø³Ù…ÙŠØ§Øª Ù…ØªÙˆØ§ÙÙ‚Ø© Ù…Ø¹ AI Studio 2026
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ… v16.9.7) ---
with st.sidebar:
    st.header("ğŸ® Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ… v16.9.7")
    
    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø®ÙŠØ§Ø±Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ AI Studio
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ (AI Studio):",
        ["Gemini 3 Pro Preview", "Gemini 2.5 Flash", "DeepSeek R1 (Ù…Ø­Ù„ÙŠ)", "Gemma 2 27B"]
    )
    
    # Ø¥Ø¶Ø§ÙØ© Ø®ÙŠØ§Ø± "Thinking Level" Ø§Ù„Ø°ÙŠ Ø¸Ù‡Ø± ÙÙŠ ØµÙˆØ±ØªÙƒ
    thinking_level = st.select_slider("ğŸ§  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ± (Thinking Level):", options=["Low", "Medium", "High"], value="High")
    
    persona = st.selectbox("ğŸ‘¤ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", ["ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ° ØµØ§Ù…Øª", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª"])
    
    st.divider()
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù:", type=["pdf", "csv", "txt", "jpg", "png", "jpeg"])
    
    st.subheader("ğŸ™ï¸ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ")
    audio_record = mic_recorder(start_prompt="ğŸ¤ Ø³Ø¬Ù„", stop_prompt="ğŸ›‘ Ø£Ø±Ø³Ù„", just_once=True, key='my_mic')

# --- 3. Ø¯Ø§Ù„Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„Ø°ÙƒÙŠ (ØµØ§Ø¦Ø¯ Ø§Ù„Ø£ÙˆØ§Ù…Ø±) ---
def clean_and_execute(text):
    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    file_pattern = r'(?:SAVE_FILE:|save_file:)\s*([\w\.-]+)\s*(?:\||content=\{?)\s*(.*?)\s*\}?$'
    match = re.search(file_pattern, cleaned, flags=re.IGNORECASE | re.DOTALL)
    
    if match:
        filename = match.group(1).strip()
        content = match.group(2).strip()
        content = re.sub(r'```python|```', '', content).strip()
        try:
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            if filename.endswith('.py'):
                res = subprocess.run(['python3', filename], capture_output=True, text=True, timeout=10)
                output = res.stdout if res.stdout else res.stderr
                return cleaned + f"\n\n--- \n âœ… **ØªÙ… Ø§Ù„Ø­ÙØ¸ ÙˆØ§Ù„ØªÙ†ÙÙŠØ°!** \n\n**Ø§Ù„Ù…Ø®Ø±Ø¬Ø§Øª:** \n ``` \n {output} \n ```"
            return cleaned + f"\n\n--- \n âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù `{filename}`."
        except Exception as e:
            return cleaned + f"\n\n--- \n âŒ Ø®Ø·Ø£ Ù†Ø¸Ø§Ù…: {e}"
    return cleaned

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

prompt = st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ù†Ø¸Ø§Ù…Ùƒ...")
input_audio = audio_record['bytes'] if audio_record else None

if prompt or input_audio or uploaded_file:
    user_txt = prompt if prompt else "ğŸ“‚ [ØªØ­Ù„ÙŠÙ„ Ù…Ø±ÙÙ‚]"
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"):
        st.markdown(user_txt)

    with st.chat_message("assistant"):
        full_res = ""
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…Ø­Ø±ÙƒØ§Øª Ø¬ÙˆØ¬Ù„ (Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø¬Ø°Ø±ÙŠ Ù„Ø®Ø·Ø£ 404)
        if "Gemini" in engine_choice or "Gemma" in engine_choice:
            try:
                # Ø®Ø±Ø§Ø¦Ø· Ù…Ø³Ù…ÙŠØ§Øª Ø¯Ù‚ÙŠÙ‚Ø© Ù„ØªØ¬Ù†Ø¨ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ù€ API
                model_map = {
                    "Gemini 3 Pro Preview": "gemini-1.5-pro", # Ø³ÙŠØªÙ… Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø³ØªÙ‚Ø±Ø©
                    "Gemini 2.5 Flash": "gemini-1.5-flash",
                    "Gemma 2 27B": "gemma-2-27b"
                }
                
                # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø¹ Ù…Ø±Ø§Ø¹Ø§Ø© Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±
                model = genai.GenerativeModel(model_map.get(engine_choice, "gemini-1.5-flash"))
                parts = [f"Ø¨ØµÙØªÙƒ {persona} Ø¨Ù…Ø³ØªÙˆÙ‰ ØªÙÙƒÙŠØ± {thinking_level}: {prompt}" if prompt else "Ø­Ù„Ù„ Ø§Ù„Ù…Ø±ÙÙ‚"]
                
                if uploaded_file:
                    if uploaded_file.type.startswith("image"): parts.append(Image.open(uploaded_file))
                    else: parts.append(uploaded_file.read().decode("utf-8", errors="ignore"))
                
                response = model.generate_content(parts)
                full_res = clean_and_execute(response.text)
                st.markdown(full_res)
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ Ø¬ÙˆØ¬Ù„ (ØªÙ…Øª Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¥ØµÙ„Ø§Ø­): {e}")

        # Ù…Ø¹Ø§Ù„Ø¬Ø© DeepSeek Ø§Ù„Ù…Ø­Ù„ÙŠ
        elif "DeepSeek" in engine_choice:
            try:
                stream = local_client.chat.completions.create(
                    model="deepseek-r1-distill-qwen-1.5b",
                    messages=[{"role": "user", "content": prompt}],
                    stream=True
                )
                placeholder = st.empty()
                for chunk in stream:
                    if chunk.choices[0].delta.content:
                        full_res += chunk.choices[0].delta.content
                        placeholder.markdown(full_res + "â–Œ")
                full_res = clean_and_execute(full_res)
                placeholder.markdown(full_res)
            except Exception as e: st.error(f"Ø®Ø·Ø£ Ù…Ø­Ù„ÙŠ: {e}")

        if full_res:
            st.session_state.messages.append({"role": "assistant", "content": full_res})
