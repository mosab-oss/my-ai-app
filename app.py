import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI Ø§Ù„Ù…ØªØ·ÙˆØ±", page_icon="ğŸš€")

# ØªØ­Ù…ÙŠÙ„ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")

if not api_key:
    st.error("Ù„Ù… ÙŠØªÙ… Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API. ØªØ£ÙƒØ¯ Ù…Ù† Ø¥Ø¹Ø¯Ø§Ø¯Ù‡ ÙÙŠ Ø§Ù„Ù€ Secrets.")
    st.stop()

genai.configure(api_key=api_key)

# ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
with st.sidebar:
    st.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    model_choice = st.radio(
        "Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:",
        ["gemini-2.5-flash", "gemma-3-27b-it", "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)"],
        index=0
    )
    st.info("Ù…Ù„Ø§Ø­Ø¸Ø©: Ù…Ø­Ø±Ùƒ Ø§Ù„ØµÙˆØ± ÙŠÙØ¶Ù„ Ø§Ù„ÙˆØµÙ Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©.")

# Ù…Ù†Ø·Ù‚ Ø¹Ù…Ù„ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
if model_choice == "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)":
    st.header("ğŸ¨ ØµØ§Ù†Ø¹ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø°ÙƒÙŠ")
    st.write("Ø§ÙƒØªØ¨ ÙˆØµÙØ§Ù‹ Ù„Ù…Ø§ ØªØ±ÙŠØ¯ Ø±Ø³Ù…Ù‡ØŒ ÙˆØ³Ø£Ù‚ÙˆÙ… Ø¨ØªØ­ÙˆÙŠÙ„ Ø®ÙŠØ§Ù„Ùƒ Ø¥Ù„Ù‰ Ø­Ù‚ÙŠÙ‚Ø©.")
    
    prompt = st.text_area("ÙˆØµÙ Ø§Ù„ØµÙˆØ±Ø© (Prompt):", placeholder="Ù…Ø«Ù„Ø§Ù‹: A futuristic city with flying cars at sunset...")
    
    if st.button("Ø¥Ø¨Ø¯Ø£ Ø§Ù„Ø±Ø³Ù… ğŸ–Œï¸"):
        if prompt:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…... Ù‚Ø¯ ÙŠØ³ØªØºØ±Ù‚ Ø§Ù„Ø£Ù…Ø± Ø«ÙˆØ§Ù†Ù Ù‚Ù„ÙŠÙ„Ø©"):
                try:
                    # Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„ØµÙˆØ±
                    image_model = genai.GenerativeModel("imagen-3.0-generate-001")
                    result = image_model.generate_content(prompt)
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø©
                    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¨Ø¹Ø¶ Ø¥ØµØ¯Ø§Ø±Ø§Øª Ø§Ù„Ù…ÙƒØªØ¨Ø© ØªØ¹ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© ÙƒØ¨Ø§ÙŠØªØ§Øª Ù…Ø¨Ø§Ø´Ø±Ø©
                    st.image(result.candidates[0].content.parts[0].inline_data.data, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Ù…ØµØ¹Ø¨ AI")
                    st.success("ØªÙ… Ø§Ù„Ø±Ø³Ù… Ø¨Ù†Ø¬Ø§Ø­!")
                except Exception as e:
                    st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„Ø±Ø³Ù…: {e}")
        else:
            st.warning("Ø§Ù„Ø±Ø¬Ø§Ø¡ Ø¥Ø¯Ø®Ø§Ù„ ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø©.")

else:
    # Ù…Ø­Ø±Ùƒ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© (Ù„Ù„Ù†Ù…Ø§Ø°Ø¬ Ø§Ù„Ù†ØµÙŠØ©)
    st.header(f"ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø°ÙƒÙŠØ© ({model_choice})")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    if prompt := st.chat_input("Ø¨Ù…Ø§Ø°Ø§ ÙŠÙ…ÙƒÙ†Ù†ÙŠ Ù…Ø³Ø§Ø¹Ø¯ØªÙƒ Ø§Ù„ÙŠÙˆÙ…ØŸ"):
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                try:
                    model = genai.GenerativeModel(model_choice)
                    response = model.generate_content(prompt)
                    st.markdown(response.text)
                    st.session_state.messages.append({"role": "assistant", "content": response.text})
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø­Ø±Ùƒ: {e}")
