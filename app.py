import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import io, re, os
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø±Ø¨Ø· ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.4", layout="wide", page_icon="ğŸ¤")

# Ø±Ø¨Ø· Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ù„ÙŠ (LM Studio)
local_client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")

# Ø±Ø¨Ø· Ù…Ø­Ø±ÙƒØ§Øª Ø¬ÙˆØ¬Ù„
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ…) ---
with st.sidebar:
    st.header("ğŸ® Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ… v16.4")
    
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:",
        ["DeepSeek R1 (Ù…Ø­Ù„ÙŠ)", "Gemini 2.5 Flash", "Gemini 3 Pro", "Gemma 3 27B"]
    )
    
    persona = st.selectbox("ğŸ‘¤ Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", ["Ù…Ø¯Ø±Ø³ Ù„ØºÙˆÙŠ", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ° Ù…Ù„ÙØ§Øª"])
    
    st.divider()
    st.subheader("ğŸ™ï¸ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„ØµÙˆØªÙŠ")
    audio_record = mic_recorder(
        start_prompt="ğŸ¤ Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«",
        stop_prompt="ğŸ›‘ ØªÙˆÙ‚Ù ÙˆØ£Ø±Ø³Ù„",
        just_once=True,
        key='my_mic'
    )
    
    st.divider()
    uploaded_file = st.file_uploader("ğŸ“¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±:", type=["jpg", "png", "jpeg"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 3. Ø§Ù„Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯Ø© (Ø¥ØµÙ„Ø§Ø­ DOTALL ÙˆØ¥Ø¶Ø§ÙØ© Ø§Ù„ÙˆÙƒÙŠÙ„) ---
def clean_response(text):
    # Ø§Ø³ØªØ®Ø¯Ø§Ù… re.DOTALL Ø¨Ø¯Ù„Ø§Ù‹ Ù…Ù† st.DOTALL Ù„Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø®Ø·Ø£
    cleaned = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    
    # Ù…ÙŠØ²Ø© Ø§Ù„ÙˆÙƒÙŠÙ„ (Agent): Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª
    # Ø§Ù„Ù†Ù…Ø· Ø§Ù„Ù…Ø·Ù„ÙˆØ¨: SAVE_FILE: filename.txt | content
    file_pattern = r'SAVE_FILE:\s*([\w\.-]+)\s*\|\s*(.*)'
    match = re.search(file_pattern, cleaned, flags=re.DOTALL)
    
    if match:
        filename = match.group(1)
        content = match.group(2)
        try:
            # ØªÙ†ÙÙŠØ° Ø¹Ù…Ù„ÙŠØ© Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¹Ù„Ù‰ Ù†Ø¸Ø§Ù… Ø£ÙˆØ¨Ù†ØªÙˆ
            with open(filename, 'w', encoding='utf-8') as f:
                f.write(content)
            return cleaned + f"\n\n--- \n âœ… **[Ù†Ø¸Ø§Ù… Ø§Ù„ÙˆÙƒÙŠÙ„]: ØªÙ… Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù…Ù„Ù `{filename}` Ø¨Ù†Ø¬Ø§Ø­.**"
        except Exception as e:
            return cleaned + f"\n\n--- \n âŒ **[Ù†Ø¸Ø§Ù… Ø§Ù„ÙˆÙƒÙŠÙ„]: ÙØ´Ù„ Ø§Ù„Ø­ÙØ¸: {e}**"
            
    return cleaned

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(clean_response(msg["content"]))

# --- 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ù†Øµ Ø£Ùˆ ØµÙˆØª) ---
prompt = st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ ÙˆÙƒÙŠÙ„Ùƒ Ø§Ù„Ø°ÙƒÙŠ...")

if audio_record:
    input_audio_bytes = audio_record['bytes']
    prompt = "ØªØ­Ù„ÙŠÙ„ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ" 
else:
    input_audio_bytes = None

if prompt or input_audio_bytes:
    display_text = prompt if not input_audio_bytes else "ğŸ¤ [Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©]"
    st.session_state.messages.append({"role": "user", "content": display_text})
    
    with st.chat_message("user"):
        st.markdown(display_text)
        if input_audio_bytes:
            st.audio(input_audio_bytes)

    with st.chat_message("assistant"):
        full_response = ""
        
        # Ø£. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Gemini (ÙŠØ¯Ø¹Ù… Ø§Ù„ØµÙˆØª ÙˆØ§Ù„ØµÙˆØ±)
        if "Gemini" in engine_choice:
            try:
                model_name = "gemini-1.5-flash-latest" if "Flash" in engine_choice else "gemini-1.5-pro"
                model = genai.GenerativeModel(model_name)
                
                content_to_send = []
                if prompt: content_to_send.append(prompt)
                if uploaded_file: content_to_send.append(Image.open(uploaded_file))
                if input_audio_bytes:
                    content_to_send.append({'mime_type': 'audio/wav', 'data': input_audio_bytes})
                
                res = model.generate_content(content_to_send)
                full_response = res.text
                st.markdown(full_response)
            except Exception as e:
                st.error(f"Ø®Ø·Ø£ ÙÙŠ Gemini: {e}")

        # Ø¨. Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ DeepSeek Ø§Ù„Ù…Ø­Ù„ÙŠ (ÙŠØ¯Ø¹Ù… Ù…ÙŠØ²Ø© Ø§Ù„ÙˆÙƒÙŠÙ„)
        elif "DeepSeek" in engine_choice:
            if input_audio_bytes:
                st.warning("DeepSeek Ø§Ù„Ù…Ø­Ù„ÙŠ Ù„Ø§ ÙŠØ¯Ø¹Ù… ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ø³ØªØ®Ø¯Ø§Ù… Gemini Ù„Ù„ØµÙˆØª.")
            else:
                try:
                    # ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù…ÙŠØ²Ø© Ø­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª
                    res = local_client.chat.completions.create(
                        model="deepseek-r1-distill-qwen-1.5b",
                        messages=[{"role": "system", "content": f"Ø£Ù†Øª {persona}. Ù„Ù„Ø­ÙØ¸ Ø§Ø³ØªØ®Ø¯Ù…: SAVE_FILE: name.txt | content"}, 
                                 {"role": "user", "content": prompt}],
                        stream=True
                    )
                    placeholder = st.empty()
                    for chunk in res:
                        if chunk.choices[0].delta.content:
                            full_response += chunk.choices[0].delta.content
                            placeholder.markdown(full_response + "â–Œ")
                    
                    processed_text = clean_response(full_response)
                    placeholder.markdown(processed_text)
                    full_response = processed_text
                except: 
                    st.error("ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ LM Studio ÙˆØ§Ù„Ø¶ØºØ· Ø¹Ù„Ù‰ Start Server!")

        # Ø¬. Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
        if full_response:
            try:
                clean_text = clean_response(full_response)
                tts = gTTS(text=clean_text[:300], lang='ar')
                audio_io = io.BytesIO()
                tts.write_to_fp(audio_io)
                st.audio(audio_io)
            except: pass
            st.session_state.messages.append({"role": "assistant", "content": full_response})
