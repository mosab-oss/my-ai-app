import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from streamlit_mic_recorder import mic_recorder

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI Ø§Ù„Ø´Ø§Ù…Ù„", page_icon="ğŸ™ï¸", layout="wide")

# ØªØ­Ù…ÙŠÙ„ Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© GEMINI_API_KEY ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.")
    st.stop()

genai.configure(api_key=api_key)

# --- Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª")
    persona = st.selectbox("Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§Øª", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª", "Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª"])
    model_choice = st.radio("Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["gemini-2.5-flash", "gemma-3-27b-it", "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)"])
    
    st.divider()
    st.write("ğŸ™ï¸ Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØªÙŠ:")
    audio_record = mic_recorder(
        start_prompt="Ø¥Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø« ğŸ¤",
        stop_prompt="Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª ğŸ“¤",
        key='recorder'
    )
    
    st.divider()
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:", type=["jpg", "jpeg", "png"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ÙˆØ¯ ---
def get_ai_response(user_input, attached_image=None, attached_audio=None):
    model = genai.GenerativeModel(model_choice if model_choice != "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)" else "gemini-2.5-flash")
    content_list = [f"ØªÙ‚Ù…Øµ Ø¯ÙˆØ± {persona}: {user_input}"]
    
    if attached_image:
        content_list.append(Image.open(attached_image))
    
    if attached_audio:
        # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª ÙƒØ¨ÙŠØ§Ù†Ø§Øª Ø¨Ø§ÙŠØªØ§Øª Ù„Ù„Ù†Ù…ÙˆØ°Ø¬
        content_list.append({"mime_type": "audio/wav", "data": attached_audio})
    
    response = model.generate_content(content_list)
    return response.text

# --- ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
if model_choice == "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)":
    st.header("ğŸ¨ ØµØ§Ù†Ø¹ Ø§Ù„ØµÙˆØ±")
    prompt = st.text_area("ØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ©:")
    if st.button("Ø¥Ø¨Ø¯Ø£ Ø§Ù„Ø±Ø³Ù… ğŸ–Œï¸"):
        if prompt:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…..."):
                try:
                    img_model = genai.GenerativeModel("imagen-3.0-generate-001")
                    result = img_model.generate_content(prompt)
                    st.image(result.candidates[0].content.parts[0].inline_data.data)
                except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")
else:
    st.header(f"ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ({model_choice})")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (Ù†ØµÙŠ Ø£Ùˆ ØµÙˆØªÙŠ)
    user_input = st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø£ÙŠ Ø´ÙŠØ¡...")
    
    # Ø¥Ø°Ø§ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ØµÙˆØªØ§Ù‹ØŒ Ù†Ø¹ØªØ¨Ø±Ù‡ Ù‡Ùˆ Ø§Ù„Ù…Ø¯Ø®Ù„
    current_audio = audio_record['bytes'] if audio_record else None
    
    if user_input or current_audio:
        input_text = user_input if user_input else "Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ ÙˆØ£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡."
        
        st.session_state.messages.append({"role": "user", "content": input_text})
        with st.chat_message("user"):
            st.markdown(input_text)
            if current_audio: st.audio(current_audio)

        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ±..."):
                try:
                    response_text = get_ai_response(input_text, uploaded_file, current_audio)
                    st.markdown(response_text)
                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                except Exception as e: st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
