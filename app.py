import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from gtts import gTTS
import io

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¨Ø¯Ø§ÙŠØ©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©", layout="wide")
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))

# 2. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…Ø·ÙˆØ± (ÙŠØ­ÙˆÙ„ ÙˆØµÙÙƒ Ø§Ù„Ø¨Ø³ÙŠØ· Ø¥Ù„Ù‰ Ù„ÙˆØ­Ø© Ø³ÙŠÙ†Ù…Ø§Ø¦ÙŠØ©)
def draw_smart_image(user_prompt):
    try:
        # Ù‡Ù†Ø§ Ù†Ø³ØªØ®Ø¯Ù… Gemini 3 Flash Ù„ÙŠÙ‚ÙˆÙ… Ø¨Ø¯ÙˆØ± "ÙƒØ§ØªØ¨ Ø§Ù„Ø³ÙŠÙ†Ø§Ø±ÙŠÙˆ" ÙˆÙŠØ­Ø³Ù† Ø§Ù„ÙˆØµÙ
        desc_model = genai.GenerativeModel("gemini-3-flash-preview")
        enhancer_prompt = f"Convert this image description into a highly detailed cinematic prompt for Imagen 3: {user_prompt}"
        enhanced_prompt = desc_model.generate_content(enhancer_prompt).text
        
        # Ø§Ù„Ø¢Ù† Ù†Ø±Ø³Ù„ Ø§Ù„ÙˆØµÙ Ø§Ù„Ù…Ø·ÙˆØ± Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… Imagen
        # Ù…Ù„Ø§Ø­Ø¸Ø©: Ø¥Ø°Ø§ Ù„Ù… ÙŠÙ†Ø¬Ø­ imagen-3ØŒ Ø¬Ø±Ø¨ Ø§Ø³ØªØ¨Ø¯Ø§Ù„Ù‡ Ø¨Ù€ "imagen-3.0-generate-001"
        paint_model = genai.GenerativeModel("imagen-3.0-generate-001")
        response = paint_model.generate_content(enhanced_prompt)
        
        # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† Ø§Ø³ØªÙ„Ø§Ù… Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
        if response.candidates[0].content.parts[0].inline_data:
            return response.candidates[0].content.parts[0].inline_data.data
        return "ÙˆØµÙ"
    except Exception as e:
        return f"error: {e}"

# 3. ÙˆØ¸ÙŠÙØ© Ø§Ù„ØµÙˆØª (Ø§Ù„Ø±Ø¯ Ø§Ù„Ø°ÙƒÙŠ)
def speak(text):
    tts = gTTS(text=text.replace('*', '').replace('#', ''), lang='ar')
    fp = io.BytesIO()
    tts.write_to_fp(fp)
    return fp

# 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
with st.sidebar:
    st.header("ğŸ¨ Ø®ÙŠØ§Ø±Ø§Øª Ø§Ù„Ù…Ø­Ø±Ùƒ")
    mode = st.radio("Ø§Ø®ØªØ± Ø§Ù„ÙˆØ¶Ø¹:", ["Ø¯Ø±Ø¯Ø´Ø© ÙˆØ±Ø¤ÙŠØ© ğŸ‘ï¸", "Ø±Ø³Ù… Ø§Ø­ØªØ±Ø§ÙÙŠ ğŸ–Œï¸"])
    st.divider()
    st.subheader("ğŸ–¼ï¸ Ù‚Ø³Ù… Ø§Ù„Ø±Ø¤ÙŠØ© (Vision)")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„ØªØ­Ù„ÙŠÙ„Ù‡Ø§:", type=["jpg", "png"])
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

st.title("âš¡ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")

# --- Ù…Ù†Ø·Ù‚ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠ ---
if mode == "Ø±Ø³Ù… Ø§Ø­ØªØ±Ø§ÙÙŠ ğŸ–Œï¸":
    prompt = st.text_input("ØµÙ Ù…Ø§ ØªØ±ÙŠØ¯ Ø±Ø³Ù…Ù‡ (Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ Ø£Ùˆ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠ):")
    if st.button("ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„ÙÙ†ÙŠØ©"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ ØªØ­Ø³ÙŠÙ† Ø§Ù„ÙˆØµÙ ÙˆØ§Ù„Ø±Ø³Ù…..."):
            result = draw_smart_image(prompt)
            if isinstance(result, str) and "error" in result:
                st.error("Ø§Ù„Ù…Ø­Ø±Ùƒ ÙŠØ­ØªØ§Ø¬ VPN Ø£Ù…Ø±ÙŠÙƒÙŠ Ù„Ù„Ø±Ø³Ù… Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ.")
            elif result == "ÙˆØµÙ":
                st.warning("Ø§Ù„Ù…Ø­Ø±Ùƒ Ø£Ø¹Ø·Ù‰ ÙˆØµÙØ§Ù‹ ÙÙ‚Ø· ÙˆÙ„Ù… ÙŠØ±Ø³Ù…. Ø¬Ø±Ø¨ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ù€ VPN.")
            else:
                st.image(result, caption="ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© Ù…ØµØ¹Ø¨ AI")

# --- Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„ ---
else:
    if "messages" not in st.session_state: st.session_state.messages = []
    
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    user_msg = st.chat_input("Ø§Ø³Ø£Ù„Ù†ÙŠ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© Ø£Ùˆ Ø¯Ø±Ø¯Ø´...")
    
    if user_msg or uploaded_file:
        with st.chat_message("user"):
            st.write(user_msg if user_msg else "Ø­Ù„Ù„ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©")
            if uploaded_file: st.image(uploaded_file, width=300)
            
        with st.chat_message("assistant"):
            try:
                model = genai.GenerativeModel("gemini-3-flash-preview")
                content = [user_msg if user_msg else "Ù…Ø§Ø°Ø§ ØªØ±Ù‰ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©ØŸ"]
                if uploaded_file: content.append(Image.open(uploaded_file))
                
                response = model.generate_content(content)
                st.write(response.text)
                st.audio(speak(response.text), autoplay=True)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")
