import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, time
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 
from PIL import Image

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø³Ù…Ø§Øª ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.38.0", layout="wide", page_icon="ğŸ›¡ï¸")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; background-color: #0e1117; color: white; }
    [data-testid="stSidebar"] { background-color: #000c18; border-left: 2px solid #00d4ff; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: monospace; }
    .status-badge { background-color: #1a1a1a; color: #00d4ff; border: 1px solid #00d4ff; padding: 2px 10px; border-radius: 20px; font-size: 12px; }
    </style>
    """, unsafe_allow_html=True)

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø³Ø±ÙŠØ©
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY")
KIMI_KEY = st.secrets.get("KIMI_API_KEY")
ERNIE_KEY = st.secrets.get("ERNIE_API_KEY")

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ° ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª (v16.12) ---
def run_execution_logic(text):
    clean_txt = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    file_match = re.search(r'SAVE_FILE:\s*([\w\.-]+)\s*\|\s*content=\{(.*?)\}', text, flags=re.DOTALL)
    exec_out = ""
    if file_match:
        fname, fcontent = file_match.group(1).strip(), file_match.group(2).strip()
        fcontent = re.sub(r'```python|```', '', fcontent).strip()
        try:
            with open(fname, 'w', encoding='utf-8') as f: f.write(fcontent)
            if fname.endswith('.py'):
                res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=10)
                exec_out = f"ğŸ–¥ï¸ Ù†Ø§ØªØ¬ Ø§Ù„ØªÙ†ÙÙŠØ°:\n{res.stdout}\n{res.stderr}"
        except Exception as e: exec_out = f"âŒ Ø®Ø·Ø£: {e}"
    return clean_txt, exec_out

# --- 3. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø´Ø§Ù…Ù„Ø© (Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù… Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©) ---
def get_super_response(engine, user_input, persona, image=None, use_search=False):
    client = genai.Client(api_key=GEMINI_KEY)
    
    # ØªØ­Ø¶ÙŠØ± Ø£Ø¯ÙˆØ§Øª Ø§Ù„Ø¨Ø­Ø«
    search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None

    def gemini_router(target_model):
        try:
            contents = [user_input]
            if image: contents.append(image)
            config = types.GenerateContentConfig(system_instruction=f"Ø£Ù†Øª {persona}", tools=search_tool)
            r = client.models.generate_content(model=target_model, contents=contents, config=config)
            return r.text
        except Exception as e:
            if "429" in str(e):
                p = st.empty()
                for i in range(25, 0, -1):
                    p.warning(f"â³ Ø²Ø­Ø§Ù…! Ø§Ù†ØªØ¸Ø± {i} Ø«Ø§Ù†ÙŠØ©...")
                    time.sleep(1)
                p.empty()
                return client.models.generate_content(model=target_model, contents=[user_input]).text
            return f"âŒ Ø®Ø·Ø£: {e}"

    # Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø­Ø³Ø¨ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©
    if "gemini" in engine or "gemma" in engine:
        return gemini_router(engine)
    
    elif "ernie" in engine and ERNIE_KEY:
        try:
            c = OpenAI(api_key=ERNIE_KEY, base_url="https://api.baidu.com/v1")
            res = c.chat.completions.create(model="ernie-5.0", messages=[{"role": "user", "content": user_input}])
            return res.choices[0].message.content
        except: return gemini_router("gemini-2.0-flash")

    elif "deepseek" in engine:
        try:
            c = OpenAI(api_key="lm-studio", base_url="http://localhost:1234/v1")
            res = c.chat.completions.create(model="deepseek-r1", messages=[{"role": "user", "content": user_input}], timeout=5)
            return res.choices[0].message.content
        except: return gemini_router("gemini-2.0-flash")

    return gemini_router("gemini-2.0-flash")

# --- 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©) ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ ØªØ­Ø§Ù„Ù Ù…ØµØ¹Ø¨ v16.38")
    audio = mic_recorder(start_prompt="ğŸ¤ ØªØ­Ø¯Ø«", stop_prompt="Ø¥Ø±Ø³Ø§Ù„", key='v38_mic')
    st.divider()
    
    # ØªÙ… Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ù‡Ù†Ø§ Ø¨Ø¯Ù‚Ø©
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙÙƒØ±:", 
        [
            "gemini-2.5-flash", 
            "gemini-2.0-flash",
            "gemini-3-pro-preview", 
            "gemma-3-27b", 
            "deepseek-r1", 
            "ernie-5.0", 
            "kimi-latest"
        ]
    )
    
    persona = st.selectbox("ğŸ‘¤ Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª", "Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ†", "Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª"])
    
    st.write("---")
    web_on = st.toggle("ğŸŒ Ø¨Ø­Ø« Ø¥Ù†ØªØ±Ù†Øª Ù…Ø¨Ø§Ø´Ø±")
    uploaded_file = st.file_uploader("ğŸ–¼ï¸ Ø±ÙØ¹ ØµÙˆØ±Ø©/Ù…Ù„Ù:", type=['jpg', 'png', 'jpeg', 'csv'])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„", type="primary"):
        st.session_state.messages = []; st.rerun()

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„ØªÙ†ÙÙŠØ° ---
if "messages" not in st.session_state: st.session_state.messages = []
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ù†Ø¸Ø§Ù…Ùƒ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„...") or audio:
    txt = prompt if prompt else "ğŸ¤ [Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©]"
    st.session_state.messages.append({"role": "user", "content": txt})
    with st.chat_message("user"): st.markdown(txt)

    with st.chat_message("assistant"):
        img_obj = None
        if uploaded_file and uploaded_file.type.startswith('image'):
            img_obj = Image.open(uploaded_file)
            st.markdown('<span class="status-badge">ğŸ‘ï¸ Ø¬Ø§Ø±ÙŠ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©...</span>', unsafe_allow_html=True)
        
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø±Ø¨Ø·..."):
            raw_res = get_super_response(engine_choice, txt, persona, img_obj, web_on)
        
        clean_res, code_res = run_execution_logic(raw_res)
        st.markdown(clean_res)
        
        if code_res:
            st.markdown(f'<div class="exec-box">{code_res}</div>', unsafe_allow_html=True)
        
        try:
            tts = gTTS(text=clean_res[:250], lang='ar')
            b = io.BytesIO(); tts.write_to_fp(b); st.audio(b)
        except: pass
        
        st.session_state.messages.append({"role": "assistant", "content": clean_res})
