import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import io, re, os, subprocess
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.14.0", layout="wide", page_icon="ğŸš€")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    [data-testid="stSidebar"] { background-color: #001529; direction: rtl; }
    .stSelectbox label, .stSlider label { color: #00d4ff !important; font-weight: bold; }
    .exec-box { background-color: #000; color: #0f0; padding: 15px; border-radius: 10px; border: 1px dashed #0f0; font-family: 'Courier New', monospace; }
    </style>
    """, unsafe_allow_html=True)

# Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø±Ø¨Ø·
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key: genai.configure(api_key=api_key)

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ù„Ù„Ø£ÙƒÙˆØ§Ø¯ ---
def execute_logic(text):
    display_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    file_pattern = r'SAVE_FILE:\s*([\w\.-]+)\s*\|\s*content=\{(.*?)\}'
    match = re.search(file_pattern, text, flags=re.DOTALL)
    
    exec_output = ""
    if match:
        fname, fcontent = match.group(1).strip(), match.group(2).strip()
        fcontent = re.sub(r'```python|```', '', fcontent).strip()
        try:
            with open(fname, 'w', encoding='utf-8') as f: f.write(fcontent)
            if fname.endswith('.py'):
                res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=10)
                exec_output = f"ğŸ–¥ï¸ Ù†Ø§ØªØ¬ ØªØ´ØºÙŠÙ„ Ø§Ù„ÙƒÙˆØ¯:\n{res.stdout}\n{res.stderr}"
        except Exception as e: exec_output = f"âŒ Ø®Ø·Ø£ Ø¨Ø±Ù…ÙŠ: {e}"
    return display_text, exec_output

# --- 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (ÙƒÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª + ÙƒÙ„ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª) ---
with st.sidebar:
    st.title("ğŸ› ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© v16.14.0")
    
    # Ù…ÙŠØ²Ø© Ø§Ù„Ù…ØºØ±ÙÙˆÙ† (Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†)
    st.markdown("### ğŸ¤ Ø§Ù„Ù…ØºØ±ÙÙˆÙ†")
    audio_record = mic_recorder(start_prompt="Ø¥Ø¶ØºØ· Ù„Ù„ØªØ­Ø¯Ø«", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª", key='sidebar_mic_v14')
    
    st.divider()

    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© ÙƒÙ…Ø§ Ø·Ù„Ø¨Øª (Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ù„Ø³Ø¯Ø§Ø³ÙŠ)
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙÙƒØ±:", 
        [
            "Gemini 3 Pro", 
            "Gemini 2.5 Flash", 
            "Gemma 3 27B", 
            "DeepSeek R1", 
            "Kimi AI", 
            "ERNIE Bot"
        ]
    )

    # Ø§Ù„ØªØ­ÙƒÙ… ÙÙŠ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø´Ø®ØµÙŠØ©
    thinking_level = st.select_slider("ğŸ§  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±:", ["Low", "Medium", "High"], value="High")
    persona = st.selectbox("ğŸ‘¤ ØªÙ‚Ù…Øµ Ø¯ÙˆØ±:", ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ†", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬ Ù…Ø­ØªØ±Ù", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ°"])

    st.divider()

    # Ø£Ø¯ÙˆØ§Øª Ø¥Ø¶Ø§ÙÙŠØ©
    uploaded_file = st.file_uploader("ğŸ“‚ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª:", type=["pdf", "txt", "py", "png", "jpg"])
    
    if st.button("ğŸ” ÙØ­Øµ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ÙˆØ§Ù„Ø§ØªØµØ§Ù„"):
        st.write("ÙŠØªÙ… Ø§Ù„Ø¢Ù† ÙØ­Øµ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø³ØªØ©...")

# --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ ÙˆØ§Ù„Ø±Ø¯ÙˆØ¯ ---
if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

prompt = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ØºØ±ÙÙˆÙ† Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©...")

if prompt or audio_record or uploaded_file:
    user_txt = prompt if prompt else "ğŸ¤ [ØªÙ… Ø¥Ø±Ø³Ø§Ù„ Ø£Ù…Ø± ØµÙˆØªÙŠ]"
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"): st.markdown(user_txt)

    with st.chat_message("assistant"):
        try:
            # ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø·Ù„Ø¨ Ù„Ù„Ù…Ø­Ø±Ùƒ (Ø§ÙØªØ±Ø§Ø¶ÙŠ Gemini Ù„Ù„Ø´Ø±Ø­)
            model = genai.GenerativeModel("models/gemini-1.5-pro") # Ø£Ùˆ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø±
            full_req = f"Ø¨ØµÙØªÙƒ {persona} ÙˆØ¨Ù…Ø³ØªÙˆÙ‰ ØªÙÙƒÙŠØ± {thinking_level}: {user_txt}. Ø¥Ø°Ø§ ÙƒØªØ¨Øª ÙƒÙˆØ¯ Ø§Ø³ØªØ®Ø¯Ù…: SAVE_FILE: name | content={{}}"
            
            response = model.generate_content(full_req)
            
            # Ø§Ù„ØªÙ†Ø¸ÙŠÙ ÙˆØ§Ù„ØªÙ†ÙÙŠØ°
            clean_txt, execution_res = execute_logic(response.text)
            st.markdown(clean_txt)
            
            if execution_res:
                st.markdown(f'<div class="exec-box">{execution_res}</div>', unsafe_allow_html=True)

            # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ (TTS)
            tts = gTTS(text=clean_txt[:250], lang='ar')
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            st.audio(audio_fp, format='audio/mp3')

            st.session_state.messages.append({"role": "assistant", "content": clean_txt})
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…Ø­Ø±Ùƒ {engine_choice}: {e}")
