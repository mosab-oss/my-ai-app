import streamlit as st
from google import genai
from google.genai import types
import io, re, os, json, pandas as pd
from gtts import gTTS
from streamlit_mic_recorder import speech_to_text
from PIL import Image

# --- 1. Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙÙˆÙ„Ø§Ø°ÙŠØ© ---
def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r", encoding="utf-8") as f:
            try: return json.load(f)
            except: return []
    return []

def save_history(messages):
    with open("history.json", "w", encoding="utf-8") as f: 
        json.dump(messages, f, ensure_ascii=False, indent=4)

st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v28 - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ø´Ø§Ù…Ù„Ø©", layout="wide", page_icon="ğŸ›¡ï¸")

# --- 2. Ù…ØµÙÙˆÙØ© Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø³Ø¨Ø¹Ø© (Ø§Ù„ØªØµØ­ÙŠØ­ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ Ù„Ù„Ù…Ø³Ù…ÙŠØ§Øª) ---
MODELS_GRID = {
    "Gemini 3 Flash (Ø§Ù„Ø£Ø­Ø¯Ø«)": "gemini-2.0-flash", 
    "Gemini 2.5 Flash": "gemini-1.5-flash",
    "Gemini 2.0 Flash": "gemini-2.0-flash-exp",
    "Gemini 1.5 Pro": "gemini-1.5-pro",
    "Gemma 3 27B": "gemma-2-27b-it",
    "DeepSeek R1": "deepseek-reasoner",
    "Kimi Latest": "moonshot-v1-8k"
}

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ø­Ø« ---
def get_super_response(engine_label, user_input, persona_type, use_search=False):
    engine_id = MODELS_GRID.get(engine_label, "gemini-2.0-flash")
    try:
        client = genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
        # ØªÙØ¹ÙŠÙ„ Ø£Ø¯Ø§Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
        search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None
        
        config = types.GenerateContentConfig(
            system_instruction=f"Ø£Ù†Øª {persona_type}. Ø±Ø¯ Ø¹Ù„Ù‰ Ù…ØµØ¹Ø¨ Ø¨Ø°ÙƒØ§Ø¡ ÙˆÙˆÙ‚Ø§Ø±.",
            tools=search_tool
        )
        
        response = client.models.generate_content(model=engine_id, contents=[user_input], config=config)
        return response.text
    except Exception as e:
        # Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚ÙØ² ÙÙˆÙ‚ Ø§Ù„Ø®Ø·Ø£ ÙÙŠ Ø­Ø§Ù„ ØªØ¹Ø·Ù„ Ø£ÙŠ Ù…Ø­Ø±Ùƒ
        st.error(f"âš ï¸ {engine_label} ÙŠÙˆØ§Ø¬Ù‡ Ø¶ØºØ·Ø§Ù‹. Ø¬Ø±Ø¨ Ù…Ø­Ø±ÙƒØ§Ù‹ Ø¢Ø®Ø±.")
        return f"Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}"

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© (ØªÙ†Ø³ÙŠÙ‚Sidebar) ---
if "messages" not in st.session_state: st.session_state.messages = load_history()

with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª v28")
    
    # 1. Ø²Ø± Ø§Ù„Ù…Ø³Ø­ (ÙÙŠ Ø§Ù„Ù‚Ù…Ø© Ù„Ø³Ù‡ÙˆÙ„Ø© Ø§Ù„ÙˆØµÙˆÙ„)
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ ÙˆØªØµÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©", type="primary"):
        st.session_state.messages = []
        if os.path.exists("history.json"): os.remove("history.json")
        st.success("ØªÙ… Ø§Ù„ØªØµÙÙŠØ± Ø¨Ù†Ø¬Ø§Ø­!")
        st.rerun()

    st.divider()
    # 2. Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
    st.write("ğŸ™ï¸ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©:")
    audio_text = speech_to_text(language='ar', start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†", stop_prompt="Ø¥Ù†Ù‡Ø§Ø¡", key='v28_mic')
    
    st.divider()
    # 3. Ø²Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ø§Ù„Ù…Ø¹Ø§Ø¯ ØªÙØ¹ÙŠÙ„Ù‡)
    web_on = st.toggle("ğŸŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Google Search)", value=True)
    
    st.divider()
    # 4. Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø´Ø®ØµÙŠØ© ÙˆØ§Ù„Ù…Ø­Ø±Ùƒ
    persona = st.radio("ğŸ‘¤ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ù†Ø´Ø·Ø©:", ["Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ ğŸ‘¨â€ğŸ«", "Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ğŸ› ï¸", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø®ØµÙŠ ğŸ¤–"])
    engine_choice = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„:", list(MODELS_GRID.keys()))
    uploaded_file = st.file_uploader("ğŸ“Š Ø±ÙØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª", type=['csv', 'png', 'jpg'])

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø­ÙˆØ§Ø± ÙˆØ§Ù„Ø±Ø§Ø¯Ø§Ø± ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

chat_input = st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ù†Ø¸Ø§Ù…Ùƒ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„...")
final_prompt = audio_text if audio_text else chat_input

if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    with st.chat_message("user"): st.markdown(final_prompt)

    with st.chat_message("assistant"):
        res = get_super_response(engine_choice, final_prompt, persona, use_search=web_on)
        st.markdown(res)
        
        # Ø§Ù„Ø±Ø§Ø¯Ø§Ø± (ÙƒØ´Ù Ø§Ù„Ù…Ø³Ø§Ø±)
        code_match = re.search(r'```python(.*?)```', res, flags=re.DOTALL)
        if code_match:
            with open("radar_output.py", "w", encoding="utf-8") as f: f.write(code_match.group(1).strip())
            st.info(f"ğŸ“‚ Ø§Ù„Ø±Ø§Ø¯Ø§Ø±: ØªÙ… Ø­ÙØ¸ Ø§Ù„ÙƒÙˆØ¯ ÙÙŠ {os.path.abspath('radar_output.py')}")

        st.session_state.messages.append({"role": "assistant", "content": res})
        save_history(st.session_state.messages)
