import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„", page_icon="ğŸš€", layout="wide")

# 2. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…ÙØ§ØªÙŠØ­ ÙˆØ§Ù„Ø§ØªØµØ§Ù„
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© Ù…ÙØªØ§Ø­ GEMINI_API_KEY ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØªØ·Ø¨ÙŠÙ‚.")
    st.stop()

genai.configure(api_key=api_key)

# 3. ÙˆØ¸ÙŠÙØ© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ÙƒÙ„Ø§Ù… (Audio Output)
def speak_text(text):
    try:
        clean_text = text.replace('*', '').replace('#', '') # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªÙ†Ø³ÙŠÙ‚ Ù„Ù‚Ø±Ø§Ø¡Ø© Ø£ÙˆØ¶Ø­
        tts = gTTS(text=clean_text, lang='ar', slow=False)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except:
        return None

# 4. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª)
with st.sidebar:
    st.header("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ø·")
    persona = st.selectbox("Ø´Ø®ØµÙŠØ© Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:", ["Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§Øª", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª", "Ù…Ø­Ù„Ù„ ØªÙ‚Ù†ÙŠ"])
    model_choice = st.radio("Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["gemini-2.5-flash", "gemma-3-27b-it", "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)"])
    
    st.divider()
    st.subheader("ğŸ–¼ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ± (Vision)")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù†Ù†Ø§Ù‚Ø´Ù‡Ø§:", type=["jpg", "jpeg", "png"])
    
    st.divider()
    st.subheader("ğŸ™ï¸ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© ğŸ“¤", key='recorder')
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# 5. ÙˆØ¶Ø¹ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen)
if model_choice == "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen 3)":
    st.header("ğŸ¨ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø°ÙƒÙŠ")
    prompt = st.text_area("ØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ ØªØªØ®ÙŠÙ„Ù‡Ø§ (Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù†ØªØ§Ø¦Ø¬ Ø£ÙØ¶Ù„):")
    if st.button("Ø¥Ø¨Ø¯Ø£ Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ø±Ø³Ù… ğŸ–Œï¸"):
        if prompt:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…..."):
                try:
                    imagen = genai.ImageGenerationModel("imagen-3.0-generate-001")
                    result = imagen.generate_images(prompt=prompt, number_of_images=1)
                    st.image(result.images[0]._pil_image, caption="ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© Ù…ØµØ¹Ø¨ AI")
                except Exception as e:
                    st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ù…Ø­Ø±Ùƒ Ø§Ù„ØµÙˆØ±: {e}")
        else:
            st.warning("ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© ÙˆØµÙ Ù„Ù„ØµÙˆØ±Ø©.")

# 6. ÙˆØ¶Ø¹ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ù…ØªØ¹Ø¯Ø¯Ø© (Ù†Øµ + ØµÙˆØ±Ø© + ØµÙˆØª)
else:
    st.header(f"ğŸ’¬ Ù…Ø³Ø§Ø¹Ø¯Ùƒ Ø§Ù„Ø°ÙƒÙŠ ({model_choice})")
    
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    user_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§ Ø£Ùˆ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†...")
    current_audio_bytes = audio_record['bytes'] if audio_record else None
    
    # Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø£ÙŠ Ù†ÙˆØ¹ Ù…Ù† Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
    if user_input or current_audio_bytes or uploaded_file:
        # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù†Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ù„Ù„Ø·Ù„Ø¨
        if user_input:
            final_query = user_input
        elif current_audio_bytes:
            final_query = "Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ ÙˆØ£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø£ÙŠ ÙˆØ³Ø§Ø¦Ø· Ù…Ø±ÙÙ‚Ø©."
        else:
            final_query = "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ù…Ø§ ØªØ±Ø§Ù‡ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„ØªÙØµÙŠÙ„."

        # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„ÙˆØ§Ø¬Ù‡Ø©
        st.session_state.messages.append({"role": "user", "content": final_query})
        with st.chat_message("user"):
            st.markdown(final_query)
            if uploaded_file: st.image(uploaded_file, width=300, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©")
            if current_audio_bytes: st.audio(current_audio_bytes)

        # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ..."):
                try:
                    model = genai.GenerativeModel(model_choice)
                    
                    # Ø¨Ù†Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…ØªØ¹Ø¯Ø¯ (Multimodal List)
                    content_to_send = [f"Ø¨ØµÙØªÙƒ {persona}: {final_query}"]
                    
                    if uploaded_file:
                        content_to_send.append(Image.open(uploaded_file))
                    
                    if current_audio_bytes:
                        content_to_send.append({"mime_type": "audio/wav", "data": current_audio_bytes})
                    
                    # Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯
                    response = model.generate_content(content_to_send)
                    response_text = response.text
                    
                    # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ
                    st.markdown(response_text)
                    
                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª Ù„Ù„Ø±Ø¯
                    audio_output = speak_text(response_text)
                    if audio_output:
                        st.audio(audio_output, format='audio/mp3', autoplay=True)
                    
                    # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø³Ø¬Ù„
                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                except Exception as e:
                    st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: {e}")
