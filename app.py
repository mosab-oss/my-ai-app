import streamlit as st
import google.generativeai as genai
import os
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io
import re
import urllib.parse

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„", layout="wide", page_icon="âš¡")

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ø¨Ø´ÙƒÙ„ Ø¢Ù…Ù† Ù…Ù† Secrets
api_key = st.secrets.get("GEMINI_API_KEY") or os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("âŒ ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© GEMINI_API_KEY ÙÙŠ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Streamlit.")
    st.stop()

genai.configure(api_key=api_key)

# 2. Ø¯Ø§Ù„Ø© Ø§Ù„Ø±Ø³Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ù„Ø­Ù„ Ù…Ø´ÙƒÙ„Ø© Ø¹Ø¯Ù… Ø¸Ù‡ÙˆØ± Ø§Ù„ØµÙˆØ±)
def draw_image(description):
    encoded_desc = urllib.parse.quote(description)
    # Ù…Ø­Ø±Ùƒ Ø®Ø§Ø±Ø¬ÙŠ Ù„Ø¶Ù…Ø§Ù† ØªØ­ÙˆÙŠÙ„ Ø§Ù„ÙˆØµÙ Ø¥Ù„Ù‰ ØµÙˆØ±Ø© Ø­Ù‚ÙŠÙ‚ÙŠØ©
    return f"https://pollinations.ai/p/{encoded_desc}?width=1024&height=1024&seed=42"

# 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† ÙˆØ§Ù„ØµÙˆØ±)
with st.sidebar:
    st.header("ğŸ¨ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­ÙƒÙ…")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    st.divider()
    uploaded_file = st.file_uploader("Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„ØªØ­Ù„ÙŠÙ„Ù‡Ø§:", type=["jpg", "png", "jpeg"])
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# 4. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title("âš¡ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "img_url" in msg: st.image(msg["img_url"])

# 5. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø·Ù„Ø¨Ø§Øª
user_input = st.chat_input("Ø§Ø·Ù„Ø¨ Ø±Ø³Ù… ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹...")
current_audio = audio_record['bytes'] if audio_record else None

if user_input or current_audio or uploaded_file:
    prompt = user_input if user_input else "Ø­Ù„Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰"
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_file: st.image(uploaded_file, width=300)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨ÙˆØ§Ø³Ø·Ø© Gemini 3..."):
            # Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø§Ø³Ù… Ø§Ù„ØªÙ‚Ù†ÙŠ Ø§Ù„ØµØ­ÙŠØ­ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØµÙˆØ±ØªÙƒ Ù…Ù† AI Studio
            # Ø¬Ø±Ø¨Ù†Ø§ Pro PreviewØŒ ÙˆØ¥Ø°Ø§ ÙØ´Ù„ Ù†Ø³ØªØ®Ø¯Ù… Ø§Ù„ÙÙ„Ø§Ø´ Ø§Ù„Ù…Ø³ØªÙ‚Ø±
            model_names = ["gemini-3-pro-preview", "gemini-1.5-flash"]
            raw_text = ""
            used_model = ""
            
            for m_name in model_names:
                try:
                    model = genai.GenerativeModel(m_name)
                    contents = [prompt]
                    if uploaded_file: contents.append(Image.open(uploaded_file))
                    if current_audio: contents.append({"mime_type": "audio/wav", "data": current_audio})
                    
                    response = model.generate_content(contents)
                    raw_text = response.text
                    used_model = m_name
                    break
                except:
                    continue

            if used_model:
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø£ÙÙƒØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Thought) Ø§Ù„ØªÙŠ Ø¸Ù‡Ø±Øª ÙÙŠ ØµÙˆØ±Ùƒ (2 Ùˆ 3)
                clean_answer = re.sub(r'\{.*?\}', '', raw_text, flags=re.DOTALL)
                clean_answer = re.sub(r'thought:.*', '', clean_answer, flags=re.IGNORECASE).strip()

                # Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø³Ù… Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ Ø¹Ù†Ø¯ Ø·Ù„Ø¨ ØµÙˆØ±Ø©
                img_url = None
                if any(x in prompt for x in ["Ø§Ø±Ø³Ù…", "ØµÙˆØ±Ø©", "ØªØ®ÙŠÙ„", "draw", "image"]):
                    img_url = draw_image(prompt)
                    st.image(img_url, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ Ø±Ø³Ù…ØªÙ‡Ø§ Ù„Ùƒ")

                st.markdown(clean_answer if clean_answer else "ØªÙØ¶Ù„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„ØªÙŠ Ø·Ù„Ø¨ØªÙ‡Ø§:")
                st.caption(f"ğŸ¤– ØªÙ… Ø§Ù„Ø±Ø¯ Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ø­Ø±Ùƒ: {used_model}")
                
                # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ
                try:
                    tts = gTTS(text=clean_answer[:200] if clean_answer else "ØªÙØ¶Ù„", lang='ar')
                    audio_fp = io.BytesIO()
                    tts.write_to_fp(audio_fp)
                    st.audio(audio_fp, autoplay=True)
                except: pass
                
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
                new_msg = {"role": "assistant", "content": clean_answer}
                if img_url: new_msg["img_url"] = img_url
                st.session_state.messages.append(new_msg)
            else:
                st.error("âŒ Ù„Ù… Ù†ØªÙ…ÙƒÙ† Ù…Ù† Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„. ØªØ£ÙƒØ¯ Ù…Ù† Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API.")
