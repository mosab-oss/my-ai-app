import streamlit as st
import os
import io
import base64
from google import genai
from google.genai import types
from openai import OpenAI
from PIL import Image
import arabic_reshaper
from bidi.algorithm import get_display
import pdfplumber  # Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„ØªÙŠ Ø«Ø¨ØªÙ‡Ø§ Ø§Ù„Ø³ÙŠØ±ÙØ± Ø¨Ù†Ø¬Ø§Ø­
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder

# --- [1] Ù…Ø¬Ù„Ø³ Ø§Ù„Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ø¸Ù…Ù‰ (Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©) ---
model_map = {
    "ğŸ‡ºğŸ‡¸ Gemini 2.0 Flash (Ø§Ù„Ø¨Ø±Ù‚ Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠ)": "models/gemini-2.0-flash-exp",
    "ğŸ‡¨ğŸ‡³ DeepSeek R1 (Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„ØµÙŠÙ†ÙŠ Ø§Ù„Ø¹Ù…ÙŠÙ‚)": "deepseek/deepseek-r1",
    "ğŸ‡ªğŸ‡º Mistral Large (Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠ)": "mistralai/mistral-large",
    "ğŸ‡ºğŸ‡¸ Claude 3.5 Sonnet (Ø§Ù„Ø¯Ù‚Ø© Ø§Ù„Ø£Ù…Ø±ÙŠÙƒÙŠØ©)": "anthropic/claude-3.5-sonnet"
}

expert_map = {
    "ğŸ“œ Ø§Ù„Ø¨Ø±ÙˆÙÙŠØ³ÙˆØ± Ø§Ù„Ù„ØºÙˆÙŠ Ø§Ù„Ø¹Ø±Ø¨ÙŠ": "Ø£Ù†Øª Ù…Ø±Ø¬Ø¹ ÙÙŠ Ø§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©ØŒ ØµØº Ø§Ù„Ø±Ø¯ÙˆØ¯ Ø¨Ø£ÙØµØ­ Ø¨ÙŠØ§Ù† Ù…Ù…ÙƒÙ†.",
    "ğŸ›¡ï¸ Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø¬ÙŠÙˆØ³ÙŠØ§Ø³ÙŠ ÙˆØ¹Ø³ÙƒØ±ÙŠØŒ ØªØ­Ù„Ù„ ØªÙˆØ§Ø²Ù†Ø§Øª Ø§Ù„Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ©.",
    "ğŸ“ˆ Ø®Ø¨ÙŠØ± Ø§Ù„Ø£Ø³ÙˆØ§Ù‚ Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ù…Ø§Ù„ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù„Ø­Ø¸ÙŠ Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ ÙˆØ§Ù„Ø¨ÙˆØ±ØµØ©.",
    "ğŸ’» ÙƒØ¨ÙŠØ± Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ÙŠÙ†": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§ØªØŒ ØªÙƒØªØ´Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØµÙ…Ù… Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø°ÙƒÙŠØ©."
}

# --- [2] ÙˆØ¸Ø§Ø¦Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ---
def process_pdf(pdf_file):
    with pdfplumber.open(pdf_file) as pdf:
        return "\n".join([page.extract_text() for page in pdf.pages if page.extract_text()])

def text_to_speech(text):
    tts = gTTS(text=text, lang='ar')
    fp = io.BytesIO()
    tts.write_to_fp(fp)
    return fp

# --- [3] Ù…Ø­Ø±Ùƒ Ø§Ù„Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ø¸Ù…Ù‰ (Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ù…Ø±ÙƒØ²ÙŠ) ---
def run_alliance_engine(prompt, image=None, pdf_text=None, audio_bytes=None):
    target_model = model_map[selected_model]
    system_instr = expert_map[selected_expert]
    
    try:
        if "Gemini" in selected_model:
            client = genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
            content_list = [prompt]
            if image: content_list.append(image)
            if pdf_text: content_list.append(f"\nÙˆØ«ÙŠÙ‚Ø© PDF:\n{pdf_text}")
            if audio_bytes: content_list = [types.Part.from_bytes(data=audio_bytes, mime_type="audio/wav"), prompt]

            response = client.models.generate_content(
                model=target_model,
                contents=content_list,
                config=types.GenerateContentConfig(
                    system_instruction=system_instr,
                    tools=[types.Tool(google_search=types.GoogleSearch())] if live_search else None
                )
            )
            return response.text
        else:
            # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠØ© (Ø§Ù„ØµÙŠÙ†ÙŠØ©/Ø§Ù„Ø£ÙˆØ±ÙˆØ¨ÙŠØ©) Ø¹Ø¨Ø± OpenRouter
            client = OpenAI(base_url="https://openrouter.ai/api/v1", api_key=st.secrets["OPENROUTER_API_KEY"])
            messages = [{"role": "system", "content": system_instr}, {"role": "user", "content": prompt}]
            if pdf_text: messages[1]["content"] += f"\nØ³ÙŠØ§Ù‚ Ø§Ù„ÙˆØ«ÙŠÙ‚Ø©: {pdf_text}"
            
            res = client.chat.completions.create(model=target_model, messages=messages)
            return res.choices[0].message.content
    except Exception as e:
        return f"ğŸš¨ Ø¹Ø·Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø®ØªØ§Ø±Ø©: {str(e)}"

# --- [4] ÙˆØ§Ø¬Ù‡Ø© Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© Ø§Ù„Ø¹Ù„ÙŠØ§ ---
st.set_page_config(page_title="Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ© Ø§Ù„ØªØ­Ø§Ù„Ù 2026", layout="wide")
st.title("ğŸ›ï¸ Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ© Ø§Ù„ØªØ­Ø§Ù„Ù: Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙˆÙ‰ Ø§Ù„Ø¹Ø¸Ù…Ù‰")

with st.sidebar:
    st.header("âš™ï¸ Ù„ÙˆØ­Ø© Ø§Ù„Ø³ÙŠØ§Ø¯Ø©")
    selected_model = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬:", list(model_map.keys()))
    selected_expert = st.selectbox("Ø§Ù„Ù…Ø³ØªØ´Ø§Ø± Ø§Ù„Ù…ÙÙˆØ¶:", list(expert_map.keys()))
    live_search = st.toggle("Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù„Ø­Ø¸ÙŠ ğŸ“¡", value=True)
    speak_out = st.toggle("Ù†Ø·Ù‚ Ø§Ù„Ø±Ø¯ (Ø¹Ø±Ø¨ÙŠ) ğŸ—£ï¸", value=False)
    
    st.divider()
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ÙˆØ«ÙŠÙ‚Ø© Ø£Ùˆ ØµÙˆØ±Ø©:", type=['png', 'jpg', 'jpeg', 'pdf'])
    
    st.write("ğŸ¤ Ø§Ù„Ø£Ù…Ø± Ø§Ù„ØµÙˆØªÙŠ:")
    audio = mic_recorder(start_prompt="Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", stop_prompt="Ø¥Ø±Ø³Ø§Ù„", key='mic')

# --- [5] Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ÙˆØ§Ù„Ø¹Ø±Ø¶ ---
if prompt := st.chat_input("Ø£ØµØ¯Ø± Ø£ÙˆØ§Ù…Ø±Ùƒ Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ©..."):
    with st.chat_message("user"):
        st.markdown(prompt)
    
    with st.chat_message("assistant"):
        img = None
        pdf_txt = None
        
        if uploaded_file:
            if uploaded_file.type == "application/pdf":
                pdf_txt = process_pdf(uploaded_file)
                st.info("ğŸ“„ ØªÙ… ØªØ­Ù„ÙŠÙ„ ÙˆØ«ÙŠÙ‚Ø© Ø§Ù„Ù€ PDF Ø¨Ù†Ø¬Ø§Ø­")
            else:
                img = Image.open(uploaded_file)
                st.image(img, caption="ØªØ­Ù„ÙŠÙ„ Ø¨ØµØ±ÙŠ", width=300)

        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ­Ø¶Ø§Ø± Ø§Ù„Ø­ÙƒÙ…Ø© Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©..."):
            response = run_alliance_engine(prompt, image=img, pdf_text=pdf_txt, audio_bytes=audio['bytes'] if audio else None)
            st.markdown(response)
            
            if speak_out:
                st.audio(text_to_speech(response), format='audio/mp3')
