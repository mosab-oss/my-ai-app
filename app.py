import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI - Ø¬ÙŠÙ„ Gemini 3", page_icon="âš¡", layout="wide")

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù€ API (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙØªØ§Ø­ ÙÙŠ Ù…Ù„Ù .env Ø£Ùˆ Secrets)
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ.")
    st.stop()

genai.configure(api_key=api_key)

# 3. Ø¯Ø§Ù„Ø© ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ø¥Ù„Ù‰ ØµÙˆØª
def speak_text(text):
    try:
        clean_text = text.replace('*', '').replace('#', '')
        tts = gTTS(text=clean_text, lang='ar', slow=False)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

# 4. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Sidebar) - ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø²Ø± Ø§Ù„Ø­Ø°Ù ÙˆØ§Ù„Ø±Ø¤ÙŠØ©
with st.sidebar:
    st.title("ğŸš€ Ù„ÙˆØ­Ø© ØªØ­ÙƒÙ… Gemini 3")
    persona = st.selectbox("Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", ["Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§Øª", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª"])
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙƒÙ…Ø§ ÙŠØ¸Ù‡Ø± ÙÙŠ Ø­Ø³Ø§Ø¨Ùƒ
    model_choice = st.radio("Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø·:", ["gemini-3-flash-preview", "ğŸ¨ Ø±Ø³Ù… Ø¨Ø§Ù„Ø°ÙƒØ§Ø¡ (Imagen 4)"])
    
    st.divider()
    
    # --- Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ (Vision) ---
    st.subheader("ğŸ–¼ï¸ Ø§Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© (ÙƒÙˆØ¯ØŒ Ù†ØµØŒ Ù…Ù†Ø¸Ø±):", type=["jpg", "jpeg", "png"])
    
    st.divider()
    
    # --- Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ© ---
    st.subheader("ğŸ™ï¸ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    
    st.divider()
    
    # --- Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© (Ø§Ù„Ø°ÙŠ ÙƒÙ†Øª ØªØ¨Ø­Ø« Ø¹Ù†Ù‡) ---
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„
st.header(f"ğŸ’¬ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ø°ÙƒÙŠ (Gemini 3 Flash)")

if "messages" not in st.session_state:
    st.session_state.messages = []

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„ Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
user_input = st.chat_input("Ø¯Ø±Ø¯Ø´ Ù‡Ù†Ø§ Ø£Ùˆ Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø©...")
current_audio = audio_record['bytes'] if audio_record else None

if user_input or current_audio or uploaded_file:
    # ØµÙŠØ§ØºØ© Ø§Ù„Ø§Ø³ØªØ¹Ù„Ø§Ù…
    if user_input:
        query = user_input
    elif current_audio:
        query = "Ø­Ù„Ù„ Ø§Ù„ØµÙˆØª Ø§Ù„Ù…Ø±ÙÙ‚ ÙˆØ£Ø¬Ø¨ Ø¹Ù„ÙŠÙ‡."
    else:
        query = "Ø§Ø´Ø±Ø­ Ù„ÙŠ Ù…Ø§Ø°Ø§ ÙŠÙˆØ¬Ø¯ ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„ØµÙˆØ±Ø©."

    st.session_state.messages.append({"role": "user", "content": query})
    with st.chat_message("user"):
        st.markdown(query)
        if uploaded_file: st.image(uploaded_file, width=300)

    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ù…Ù† Gemini 3
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù†Ø·Ù‚..."):
            try:
                model = genai.GenerativeModel("gemini-3-flash-preview")
                content_list = [f"Ø¨ØµÙØªÙƒ {persona}: {query}"]
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„ (Vision)
                if uploaded_file:
                    content_list.append(Image.open(uploaded_file))
                
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„ØµÙˆØª Ù„Ù„ØªØ­Ù„ÙŠÙ„
                if current_audio:
                    content_list.append({"mime_type": "audio/wav", "data": current_audio})
                
                response = model.generate_content(content_list)
                st.markdown(response.text)
                
                # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ
                audio_fp = speak_text(response.text)
                if audio_fp:
                    st.audio(audio_fp, format='audio/mp3', autoplay=True)
                
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
