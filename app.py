import streamlit as st
import google.generativeai as genai
import os
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io
import re

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø©
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„", layout="wide", page_icon="âš¡")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ù…ÙØªØ§Ø­ API (ØªØ£ÙƒØ¯ Ù…Ù† ÙˆØ¬ÙˆØ¯Ù‡ ÙÙŠ Secrets)
api_key = st.secrets["GEMINI_API_KEY"] if "GEMINI_API_KEY" in st.secrets else os.getenv("GEMINI_API_KEY")
genai.configure(api_key=api_key)

# 2. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø°ÙƒÙŠØ© (Gemini 3 Flash Preview ÙƒÙ…Ø§ ÙÙŠ ØµÙˆØ±ØªÙƒ)
def smart_generate(contents):
    model_name = "gemini-3-flash-preview"
    try:
        model = genai.GenerativeModel(model_name)
        response = model.generate_content(contents)
        return response.text, model_name
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£: {e}", None

# 3. Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ (Ù„Ø¥Ø®ÙØ§Ø¡ Ø§Ù„Ù€ Thought ÙˆØ¥Ø¸Ù‡Ø§Ø± Ø§Ù„ØµÙˆØ±)
def process_response(text):
    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· Ø§Ù„ØµÙˆØ±Ø© Ø¥Ø°Ø§ ÙˆØ¬Ø¯
    img_urls = re.findall(r'(https?://\S+?\.(?:png|jpg|jpeg|gif))', text)
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ù† Ø£ÙÙƒØ§Ø± Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (Thought) ÙˆØ£ÙƒÙˆØ§Ø¯ JSON Ø§Ù„Ù…Ø²Ø¹Ø¬Ø©
    clean_text = re.sub(r'\{.*?\}', '', text, flags=re.DOTALL)
    clean_text = re.sub(r'"thought":.*?,', '', clean_text, flags=re.DOTALL)
    clean_text = clean_text.replace('"', '').replace('thought:', '').strip()
    
    return clean_text if clean_text else "ØªÙ…Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¨Ù†Ø¬Ø§Ø­.", img_urls

# 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ­ÙƒÙ… Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©)
with st.sidebar:
    st.header("ğŸ¨ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­ÙƒÙ…")
    st.subheader("ğŸ™ï¸ Ø§Ù„ØªØ³Ø¬ÙŠÙ„ Ø§Ù„ØµÙˆØªÙŠ")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    
    st.divider()
    st.subheader("ğŸ–¼ï¸ Ø±ÙØ¹ Ø§Ù„ØµÙˆØ±")
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„ØªØ­Ù„ÙŠÙ„Ù‡Ø§:", type=["jpg", "png", "jpeg"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        st.rerun()

# 5. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©
st.title("âš¡ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª (Ù†ØµØŒ ØµÙˆØªØŒ ØµÙˆØ±Ø©)
user_input = st.chat_input("Ø§Ø·Ù„Ø¨ Ø±Ø³Ù… ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ø³Ø£Ù„ Ø³Ø¤Ø§Ù„Ø§Ù‹...")
current_audio = audio_record['bytes'] if audio_record else None

if user_input or current_audio or uploaded_file:
    prompt = user_input if user_input else "Ø­Ù„Ù„ Ø§Ù„Ù…Ø±ÙÙ‚Ø§Øª Ø¨Ø¯Ù‚Ø©"
    
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_file: st.image(uploaded_file, width=300)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© Gemini 3..."):
            contents = [prompt]
            if uploaded_file: contents.append(Image.open(uploaded_file))
            if current_audio: contents.append({"mime_type": "audio/wav", "data": current_audio})
            
            raw_text, m_used = smart_generate(contents)
            
            if m_used:
                clean_text, images = process_response(raw_text)
                
                # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ÙˆÙ„Ø¯Ø© Ø¥Ù† ÙˆØ¬Ø¯Øª
                if images:
                    for img_url in images:
                        st.image(img_url, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…ÙˆÙ„Ø¯Ø©")
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ø¸ÙŠÙ
                st.markdown(clean_text)
                st.caption(f"ğŸ¤– Ø§Ù„Ù…Ø­Ø±Ùƒ: {m_used}")
                
                # Ø¥Ø¹Ø§Ø¯Ø© Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
                try:
                    tts = gTTS(text=clean_text[:250], lang='ar')
                    audio_fp = io.BytesIO()
                    tts.write_to_fp(audio_fp)
                    st.audio(audio_fp, autoplay=True)
                except: pass
                
                st.session_state.messages.append({"role": "assistant", "content": clean_text})
