import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import io, re, os, subprocess
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© (RTL) ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.11.9", layout="wide", page_icon="ğŸ¤")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    section[data-testid="stSidebar"] { direction: rtl; text-align: right; background-color: #111; }
    .stSelectbox label, .stSlider label { color: #00ffcc !important; font-weight: bold; }
    </style>
    """, unsafe_allow_html=True)

# Ø§Ù„Ø±Ø¨Ø· Ø§Ù„Ù…Ø­Ù„ÙŠ (LM Studio) ÙˆÙ…Ø­Ø±ÙƒØ§Øª Ø¬ÙˆØ¬Ù„
local_client = OpenAI(base_url="http://127.0.0.1:1234/v1", api_key="lm-studio")
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© ---
with st.sidebar:
    st.header("ğŸ® Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ… v16.11.9")
    
    st.subheader("ğŸ¤ Ø§Ù„Ù…ØºØ±ÙÙˆÙ† (Ù„Ù„ØªÙƒÙ„Ù…)")
    audio_record = mic_recorder(
        start_prompt="Ø¨Ø¯Ø¡ Ø§Ù„ØªØ³Ø¬ÙŠÙ„", 
        stop_prompt="Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª", 
        just_once=True, 
        key='sidebar_mic'
    )
    
    st.divider()

    thinking_level = st.select_slider(
        "ğŸ§  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±:", 
        options=["Low", "Medium", "High"], 
        value="High"
    )
    
    persona = st.selectbox(
        "ğŸ‘¤ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø®Ø¨ÙŠØ±:", 
        ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ† (Ø£Ù‡Ù„ Ø§Ù„Ø¹Ù„Ù…)", "Ø®Ø¨ÙŠØ± Ø§Ù„Ù„ØºØ§Øª", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ°ÙŠ", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬"]
    )
    
    st.divider()
    
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ:",
        ["DeepSeek R1 (Local)", "Gemini 2.5 Flash", "Gemini 3 Pro"]
    )
    
    uploaded_file = st.file_uploader("ğŸ“‚ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª:", type=["pdf", "csv", "txt", "jpg", "png", "jpeg"])
    
    st.divider()
    
    if st.button("ğŸ” ÙØ­Øµ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©"):
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.info("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
            st.code("\n".join(models))
        except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")

# --- 3. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
if "messages" not in st.session_state: 
    st.session_state.messages = []

# Ø¹Ø±Ø¶ ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¯Ø±Ø¯Ø´Ø©
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): 
        st.markdown(msg["content"])

# --- ÙƒÙˆØ¯ Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ø§Ù„Ù…Ø¯Ù…Ø¬ (Ø§Ù„Ù…Ø¹Ø¯Ù„ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ ØµÙˆØ±ØªÙƒ) ---
if prompt := st.chat_input("Ø§Ø³Ø£Ù„ Ø°ÙƒØ§Ø¡Ùƒ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ Ø§Ù„Ù…Ø­Ù„ÙŠ..."):
    # Ø¥Ø¶Ø§ÙØ© Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ù„Ù„ØªØ§Ø±ÙŠØ® ÙˆØ§Ù„Ø¹Ø±Ø¶
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø­Ù„ÙŠ
    with st.chat_message("assistant"):
        try:
            stream = local_client.chat.completions.create(
                # ØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø§Ø³Ù… Ù‡Ù†Ø§ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù€ Identifier ÙÙŠ ØµÙˆØ±ØªÙƒ
                model="deepseek-r1-distill-qwen-1.5b",
                messages=[{"role": "user", "content": prompt}],
                stream=True
            )
            # Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø¯ Ø£Ø«Ù†Ø§Ø¡ ØªØ¯ÙÙ‚Ù‡ (Streaming)
            answer = st.write_stream(stream)
            
            # Ø­ÙØ¸ Ø±Ø¯ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ ÙÙŠ Ø§Ù„ØªØ§Ø±ÙŠØ®
            st.session_state.messages.append({"role": "assistant", "content": answer})
            
        except Exception as e:
            st.error(f"ØªØ£ÙƒØ¯ Ù…Ù† ØªØ´ØºÙŠÙ„ Ø§Ù„Ø®Ø§Ø¯Ù… ÙˆØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙÙŠ LM Studio. Ø§Ù„Ø®Ø·Ø£: {e}")
