import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, time, json, pandas as pd
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 
from PIL import Image

# --- 1. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø³Ø¬Ù„ ---
def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r", encoding="utf-8") as f: return json.load(f)
    return []

def save_history(messages):
    with open("history.json", "w", encoding="utf-8") as f: 
        json.dump(messages, f, ensure_ascii=False, indent=4)

st.set_page_config(page_title="ØªØ­Ø§Ù„Ù Ù…ØµØ¹Ø¨ v16.46.15 - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù…Ø«Ø¨ØªØ©", layout="wide", page_icon="ğŸ›¡ï¸")

# --- 2. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ø¬Ù…Ø§Ù„ÙŠØ§Øª ---
st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; background-color: #0e1117; color: white; }
    [data-testid="stSidebar"] { background-color: #000c18; border-left: 2px solid #00d4ff; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: monospace; }
    .stButton>button { width: 100%; border-radius: 5px; }
    </style>
    """, unsafe_allow_html=True)

KEYS = {
    "GEMINI": st.secrets.get("GEMINI_API_KEY"),
    "ERNIE": st.secrets.get("ERNIE_API_KEY"),
    "KIMI": st.secrets.get("KIMI_API_KEY")
}

# --- 3. Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙˆØ¬Ù‡ (Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ù…Ø«Ø¨ØªØ©) ---
MODELS_GRID = [
    "gemini-2.5-flash", 
    "gemini-2.0-flash",
    "gemini-3-pro-preview", 
    "gemma-3-27b", 
    "deepseek-r1", 
    "ernie-5.0", 
    "kimi-latest"
]

def get_super_response(engine, user_input, persona_type, image=None, use_search=False):
    client_gem = genai.Client(api_key=KEYS["GEMINI"])
    persona_desc = f"Ø£Ù†Øª {persona_type}. Ø±Ø¯ Ø¹Ù„Ù‰ Ù…ØµØ¹Ø¨ Ø¨Ø¯Ù‚Ø© ÙˆØ§Ø­ØªØ±Ø§ÙÙŠØ©."
    
    try:
        # Ø¹Ø§Ø¦Ù„Ø© Ø¬ÙˆØ¬Ù„
        if "gemini" in engine or "gemma" in engine:
            search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None
            config = types.GenerateContentConfig(system_instruction=persona_desc, tools=search_tool)
            contents = [user_input]
            if image: contents.append(image)
            return client_gem.models.generate_content(model=engine, contents=contents, config=config).text
        
        # Ù…Ø­Ø±Ùƒ Ernie 5.0
        elif engine == "ernie-5.0":
            c = OpenAI(api_key=KEYS["ERNIE"], base_url="https://api.baidu.com/v1")
            r = c.chat.completions.create(model="ernie-5.0", messages=[{"role": "system", "content": persona_desc}, {"role": "user", "content": user_input}])
            return r.choices[0].message.content
            
        # Ù…Ø­Ø±Ùƒ Kimi
        elif engine == "kimi-latest":
            c = OpenAI(api_key=KEYS["KIMI"], base_url="https://api.moonshot.cn/v1")
            r = c.chat.completions.create(model="moonshot-v1-8k", messages=[{"role": "system", "content": persona_desc}, {"role": "user", "content": user_input}])
            return r.choices[0].message.content

        # Ù…Ø­Ø±Ùƒ DeepSeek R1 (Ù…Ø­Ù„ÙŠ Ø£Ùˆ Ø¹Ø¨Ø± API)
        elif engine == "deepseek-r1":
            c = OpenAI(api_key="sk-xxx", base_url="https://api.deepseek.com") # Ø£Ùˆ Ø±Ø§Ø¨Ø· LM Studio
            r = c.chat.completions.create(model="deepseek-reasoner", messages=[{"role": "user", "content": user_input}])
            return r.choices[0].message.content
            
    except Exception as e: return f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ù…Ø­Ø±Ùƒ {engine}: {str(e)}"

# --- 4. Ø§Ù„Ø±Ø§Ø¯Ø§Ø± v16.46.15 ---
def run_and_autofix(text, engine, persona):
    clean_txt = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    code_match = re.search(r'```python(.*?)```', text, flags=re.DOTALL)
    exec_out = ""
    if code_match:
        code = code_match.group(1).strip()
        fname = "auto_script.py"
        full_path = os.path.abspath(fname)
        with open(fname, "w", encoding="utf-8") as f: f.write(code)
        res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=30)
        exec_out = f"ğŸ“‚ **Ø§Ù„Ù…Ø¬Ù„Ø¯:** `{os.getcwd()}`\nğŸ“œ **Ø§Ù„Ø±Ø§Ø¯Ø§Ø±:** `{full_path}`\n\n"
        exec_out += f"ğŸ–¥ï¸ **Ø§Ù„Ù†Ø§ØªØ¬:**\n{res.stdout if not res.stderr else res.stderr}"
    return clean_txt, exec_out

# --- 5. Ø´Ø±ÙŠØ· Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
if "messages" not in st.session_state: st.session_state.messages = load_history()

with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ Ø§Ù„Ù…Ø«Ø¨ØªØ©")
    audio_mic = mic_recorder(start_prompt="ğŸ¤ ØªØ­Ø¯Ø«", stop_prompt="â¹ï¸", key='v15_mic')
    
    # Ù…ÙŠØ²Ø© Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ (Ø§Ù„Ù…Ø«Ø¨ØªØ©)
    if st.button("ğŸ§¹ Ù…Ø³Ø­ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø§Øª", type="primary"):
        st.session_state.messages = []
        save_history([])
        st.rerun()

    st.divider()
    persona = st.radio("ğŸ‘¤ Ø§Ù„Ø´Ø®ØµÙŠØ© Ø§Ù„Ù†Ø´Ø·Ø©:", ["Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ ğŸ‘¨â€ğŸ«", "Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ğŸ› ï¸", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø®ØµÙŠ ğŸ¤–"])
    
    # Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ù…Ø«Ø¨ØªØ© (Ø¨Ø¯ÙˆÙ† Ù†ÙˆØ§Ù‚Øµ)
    engine_choice = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„:", MODELS_GRID)
    
    st.divider()
    uploaded_file = st.file_uploader("ğŸ“Š Ø±ÙØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø£Ùˆ ØµÙˆØ±", type=['csv', 'xlsx', 'jpg', 'png'])
    web_on = st.toggle("ğŸŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ", value=True)

# --- 6. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø­ÙˆØ§Ø± ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("Ø§Ø·Ù„Ø¨ Ø£ÙŠ Ø´ÙŠØ¡ Ù…Ù† ÙØ±ÙŠÙ‚Ùƒ Ø§Ù„Ø°ÙƒÙŠ...") or audio_mic:
    txt = prompt if isinstance(prompt, str) else "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ Ù…Ø³ØªÙ„Ù…]"
    st.session_state.messages.append({"role": "user", "content": txt})
    with st.chat_message("user"): st.markdown(txt)

    with st.chat_message("assistant"):
        img_obj = Image.open(uploaded_file) if uploaded_file and uploaded_file.type.startswith('image') else None
        raw_res = get_super_response(engine_choice, txt, persona, img_obj, web_on)
        clean_res, code_res = run_and_autofix(raw_res, engine_choice, persona)
        
        st.markdown(clean_res)
        if code_res: st.markdown(f'<div class="exec-box">{code_res}</div>', unsafe_allow_html=True)
        
        st.session_state.messages.append({"role": "assistant", "content": clean_res})
        save_history(st.session_state.messages)
        
        try:
            tts = gTTS(text=clean_res[:150], lang='ar')
            b = io.BytesIO(); tts.write_to_fp(b); st.audio(b)
        except: pass
