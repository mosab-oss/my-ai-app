import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, time, json, pandas as pd
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 
from PIL import Image

# --- 1. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø³Ø¬Ù„ ÙˆØ§Ù„Ø°Ø§ÙƒØ±Ø© (Ø§Ù„Ù…ÙŠØ²Ø© Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø© Ø³Ø§Ø¨Ù‚Ø§Ù‹) ---
def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r", encoding="utf-8") as f:
            try: return json.load(f)
            except: return []
    return []

def save_history(messages):
    with open("history.json", "w", encoding="utf-8") as f: 
        json.dump(messages, f, ensure_ascii=False, indent=4)

st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ© v16.46.19", layout="wide", page_icon="ğŸ›¡ï¸")

# --- 2. Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø³Ø¨Ø¹Ø© (Ø§Ù„Ù…Ø«Ø¨ØªØ© Ø¨Ø¯ÙˆÙ† Ù†Ù‚Øµ) ---
MODELS_GRID = {
    "gemini-2.5-flash": "gemini-2.5-flash", 
    "gemini-2.0-flash": "gemini-2.0-flash",
    "gemini-3-pro-preview": "gemini-3-pro-preview", 
    "gemma-3-27b": "gemma-3-27b", 
    "deepseek-r1": "deepseek-reasoner", 
    "ernie-5.0": "ernie-5.0", 
    "kimi-latest": "moonshot-v1-8k"
}

# --- 3. ØªØµÙ…ÙŠÙ… Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; background-color: #0e1117; color: white; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: monospace; }
    .stButton>button { width: 100%; background-color: #ff4b4b; color: white; } /* Ø³ØªØ§ÙŠÙ„ Ø²Ø± Ø§Ù„Ù…Ø³Ø­ */
    </style>
    """, unsafe_allow_html=True)

KEYS = {
    "GEMINI": st.secrets.get("GEMINI_API_KEY"),
    "ERNIE": st.secrets.get("ERNIE_API_KEY"),
    "KIMI": st.secrets.get("KIMI_API_KEY")
}

# --- 4. Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙˆØ¬Ù‡ (Ø§Ù„Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠ Ù„ÙƒÙ„ Ù…Ø­Ø±Ùƒ) ---
def get_super_response(engine, user_input, persona, image=None, use_search=False):
    client_gem = genai.Client(api_key=KEYS["GEMINI"])
    p_desc = f"Ø£Ù†Øª {persona}. Ø±Ø¯ Ø¹Ù„Ù‰ Ù…ØµØ¹Ø¨ Ø¨Ø¯Ù‚Ø©."
    
    try:
        # ØªØ´ØºÙŠÙ„ Ø¹Ø§Ø¦Ù„Ø© Gemini Ùˆ Gemma
        if "gemini" in engine or "gemma" in engine:
            search = [types.Tool(google_search=types.GoogleSearch())] if use_search else None
            config = types.GenerateContentConfig(system_instruction=p_desc, tools=search)
            contents = [user_input]
            if image: contents.append(image)
            return client_gem.models.generate_content(model=engine, contents=contents, config=config).text
        
        # ØªØ´ØºÙŠÙ„ Ù…Ø­Ø±Ùƒ Ernie
        elif engine == "ernie-5.0":
            c = OpenAI(api_key=KEYS["ERNIE"], base_url="https://api.baidu.com/v1")
            r = c.chat.completions.create(model=engine, messages=[{"role": "user", "content": user_input}])
            return r.choices[0].message.content
            
        # ØªØ´ØºÙŠÙ„ Ù…Ø­Ø±Ùƒ Kimi
        elif engine == "kimi-latest":
            c = OpenAI(api_key=KEYS["KIMI"], base_url="https://api.moonshot.cn/v1")
            r = c.chat.completions.create(model="moonshot-v1-8k", messages=[{"role": "user", "content": user_input}])
            return r.choices[0].message.content
    except Exception as e: return f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ {engine}: {str(e)}"

# --- 5. Ø´Ø±ÙŠØ· Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„Ø²Ø± Ø§Ù„Ù…ÙÙ‚ÙˆØ¯ ---
if "messages" not in st.session_state: st.session_state.messages = load_history()

with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª")
    
    # Ù…ÙŠØ²Ø© Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ (Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ø¶Ø¨Ø· Ø§Ù„Ù…ØµÙ†Ø¹ÙŠ)
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ ÙˆØªØµÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        if os.path.exists("history.json"): os.remove("history.json")
        st.session_state.messages = []
        st.success("ØªÙ… Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ Ø¨Ù†Ø¬Ø§Ø­!")
        st.rerun()
        
    st.divider()
    persona_choice = st.radio("ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ø±ÙˆØ­:", ["Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ ğŸ‘¨â€ğŸ«", "Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ğŸ› ï¸", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø®ØµÙŠ ğŸ¤–"])
    engine_choice = st.selectbox("ğŸ¯ Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù†Ø´Ø·:", list(MODELS_GRID.keys()))
    web_on = st.toggle("ğŸŒ Ø¨Ø­Ø« Ø¥Ù†ØªØ±Ù†Øª", value=True)
    uploaded_file = st.file_uploader("ğŸ“Š Ø±ÙØ¹ (CSV/Images)", type=['csv', 'png', 'jpg'])

# --- 6. Ø§Ù„Ø±Ø§Ø¯Ø§Ø± ÙˆØ§Ù„Ø¹Ø±Ø¶ ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("Ø£Ù…Ø±Ùƒ ÙŠØ§ Ù…ØµØ¹Ø¨...") or mic_recorder(start_prompt="ğŸ¤", stop_prompt="â¹ï¸", key='v19_mic'):
    u_txt = prompt if isinstance(prompt, str) else "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ]"
    st.session_state.messages.append({"role": "user", "content": u_txt})
    with st.chat_message("user"): st.markdown(u_txt)

    with st.chat_message("assistant"):
        img = Image.open(uploaded_file) if uploaded_file and uploaded_file.type.startswith('image') else None
        res = get_super_response(engine_choice, u_txt, persona_choice, img, web_on)
        st.markdown(res)
        
        # Ø§Ù„Ø±Ø§Ø¯Ø§Ø± (ÙƒØ´Ù Ø§Ù„Ù…Ø³Ø§Ø± Ø§Ù„Ù…Ø·Ù„Ù‚)
        code_match = re.search(r'```python(.*?)```', res, flags=re.DOTALL)
        if code_match:
            with open("script.py", "w", encoding="utf-8") as f: f.write(code_match.group(1).strip())
            st.markdown(f'<div class="exec-box">ğŸ“‚ Ø§Ù„Ø±Ø§Ø¯Ø§Ø±: {os.path.abspath("script.py")}</div>', unsafe_allow_html=True)

        st.session_state.messages.append({"role": "assistant", "content": res})
        save_history(st.session_state.messages)
