import streamlit as st
import google.generativeai as genai
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io, urllib.parse, re, json
from PIL import Image

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù…Ù†ØµØ© Ø§Ù„Ø´Ø§Ù…Ù„Ø© V12.4 - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù…ØµØ¹Ø¨
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© V12.4", layout="wide", page_icon="ğŸ“")

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØªØ§Ø­ Ø§Ù„Ø³Ø±ÙŠ Ù…Ù† Secrets
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)
else:
    st.error("âš ï¸ Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Secrets!")
    st.stop()

# --- Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ù…Ø³ØªÙ‚Ø± (ÙŠÙ…Ù†Ø¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…ÙƒØ³ÙˆØ±Ø©) ---
def draw_image_logic(query):
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø·Ù„Ø¨ ÙˆØ£Ø®Ø° Ø£ÙˆÙ„ 60 Ø­Ø±Ù Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ‚Ø±Ø§Ø± Ø§Ù„Ø±Ø§Ø¨Ø·
    clean_prompt = re.sub(r'[^\w\s]', '', query)[:60]
    encoded = urllib.parse.quote(clean_prompt)
    return f"https://pollinations.ai/p/{encoded}?width=1024&height=1024&seed=123"

# --- Ø¯Ø§Ù„Ø© Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø¹ Ø¯Ø¹Ù… Ø§Ù„Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ÙŠØ¯ÙˆÙŠ ÙˆØ§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ ---
def generate_response(contents, selected_model):
    model_map = {
        "Gemini 2.5 Flash (Ø§Ù„Ø£Ø³Ø±Ø¹)": "gemini-2.5-flash-exp",
        "Gemini 3 Pro (Ø§Ù„Ø£Ø°ÙƒÙ‰)": "gemini-3-pro-preview",
        "Gemma 3 27B (Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚)": "gemma-3-27b-it"
    }
    
    if selected_model != "ØªØ¨Ø¯ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø°ÙƒÙŠ)":
        try:
            model_id = model_map[selected_model]
            model = genai.GenerativeModel(model_id)
            response = model.generate_content(contents)
            return response.text, selected_model
        except:
            st.warning(f"âš ï¸ {selected_model} ØºÙŠØ± Ù…ØªØ§Ø­ØŒ Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ù„Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ...")
    
    # Ù†Ø¸Ø§Ù… Ø§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ (Fallback)
    auto_models = ["gemini-2.5-flash-exp", "gemini-3-pro-preview", "gemma-3-27b-it"]
    for m_id in auto_models:
        try:
            model = genai.GenerativeModel(m_id)
            response = model.generate_content(contents)
            if response.text: return response.text, f"ØªÙ„Ù‚Ø§Ø¦ÙŠ ({m_id})"
        except: continue
    return "Ù„Ø§ ÙŠÙˆØ¬Ø¯ Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ù† Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø­Ø§Ù„ÙŠØ§Ù‹.", None

# 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (Ø§Ù„Ø£Ø¯ÙˆØ§Øª ÙˆØ§Ù„ØªØ­ÙƒÙ…)
with st.sidebar:
    st.title("ğŸ’ ØªØ­ÙƒÙ… Ù…ØµØ¹Ø¨ Ø§Ù„Ø´Ø§Ù…Ù„")
    
    # Ù…ÙŠØ²Ø© Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ (ÙŠØ¯ÙˆÙŠ/ØªÙ„Ù‚Ø§Ø¦ÙŠ)
    selected_engine = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ:", [
        "ØªØ¨Ø¯ÙŠÙ„ ØªÙ„Ù‚Ø§Ø¦ÙŠ (Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø°ÙƒÙŠ)",
        "Gemini 2.5 Flash (Ø§Ù„Ø£Ø³Ø±Ø¹)",
        "Gemini 3 Pro (Ø§Ù„Ø£Ø°ÙƒÙ‰)",
        "Gemma 3 27B (Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ù†Ø·Ù‚)"
    ])
    
    st.divider()
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„ØªØ®ØµØµ
    persona = st.selectbox("ğŸ‘¤ Ø§Ù„ØªØ®ØµØµ:", ["Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ù…Ø­ØªØ±Ù", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø© Ubuntu", "Ù…ØµÙ…Ù… ØµÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ", "Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…"])
    
    persona_instr = {
        "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ù…Ø­ØªØ±Ù": "Ø£Ù†Øª Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª Ø®Ø¨ÙŠØ±. ØµØ­Ø­ Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ØŒ Ø§Ø´Ø±Ø­ Ø§Ù„Ù‚ÙˆØ§Ø¹Ø¯ØŒ ÙˆØ§Ù†Ø·Ù‚ Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø¨ÙˆØ¶ÙˆØ­ ØªØ§Ù….",
        "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬Ø© Ubuntu": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù„ÙŠÙ†ÙƒØ³ ÙˆØ¨Ø±Ù…Ø¬Ø©. Ù‚Ø¯Ù… Ø­Ù„ÙˆÙ„Ø§Ù‹ Ø¨Ø±Ù…Ø¬ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø© Ù„Ø¬Ù‡Ø§Ø² HP Ø§Ù„Ø®Ø§Øµ Ø¨Ù…ØµØ¹Ø¨.",
        "Ù…ØµÙ…Ù… ØµÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ": "Ø£Ù†Øª ÙÙ†Ø§Ù† Ø±Ù‚Ù…ÙŠ Ø¨ØµØ±ÙŠØŒ Ù‚Ø¯Ù… Ø£ÙˆØµØ§ÙØ§Ù‹ Ø®ÙŠØ§Ù„ÙŠØ© Ù„Ù„ØµÙˆØ±.",
        "Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…": "Ø£Ù†Øª Ù…Ø³Ø§Ø¹Ø¯ Ø°ÙƒÙŠ Ø´Ø§Ù…Ù„."
    }

    st.divider()
    # Ø§Ù„Ù…Ø§ÙŠÙƒ ÙˆØ±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª Ù„Ù„ØªØ­Ù„ÙŠÙ„
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    uploaded_image = st.file_uploader("Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù„ØªØ­Ù„ÙŠÙ„:", type=['jpg', 'png', 'jpeg'])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []; st.rerun()

# 3. Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ØªØ§Ø±ÙŠØ®ÙŠØ©
if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "img" in msg and msg["img"]: st.image(msg["img"])

# 4. Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ (Ø§Ù„ØªÙ†ÙÙŠØ°)
user_query = st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ù…Ø¯Ø±Ø³ÙƒØŒ Ø§Ø·Ù„Ø¨ ÙƒÙˆØ¯Ø§Ù‹ØŒ Ø£Ùˆ Ø§Ø·Ù„Ø¨ Ø±Ø³Ù…Ø§Ù‹...")

if user_query or (audio_record and audio_record['bytes']) or uploaded_image:
    prompt = user_query if user_query else "Ø­Ù„Ù„ Ù‡Ø°Ø§ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙ‚"
    with st.chat_message("user"): st.markdown(prompt)
    
    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„ØªÙˆÙ„ÙŠØ¯..."):
            # ØªØ¬Ù‡ÙŠØ² Ø§Ù„Ù…Ø­ØªÙˆÙ‰ (Ù†Øµ + ØªØ¹Ù„ÙŠÙ…Ø§Øª + ØµÙˆØ±Ø©)
            content_list = [f"Ø¨ØµÙØªÙƒ {persona}ØŒ Ù†ÙØ° Ø§Ù„Ø¢ØªÙŠ: {prompt}"]
            if uploaded_image: content_list.append(Image.open(uploaded_image))
            
            # Ø¬Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø®ØªØ§Ø±
            ai_text, active_name = generate_response(content_list, selected_engine)
            
            if ai_text:
                # Ø£- ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…)
                img_url = None
                if any(w in prompt for w in ["Ø§Ø±Ø³Ù…", "ØµÙˆØ±Ø©", "ØªØ®ÙŠÙ„"]) or persona == "Ù…ØµÙ…Ù… ØµÙˆØ± Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ":
                    img_url = draw_image_logic(prompt)
                    st.image(img_url, caption="Ø§Ù„Ù„ÙˆØ­Ø© Ø§Ù„ÙÙ†ÙŠØ© Ø§Ù„Ù†Ø§ØªØ¬Ø©")
                
                # Ø¨- Ø¹Ø±Ø¶ Ø§Ù„Ù†Øµ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ
                st.markdown(ai_text)
                st.caption(f"ğŸš€ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø·: {active_name}")
                
                # Ø¬- Ø²Ø± Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ù…Ø·ÙˆÙ‘Ø± (Ù†Ø³Ø®Ø© V12.4 Ø§Ù„Ù‚ÙˆÙŠØ©)
                try:
                    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø¹Ù„Ø§Ù…Ø§Øª Ø§Ù„ØªØ±Ù‚ÙŠÙ… Ù„Ù€ 2000 Ø­Ø±Ù
                    clean_voice_text = re.sub(r'[^\w\s.,!?]', '', ai_text)
                    text_to_read = clean_voice_text[:2000] # Ø§Ù„Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© Ø­ØªÙ‰ 2000 Ø­Ø±Ù
                    
                    # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù„ØºØ© ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹ (Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© Ù„Ù‡Ø§ Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©)
                    lang_code = 'en' if re.search(r'[a-zA-Z]', text_to_read) else 'ar'
                    
                    # ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª MP3
                    tts = gTTS(text=text_to_read, lang=lang_code, slow=False)
                    audio_io = io.BytesIO()
                    tts.write_to_fp(audio_io)
                    
                    # Ø¹Ø±Ø¶ Ù…Ø´ØºÙ„ Ø§Ù„ØµÙˆØª Ù„Ù…ØµØ¹Ø¨
                    st.audio(audio_io, format='audio/mp3')
                    st.caption(f"ğŸ”Š Ù†Ø·Ù‚ {lang_code} (ÙŠÙ‚Ø±Ø£ Ø­ØªÙ‰ 2000 Ø­Ø±Ù)")
                except Exception as e:
                    pass # Ø¶Ù…Ø§Ù† Ø¹Ø¯Ù… ØªÙˆÙ‚Ù Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø¥Ø°Ø§ ÙØ´Ù„ Ø§Ù„ØµÙˆØª
                
                # Ø­ÙØ¸ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªÙ…Ø±Ø§Ø±ÙŠØ© Ø§Ù„Ø­ÙˆØ§Ø±
                st.session_state.messages.append({"role": "assistant", "content": ai_text, "img": img_url})
