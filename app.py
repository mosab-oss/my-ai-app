import streamlit as st
# Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø§Ù„Ø¬Ø¯ÙŠØ¯Ø© Ù„Ø¯Ø¹Ù… Gemini 3 ÙˆØ§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù‚ØµÙˆÙ‰
from google import genai
from google.genai import types
import io, re, os, subprocess, time
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© (RTL) ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.17.5", layout="wide", page_icon="ğŸ’")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    [data-testid="stSidebar"] { background-color: #001529; direction: rtl; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: monospace; }
    .stChatFloatingInputContainer { direction: rtl; }
    </style>
    """, unsafe_allow_html=True)

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØªØ§Ø­ Ù…Ù† Secrets
API_KEY = st.secrets.get("GEMINI_API_KEY")

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„Ø°ÙƒÙŠ Ù„Ù„Ø£ÙƒÙˆØ§Ø¯ (Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ v16.14.5) ---
def execute_logic(text):
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø¯ Ù…Ù† ÙˆØ³ÙˆÙ… Ø§Ù„ØªÙÙƒÙŠØ±
    display_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù†Ù…Ø· Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù SAVE_FILE: name | content={}
    file_pattern = r'SAVE_FILE:\s*([\w\.-]+)\s*\|\s*content=\{(.*?)\}'
    match = re.search(file_pattern, text, flags=re.DOTALL)
    
    exec_output = ""
    if match:
        fname, fcontent = match.group(1).strip(), match.group(2).strip()
        fcontent = re.sub(r'```python|```', '', fcontent).strip()
        try:
            with open(fname, 'w', encoding='utf-8') as f: f.write(fcontent)
            if fname.endswith('.py'):
                # ØªÙ†ÙÙŠØ° Ø§Ù„ÙƒÙˆØ¯ ÙˆØ¬Ù„Ø¨ Ø§Ù„Ù†ØªÙŠØ¬Ø©
                res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=10)
                exec_output = f"ğŸ–¥ï¸ Ù†Ø§ØªØ¬ Ø§Ù„ØªÙ†ÙÙŠØ°:\n{res.stdout}\n{res.stderr}"
            else:
                exec_output = f"âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù: {fname}"
        except Exception as e: exec_output = f"âŒ Ø®Ø·Ø£ Ø¨Ø±Ù…ÙŠ: {e}"
    return display_text, exec_output

# --- 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (ÙƒÙ„ Ø§Ù„Ù…ÙŠØ²Ø§Øª + Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ù„Ø³Ø¯Ø§Ø³ÙŠ) ---
with st.sidebar:
    st.title("ğŸ® Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© v16.17.5")
    
    # Ø£. Ø§Ù„Ù…ØºØ±ÙÙˆÙ†
    st.subheader("ğŸ¤ Ø§Ù„Ù…ØºØ±ÙÙˆÙ†")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†", stop_prompt="Ø¥Ø±Ø³Ø§Ù„", key='v17_mic')
    
    st.divider()

    # Ø¨. Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª (ØªØ´Ù…Ù„ Gemini 3 Ùˆ Kimi Ùˆ ERNIE)
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø·:", 
        ["gemini-3-pro-preview", "gemini-3-flash", "gemini-2.0-flash", "deepseek-r1", "kimi-latest", "ernie-4.0"]
    )

    # Ø¬. Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„Ø´Ø®ØµÙŠØ© (ØªØ´Ù…Ù„ Ù…Ø¯Ø±Ø³ Ø§Ù„Ù„ØºØ©)
    thinking_level = st.select_slider("ğŸ§  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±:", ["Low", "Medium", "High"], value="High")
    persona = st.selectbox(
        "ğŸ‘¤ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø®Ø¨ÙŠØ±:", 
        ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ†", "Ù…Ø¯Ø±Ø³ Ø§Ù„Ù„ØºØ© (ØªØ±Ø¬Ù…Ø© ÙˆØªØ¹Ù„ÙŠÙ…)", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ°"]
    )

    st.divider()
    
    # Ø¯. Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª ÙˆØ£Ø¯ÙˆØ§Øª Ø§Ù„ØµÙŠØ§Ù†Ø©
    uploaded_file = st.file_uploader("ğŸ“‚ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª:", type=["pdf", "txt", "py", "png", "jpg"])
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("ğŸ” ÙØ­Øµ Ø³Ø±ÙŠØ¹"):
            try:
                client = genai.Client(api_key=API_KEY)
                client.models.get(model=engine_choice)
                st.toast("âœ… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø¬Ø§Ù‡Ø²!")
            except: st.toast("âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„")
    with col2:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©", type="primary"):
            st.session_state.messages = []
            st.rerun()

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© ---
if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

prompt = st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ...")

# ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ (Ù†ØµÙŠ Ø£Ùˆ ØµÙˆØªÙŠ)
if prompt or audio_record:
    user_txt = prompt if prompt else "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ Ø¹Ø¨Ø± Ø§Ù„Ù…ØºØ±ÙÙˆÙ†]"
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"): st.markdown(user_txt)

    with st.chat_message("assistant"):
        try:
            client = genai.Client(api_key=API_KEY)
            
            # ØµÙŠØ§ØºØ© Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø´Ø®ØµÙŠØ© ÙˆÙ…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±
            instruction = f"Ø¨ØµÙØªÙƒ {persona} ÙˆØªØ¹Ù…Ù„ Ø¨Ù…Ø³ØªÙˆÙ‰ ØªÙÙƒÙŠØ± {thinking_level}. Ø¥Ø°Ø§ Ø·Ù„Ø¨ Ù…Ù†Ùƒ ÙƒÙˆØ¯ Ø§Ø³ØªØ®Ø¯Ù… SAVE_FILE: name | content={{}}."
            
            # Ø·Ù„Ø¨ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ù…Ø­Ø±Ùƒ
            response = client.models.generate_content(
                model=engine_choice,
                contents=user_txt,
                config=types.GenerateContentConfig(system_instruction=instruction)
            )
            
            # Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©: ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†Øµ + ØªÙ†ÙÙŠØ° Ø§Ù„Ø£ÙƒÙˆØ§Ø¯
            clean_txt, exec_res = execute_logic(response.text)
            st.markdown(clean_txt)
            
            if exec_res:
                st.markdown(f'<div class="exec-box">{exec_res}</div>', unsafe_allow_html=True)

            # Ù‡Ù€. Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµÙˆØªÙŠ (Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ v16.14.5)
            tts = gTTS(text=clean_txt[:250], lang='ar')
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            st.audio(audio_fp, format='audio/mp3')

            st.session_state.messages.append({"role": "assistant", "content": clean_txt})
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
