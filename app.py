import streamlit as st
import os
import time
import io
import base64
from google import genai
from google.genai import types
from openai import OpenAI  # Ù„Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ DeepSeek
from PIL import Image

# --- [1] Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ù„ÙƒÙŠØ© (Ø§Ù„ÙˆØ¶Ø¹ Ø§Ù„Ø¯Ø§ÙƒÙ† Ø§Ù„ÙØ§Ø®Ø±) ---
st.set_page_config(page_title="Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ© Ø§Ù„ØªØ­Ø§Ù„Ù 2026", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #050505 !important; color: #FFFFFF !important; direction: rtl; }
    .stMarkdown p, .stMarkdown h1, .stMarkdown h2 { color: #FFFFFF !important; }
    .stChatMessage { background-color: #1a1a1a !important; border-right: 5px solid #007bff !important; border-radius: 12px; }
    .stDownloadButton button { background-color: #28a745 !important; color: white !important; width: 100%; border-radius: 20px; }
    </style>
    """, unsafe_allow_html=True)

# --- [2] Ø£Ø³Ø·ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…Ø·ÙˆØ± (Ø¥Ø¶Ø§ÙØ© DeepSeek R1) ---
model_map = {
    "ğŸ§  DeepSeek R1 (Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªØ¯Ù„Ø§Ù„ Ø§Ù„Ø¹Ù…ÙŠÙ‚)": "deepseek-reasoner", # Ù‡Ø°Ø§ Ù‡Ùˆ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨
    "ğŸ“ˆ Gemini 2.5 Pro (Ø§Ù„Ù‚ÙˆØ© Ø§Ù„Ù…ØªÙˆØ§Ø²Ù†Ø©)": "gemini-2.5-pro",
    "ğŸš€ Gemini 3 Flash (Ø§Ù„Ø³Ø±Ø¹Ø© Ø§Ù„Ù‚ØµÙˆÙ‰)": "gemini-3-flash-preview",
    "ğŸ›¡ï¸ Gemini 3 Pro (Ø§Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ)": "gemini-3-pro-preview",
    "ğŸ“¡ Gemini 1.5 Flash (Ø§Ù„Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ù…Ø³ØªÙ‚Ø±)": "gemini-flash-latest"
}

expert_map = {
    "ğŸ“ˆ Ù…Ø­Ù„Ù„ Ø£Ø³ÙˆØ§Ù‚": "Ø£Ù†Øª Ø¨Ø±ÙˆÙÙŠØ³ÙˆØ± Ù…Ø§Ù„ÙŠ Ø¹Ø§Ù„Ù…ÙŠ. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ ÙˆØ¬ÙˆØ¨Ø§Ù‹ Ù„Ø¬Ù„Ø¨ Ø£Ø³Ø¹Ø§Ø± Ø§Ù„Ø°Ù‡Ø¨ ÙˆØ§Ù„Ø¨ÙˆØ±ØµØ© ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª Ø§Ù„Ø¢Ù†ØŒ ÙˆÙ‚Ø¯Ù… ØªØ­Ù„ÙŠÙ„Ø§Ù‹ ÙÙŠ Ø¬Ø¯Ø§ÙˆÙ„.",
    "ğŸ›¡ï¸ Ø®Ø¨ÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø¹Ø³ÙƒØ±ÙŠ ÙˆØ³ÙŠØ§Ø³ÙŠ Ø±ÙÙŠØ¹ Ø§Ù„Ù…Ø³ØªÙˆÙ‰ØŒ ØªÙ‚Ø¯Ù… Ø±Ø¤Ù‰ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠØ© ÙˆØ³ÙŠÙ†Ø§Ø±ÙŠÙˆÙ‡Ø§Øª Ù…Ø³ØªÙ‚Ø¨Ù„ÙŠØ©.",
    "âš–ï¸ Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠ Ù…Ø±Ø§Ø¬Ø¹ Ù„Ù„Ø¹Ù‚ÙˆØ¯ ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„ Ù„Ù„Ù‚ÙˆØ§Ù†ÙŠÙ† Ø§Ù„Ø¯ÙˆÙ„ÙŠØ©.",
    "ğŸ’» Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ": "Ø£Ù†Øª Ù…Ø¨Ø±Ù…Ø¬ Ø®Ø¨ÙŠØ±ØŒ ÙˆØ¸ÙŠÙØªÙƒ ÙƒØªØ§Ø¨Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù†Ø¸ÙŠÙØ© ÙˆØ­Ù„ Ø§Ù„Ù…Ø´ÙƒÙ„Ø§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©.",
    "ğŸ“§ Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø±Ø§Ø³Ù„Ø§Øª": "Ø£Ù†Øª Ø³ÙƒØ±ØªÙŠØ± ØªÙ†ÙÙŠØ°ÙŠØŒ ØªØµÙŠØº Ø§Ù„Ø®Ø·Ø§Ø¨Ø§Øª Ø§Ù„Ø±Ø³Ù…ÙŠØ© ÙˆØ§Ù„Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª Ø¨Ù„Ù‡Ø¬Ø© Ø¯Ø¨Ù„ÙˆÙ…Ø§Ø³ÙŠØ© Ø§Ø­ØªØ±Ø§ÙÙŠØ©.",
    "ğŸŒ Ø®Ø¨ÙŠØ± Ø¹Ø§Ù…": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø°ÙƒÙŠ Ù…ÙˆØ³ÙˆØ¹ÙŠØŒ ØªØ¬ÙŠØ¨ Ø¨ÙˆØ¶ÙˆØ­ ÙˆÙ„Ø¨Ø§Ù‚Ø©."
}

if "messages" not in st.session_state: st.session_state.messages = []
if "count" not in st.session_state: st.session_state.count = 0

# --- [3] Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù…Ø²Ø¯ÙˆØ¬ (Google + DeepSeek) ---
def run_empire_engine(user_input, is_voice=False, uploaded_file=None):
    try:
        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ù…Ø®ØªØ§Ø± Ù‡Ùˆ DeepSeek
        if "DeepSeek" in selected_model:
            client = OpenAI(api_key=st.secrets["DEEPSEEK_API_KEY"], base_url="https://api.deepseek.com")
            response = client.chat.completions.create(
                model="deepseek-reasoner",
                messages=[
                    {"role": "system", "content": expert_map[selected_expert]},
                    {"role": "user", "content": user_input if not is_voice else "[ØµÙˆØª ØºÙŠØ± Ù…Ø¯Ø¹ÙˆÙ… ÙÙŠ DeepSeek Ø­Ø§Ù„ÙŠØ§Ù‹]"}
                ]
            )
            st.session_state.count += 1
            return response.choices[0].message.content

        # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ù† Ø¹Ø§Ø¦Ù„Ø© Gemini
        else:
            client = genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
            search_tool = types.Tool(google_search=types.GoogleSearch())
            config = types.GenerateContentConfig(
                system_instruction=expert_map.get(selected_expert),
                tools=[search_tool] if live_search else [],
                temperature=0.7
            )
            parts = []
            if uploaded_file: parts.append(Image.open(uploaded_file))
            if is_voice:
                parts.append(types.Part.from_bytes(data=user_input['bytes'], mime_type="audio/wav"))
                parts.append(f"Ø£Ù†Øª {selected_expert}. Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ ÙÙˆØ±Ø§Ù‹.")
            else:
                parts.append(f"{user_input} (Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ Ø§Ù„Ø¢Ù†)")
            
            response = client.models.generate_content(model=model_map[selected_model], contents=parts, config=config)
            st.session_state.count += 1
            return response.text

    except Exception as e:
        return f"âŒ ØªÙ†Ø¨ÙŠÙ‡ ØªÙ‚Ù†ÙŠ: {str(e)}"

# --- [4] Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„ØªØ­ÙƒÙ… ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©")
    st.success(f"Ø§Ù„Ø·Ù„Ø¨Ø§Øª: {st.session_state.count} / 50")
    selected_model = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:", list(model_map.keys()), index=0)
    selected_expert = st.selectbox("Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ:", list(expert_map.keys()))
    live_search = st.toggle("Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ ğŸ“¡", value=True)
    up_file = st.file_uploader("Ø±ÙØ¹ ÙˆØ³Ø§Ø¦Ø·", type=['png', 'jpg', 'jpeg'])

# Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

# Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„
from streamlit_mic_recorder import mic_recorder
c1, c2 = st.columns([1, 8])
with c1:
    audio_data = mic_recorder(start_prompt="ğŸ¤", stop_prompt="ğŸ“¤", key='empire_mic_v10')
with c2:
    text_data = st.chat_input("Ø£ØµØ¯Ø± Ø£ÙˆØ§Ù…Ø±Ùƒ Ù‡Ù†Ø§...")

active_input = None
is_audio = False
if audio_data: active_input, is_audio = audio_data, True
elif text_data: active_input = text_data

if active_input:
    label = "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ]" if is_audio else active_input
    st.session_state.messages.append({"role": "user", "content": label})
    with st.chat_message("user"): st.markdown(label)
    
    with st.chat_message("assistant"):
        with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© {selected_model}..."):
            ans = run_empire_engine(active_input, is_audio, up_file)
            st.markdown(ans)
            st.session_state.messages.append({"role": "assistant", "content": ans})
            st.download_button("ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ±", ans, file_name="report.txt")
