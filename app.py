import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, time, pandas as pd
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 
from PIL import Image
import PyPDF2 # Ù…ÙƒØªØ¨Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù€ PDF

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„Ø³Ù…Ø§Øª ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.39.0", layout="wide", page_icon="ğŸ›¡ï¸")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; background-color: #0e1117; color: white; }
    [data-testid="stSidebar"] { background-color: #000c18; border-left: 2px solid #00d4ff; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: monospace; }
    .status-badge { background-color: #1a1a1a; color: #ffcc00; border: 1px solid #ffcc00; padding: 2px 10px; border-radius: 20px; font-size: 12px; }
    </style>
    """, unsafe_allow_html=True)

# Ø¬Ù„Ø¨ Ø§Ù„Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø³Ø±ÙŠØ©
GEMINI_KEY = st.secrets.get("GEMINI_API_KEY")

# --- 2. Ù…Ø­Ø±Ùƒ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ø°ÙƒÙŠ ---
def process_uploaded_file(uploaded_file):
    file_text = ""
    if uploaded_file.type == "application/pdf":
        pdf_reader = PyPDF2.PdfReader(uploaded_file)
        for page in pdf_reader.pages:
            file_text += page.extract_text() + "\n"
        return f"\n[Ù…Ø­ØªÙˆÙ‰ Ù…Ù„Ù PDF]:\n{file_text}"
    elif uploaded_file.type in ["text/csv", "application/vnd.ms-excel"]:
        df = pd.read_csv(uploaded_file) if uploaded_file.name.endswith('.csv') else pd.read_excel(uploaded_file)
        return f"\n[Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ù„Ù]:\n{df.head(10).to_string()}" # Ù†Ø±Ø³Ù„ Ø£ÙˆÙ„ 10 Ø£Ø³Ø·Ø± Ù„Ù„Ø°ÙƒØ§Ø¡ Ø§Ù„Ø§ØµØ·Ù†Ø§Ø¹ÙŠ
    return ""

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ° ÙˆØ­ÙØ¸ Ø§Ù„Ù…Ù„ÙØ§Øª ---
def run_execution_logic(text):
    clean_txt = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    file_match = re.search(r'SAVE_FILE:\s*([\w\.-]+)\s*\|\s*content=\{(.*?)\}', text, flags=re.DOTALL)
    exec_out = ""
    if file_match:
        fname, fcontent = file_match.group(1).strip(), file_match.group(2).strip()
        fcontent = re.sub(r'```python|```', '', fcontent).strip()
        try:
            with open(fname, 'w', encoding='utf-8') as f: f.write(fcontent)
            if fname.endswith('.py'):
                res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=10)
                exec_out = f"ğŸ–¥ï¸ Ù†Ø§ØªØ¬ ØªÙ†ÙÙŠØ° ÙƒÙˆØ¯ {fname}:\n{res.stdout}\n{res.stderr}"
        except Exception as e: exec_out = f"âŒ Ø®Ø·Ø£ ØªÙ†ÙÙŠØ°: {e}"
    return clean_txt, exec_out

# --- 4. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ø´Ø§Ù…Ù„Ø© ---
def get_super_response(engine, user_input, persona, image=None, use_search=False, context_text=""):
    client = genai.Client(api_key=GEMINI_KEY)
    search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None
    
    # Ø¯Ù…Ø¬ Ø³ÙŠØ§Ù‚ Ø§Ù„Ù…Ù„ÙØ§Øª Ù…Ø¹ Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…
    full_prompt = f"{user_input}\n{context_text}" if context_text else user_input

    try:
        contents = [full_prompt]
        if image: contents.append(image)
        config = types.GenerateContentConfig(
            system_instruction=f"Ø£Ù†Øª {persona}. Ø­Ù„Ù„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…Ø±ÙÙ‚Ø© Ø¨Ø¯Ù‚Ø©.",
            tools=search_tool
        )
        # ØªØµØ­ÙŠØ­ Ù…Ø³Ù…Ù‰ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù„Ø¶Ù…Ø§Ù† Ø§Ù„Ø¹Ù…Ù„
        target_model = engine if "gemini" in engine else "gemini-2.0-flash"
        r = client.models.generate_content(model=target_model, contents=contents, config=config)
        return r.text
    except Exception as e:
        return f"âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ Ù…ØµØ¹Ø¨ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"

# --- 5. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ ØªØ­Ø§Ù„Ù Ù…ØµØ¹Ø¨ v16.39")
    audio = mic_recorder(start_prompt="ğŸ¤ ØªØ­Ø¯Ø«", stop_prompt="Ø¥Ø±Ø³Ø§Ù„", key='v39_mic')
    st.divider()
    
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù…ÙÙƒØ±:", 
        ["gemini-2.0-flash", "gemini-2.0-pro-exp-02-05", "deepseek-r1"]
    )
    
    persona = st.selectbox("ğŸ‘¤ Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ù…Ø­Ù„Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø®Ø¨ÙŠØ±", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª"])
    web_on = st.toggle("ğŸŒ Ø¨Ø­Ø« Ø¥Ù†ØªØ±Ù†Øª Ù…Ø¨Ø§Ø´Ø±")
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ (Image, PDF, CSV):", type=['jpg', 'png', 'pdf', 'csv', 'xlsx'])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„", type="primary"):
        st.session_state.messages = []; st.rerun()

# --- 6. Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„ØªÙ†ÙÙŠØ° ---
if "messages" not in st.session_state: st.session_state.messages = []
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Ù†Ø¸Ø§Ù…Ùƒ...") or audio:
    txt = prompt if prompt else "ğŸ¤ [Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©]"
    st.session_state.messages.append({"role": "user", "content": txt})
    with st.chat_message("user"): st.markdown(txt)

    with st.chat_message("assistant"):
        img_obj = None
        context_text = ""
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…Ø±ÙÙˆØ¹Ø©
        if uploaded_file:
            if uploaded_file.type.startswith('image'):
                img_obj = Image.open(uploaded_file)
                st.markdown('<span class="status-badge">ğŸ‘ï¸ ØªÙ… Ø±ØµØ¯ ØµÙˆØ±Ø©...</span>', unsafe_allow_html=True)
            else:
                with st.spinner("â³ Ø¬Ø§Ø±ÙŠ Ù‚Ø±Ø§Ø¡Ø© Ø§Ù„Ù…Ù„Ù ÙˆØ§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª..."):
                    context_text = process_uploaded_file(uploaded_file)
                    st.markdown('<span class="status-badge">ğŸ“„ ØªÙ… ØªØ­Ù„ÙŠÙ„ Ù…Ø³ØªÙ†Ø¯ Ø§Ù„Ù…Ø±ÙÙ‚</span>', unsafe_allow_html=True)

        with st.spinner("ğŸ§  Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ø±Ø¨Ø·..."):
            raw_res = get_super_response(engine_choice, txt, persona, img_obj, web_on, context_text)
        
        clean_res, code_res = run_execution_logic(raw_res)
        st.markdown(clean_res)
        
        if code_res:
            st.markdown(f'<div class="exec-box">{code_res}</div>', unsafe_allow_html=True)
        
        # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ØµÙˆØª (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        try:
            tts = gTTS(text=clean_res[:200], lang='ar')
            b = io.BytesIO(); tts.write_to_fp(b); st.audio(b)
        except: pass
        
        st.session_state.messages.append({"role": "assistant", "content": clean_res})
