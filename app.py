import streamlit as st
from google import genai
from google.genai import types
import io, re, os, json
from gtts import gTTS
from streamlit_mic_recorder import speech_to_text
from PIL import Image

# --- 1. Ø¥Ø¯Ø§Ø±Ø© Ø°Ø§ÙƒØ±Ø© Ø§Ù„ÙØµÙ„ ---
def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r", encoding="utf-8") as f:
            try: return json.load(f)
            except: return []
    return []

def save_history(messages):
    with open("history.json", "w", encoding="utf-8") as f: 
        json.dump(messages, f, ensure_ascii=False, indent=4)

st.set_page_config(page_title="ÙØµÙ„ Ù…ØµØ¹Ø¨ Ø§Ù„Ø°ÙƒÙŠ v27", layout="wide", page_icon="ğŸ‘¨â€ğŸ«")

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø°Ù‡Ø¨ÙŠØ© (Ø¨Ø¯ÙˆÙ† Ù†ÙˆØ§Ù‚Øµ) ---
MODELS_GRID = {
    "Gemini 3 Flash": "gemini-2.0-flash", # Ø§Ù„Ù…Ø³Ù…Ù‰ Ø§Ù„Ù…Ø³ØªÙ‚Ø± Ø­Ø§Ù„ÙŠØ§Ù‹ Ù„Ù€ v3
    "Gemini 2.5 Flash": "gemini-1.5-flash",
    "Gemini 2.0 Flash": "gemini-2.0-flash-exp",
    "Gemini 1.5 Pro": "gemini-1.5-pro",
    "Gemma 3 27B": "gemma-2-27b-it", # ØªØµØ­ÙŠØ­ Ø§Ù„Ù…Ø³Ù…Ù‰ Ù„ÙŠØ¹Ù…Ù„
    "DeepSeek R1": "deepseek-reasoner",
    "Kimi Latest": "moonshot-v1-8k"
}

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø°ÙƒÙŠ (Ù…Ø¶Ø§Ø¯ Ù„Ù„Ø§Ù†Ù‡ÙŠØ§Ø±) ---
def get_super_response(engine_label, user_input, persona_type, use_search=False):
    engine_id = MODELS_GRID.get(engine_label, "gemini-2.0-flash")
    try:
        client = genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
        search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None
        
        config = types.GenerateContentConfig(
            system_instruction=f"Ø£Ù†Øª {persona_type}. Ø±Ø¯ Ø¹Ù„Ù‰ Ù…ØµØ¹Ø¨ Ø¨Ø£Ø³Ù„ÙˆØ¨ ØªØ¹Ù„ÙŠÙ…ÙŠ Ù…Ø´Ø¬Ø¹.",
            tools=search_tool
        )
        
        response = client.models.generate_content(model=engine_id, contents=[user_input], config=config)
        return response.text
    except Exception as e:
        # Ù†Ø¸Ø§Ù… Ø§Ù„Ù‚ÙØ² ÙÙˆÙ‚ Ø§Ù„Ø®Ø·Ø£ (Fallback)
        st.warning(f"âš ï¸ Ø§Ù„Ù…Ø­Ø±Ùƒ {engine_label} Ù…Ø´ØºÙˆÙ„ØŒ Ø³Ø£Ø¬ÙŠØ¨Ùƒ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø³ØªÙ‚Ø±...")
        backup_res = client.models.generate_content(model="gemini-2.0-flash", contents=[user_input])
        return backup_res.text

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© ---
if "messages" not in st.session_state: st.session_state.messages = load_history()

with st.sidebar:
    st.title("ğŸ‘¨â€ğŸ« Ø§Ù„Ù…Ø¹Ù„Ù… Ø§Ù„Ø°ÙƒÙŠ")
    
    # Ù…ÙŠØ²Ø© Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ (Ø§Ù„Ù…Ø«Ø¨ØªØ©)
    if st.button("ğŸ—‘ï¸ ØªØµÙÙŠØ± Ø§Ù„Ø­ØµØ© (Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„)"):
        st.session_state.messages = []
        if os.path.exists("history.json"): os.remove("history.json")
        st.rerun()

    st.divider()
    # Ù…ÙŠØ²Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†
    st.write("ğŸ¤ ØªØ­Ø¯Ø« Ø¥Ù„ÙŠ:")
    audio_text = speech_to_text(language='ar', start_prompt="Ø§Ø¨Ø¯Ø£ Ø§Ù„ØªØ­Ø¯Ø«", stop_prompt="Ø§Ù†ØªÙ‡ÙŠØª", key='v27_mic')
    
    st.divider()
    # Ø²Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±
    web_on = st.toggle("ğŸŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø±", value=True)
    
    persona = st.radio("ğŸ‘¤ Ø§Ø®ØªØ± Ø´Ø®ØµÙŠØªÙŠ:", ["Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ ğŸ‘¨â€ğŸ«", "Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ğŸ› ï¸", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø®ØµÙŠ ğŸ¤–"])
    engine_choice = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„:", list(MODELS_GRID.keys()))

# --- 5. Ø¹Ø±Ø¶ Ø§Ù„Ø¯Ø±Ø³ ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

chat_in = st.chat_input("Ø§Ø³Ø£Ù„ Ù…Ø¯Ø±Ø³Ùƒ Ø£ÙŠ Ø´ÙŠØ¡...")
final_prompt = audio_text if audio_text else chat_in

if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    with st.chat_message("user"): st.markdown(final_prompt)

    with st.chat_message("assistant"):
        res = get_super_response(engine_choice, final_prompt, persona, use_search=web_on)
        st.markdown(res)
        
        # Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
        try:
            tts = gTTS(text=res[:100], lang='ar')
            b = io.BytesIO(); tts.write_to_fp(b); st.audio(b)
        except: pass

        st.session_state.messages.append({"role": "assistant", "content": res})
        save_history(st.session_state.messages)
