import streamlit as st
import google.generativeai as genai
import io
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ù‡ÙˆÙŠØ© ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.12.1", layout="wide", page_icon="ğŸ™ï¸")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    .stButton button { width: 100%; border-radius: 10px; font-weight: bold; }
    .mic-box { border: 2px solid #ff4b4b; padding: 10px; border-radius: 15px; text-align: center; margin-bottom: 20px; }
    </style>
    """, unsafe_allow_html=True)

# Ø§Ù„Ø±Ø¨Ø· Ø§Ù„ØªÙ‚Ù†ÙŠ
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- 2. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ÙˆØ§Ù„Ø³ÙŠØ§Ù‚ (Context Handling) ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# ØªØ­ÙˆÙŠÙ„ ØªØ§Ø±ÙŠØ® Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø¥Ù„Ù‰ ØªÙ†Ø³ÙŠÙ‚ ÙŠÙÙ‡Ù…Ù‡ Gemini
def get_gemini_history():
    history = []
    for msg in st.session_state.messages:
        role = "model" if msg["role"] == "assistant" else "user"
        history.append({"role": role, "parts": [msg["content"]]})
    return history

# --- 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
with st.sidebar:
    st.title("ğŸ® Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ…")
    
    st.markdown('<div class="mic-box">', unsafe_allow_html=True)
    st.subheader("ğŸ¤ Ø§Ù„Ù…ØºØ±ÙÙˆÙ†")
    audio_record = mic_recorder(start_prompt="Ø¨Ø¯Ø¡ Ø§Ù„ØªÙƒÙ„Ù…", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª", just_once=True, key='sidebar_mic')
    st.markdown('</div>', unsafe_allow_html=True)

    thinking_level = st.select_slider("ğŸ§  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±:", options=["Low", "Medium", "High"], value="High")
    persona = st.selectbox("ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ† (Ø£Ù‡Ù„ Ø§Ù„Ø¹Ù„Ù…)", "Ø®Ø¨ÙŠØ± Ø§Ù„Ù„ØºØ§Øª", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ°ÙŠ", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬"])
    
    st.divider()
    engine_choice = st.selectbox("ğŸ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["Gemini 2.0 Flash", "Gemini 1.5 Pro"])
    uploaded_file = st.file_uploader("ğŸ“‚ Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª:", type=["pdf", "txt", "jpg", "png", "jpeg"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# --- 4. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„Ø¹Ø±Ø¶ ---
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

prompt = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

# Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
if prompt or audio_record:
    user_txt = prompt if prompt else "ğŸ¤ [Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©]"
    
    # Ø¹Ø±Ø¶ Ø±Ø³Ø§Ù„Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙˆØ±Ø§Ù‹
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"):
        st.markdown(user_txt)

    # --- Ø§Ù„Ø¨Ø¯Ø¡ ÙÙŠ Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø« (Streaming) ---
    with st.chat_message("assistant"):
        try:
            # Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ù…Ø¹ Ø§Ù„Ø³ÙŠØ§Ù‚
            model_name = "gemini-2.0-flash" if "2.0" in engine_choice else "gemini-1.5-pro"
            model = genai.GenerativeModel(model_name)
            
            # Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© Ù…Ø­Ø§Ø¯Ø«Ø© ØªØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„ØªØ§Ø±ÙŠØ® Ø§Ù„Ø³Ø§Ø¨Ù‚ (Ø§Ù„Ø³ÙŠØ§Ù‚)
            chat_session = model.start_chat(history=get_gemini_history())
            
            # ØªØ¹Ù„ÙŠÙ…Ø§Øª Ø§Ù„Ù†Ø¸Ø§Ù… (System Instructions) Ù…Ø¯Ù…Ø¬Ø© ÙÙŠ Ø§Ù„Ø·Ù„Ø¨
            instruction = f"Ø¨ØµÙØªÙƒ {persona} ÙˆØ¨Ù…Ø³ØªÙˆÙ‰ ØªÙÙƒÙŠØ± {thinking_level}: "
            
            # ØªÙ†ÙÙŠØ° Ø§Ù„Ø¨Ø«
            response_placeholder = st.empty() # Ù…ÙƒØ§Ù† ÙØ§Ø±Øº Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù†Øµ ÙƒÙ„Ù…Ø© Ø¨ÙƒÙ„Ù…Ø©
            full_response = ""
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ø·Ù„Ø¨ Ø¨Ù†Ø¸Ø§Ù… Ø§Ù„Ø¨Ø«
            response = chat_session.send_message(instruction + user_txt, stream=True)
            
            for chunk in response:
                full_response += chunk.text
                response_placeholder.markdown(full_response + "â–Œ") # ØªØ£Ø«ÙŠØ± Ø§Ù„ÙƒØªØ§Ø¨Ø©
            
            response_placeholder.markdown(full_response) # Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ
            
            # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ (Ø§Ø®ØªÙŠØ§Ø±ÙŠ)
            tts = gTTS(text=full_response[:200], lang='ar')
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            st.audio(audio_fp)
            
            # Ø­ÙØ¸ Ø§Ù„Ø±Ø¯ ÙÙŠ Ø§Ù„Ø°Ø§ÙƒØ±Ø©
            st.session_state.messages.append({"role": "assistant", "content": full_response})
            
        except Exception as e:
            st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
