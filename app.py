import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, json
from gtts import gTTS
from streamlit_mic_recorder import speech_to_text # Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ø§Ø³ØªØ¯Ø¹Ø§Ø¡ Ø§Ù„Ù…Ø­ÙˆÙ„ Ø§Ù„Ù†ØµÙŠ
from PIL import Image

# --- 1. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ø§Ù„Ø³ÙŠØ§Ø¯ÙŠØ© ---
def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r", encoding="utf-8") as f:
            try: return json.load(f)
            except: return []
    return []

def save_history(messages):
    with open("history.json", "w", encoding="utf-8") as f: 
        json.dump(messages, f, ensure_ascii=False, indent=4)

st.set_page_config(page_title="ØªØ­Ø§Ù„Ù Ù…ØµØ¹Ø¨ v16.46.25 - Ø§Ù„Ù†Ø³Ø®Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø©", layout="wide", page_icon="ğŸ›¡ï¸")

# --- 2. Ù…ØµÙÙˆÙØ© Ø§Ù„Ø¹Ù‚ÙˆÙ„ Ø§Ù„Ø³Ø¨Ø¹Ø© Ø§Ù„Ù…Ø«Ø¨ØªØ© ---
MODELS_GRID = {
    "Gemini 3 Flash": "gemini-3-flash",
    "Gemini 2.5 Flash": "gemini-1.5-flash", # Ø§Ù„Ù…Ø³Ù…Ù‰ Ø§Ù„Ù…Ø³ØªÙ‚Ø± Ù„Ù„Ù†Ø³Ø®Ø© 2.5
    "Gemini 2.0 Flash": "gemini-2.0-flash-exp",
    "DeepSeek R1": "deepseek-reasoner",
    "Gemma 3 27B": "gemma-3-27-it",
    "Ernie 5.0": "ernie-5.0",
    "Kimi Latest": "moonshot-v1-8k"
}

# --- 3. Ù…Ø­Ø±Ùƒ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ø· ---
def get_super_response(engine_label, user_input, persona_type, image=None, use_search=False):
    engine_id = MODELS_GRID.get(engine_label)
    try:
        if "Gemini" in engine_label or "Gemma" in engine_label:
            client = genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
            search_tool = [types.Tool(google_search=types.GoogleSearch())] if use_search else None
            
            config = types.GenerateContentConfig(
                system_instruction=f"Ø£Ù†Øª {persona_type}. Ø®Ø§Ø·Ø¨ Ù…ØµØ¹Ø¨ Ø¨Ø§Ø­ØªØ±Ø§ÙÙŠØ©.",
                tools=search_tool
            )
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„Ù†Øµ ÙƒÙ‚Ø§Ø¦Ù…Ø© Ù†ØµÙˆØµ ØµØ±ÙŠØ­Ø© Ù„Ù…Ù†Ø¹ Ø£Ø®Ø·Ø§Ø¡ Pydantic
            response = client.models.generate_content(model=engine_id, contents=[user_input], config=config)
            return response.text
        
        elif "Ernie" in engine_label or "Kimi" in engine_label:
            # Ù…Ù†Ø·Ù‚ OpenAI Ù„Ù„Ù…Ø­Ø±ÙƒØ§Øª Ø§Ù„Ø£Ø®Ø±Ù‰ (ÙŠØªÙ… ØªÙØ¹ÙŠÙ„Ù‡ Ø¹Ù†Ø¯ ØªÙˆÙØ± Ø§Ù„Ù€ API Keys)
            return "Ø§Ù„Ù…Ø­Ø±Ùƒ Ù…ÙØ¹Ù„ØŒ ÙŠØ±Ø¬Ù‰ Ø§Ù„ØªØ£ÙƒØ¯ Ù…Ù† Ù…ÙØ§ØªÙŠØ­ Ø§Ù„Ø±Ø¨Ø·."
            
    except Exception as e:
        return f"âš ï¸ Ø¹Ø°Ø±Ø§Ù‹ Ù…ØµØ¹Ø¨ØŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {str(e)}"

# --- 4. Ø´Ø±ÙŠØ· Ø§Ù„ØªØ­ÙƒÙ… ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© ---
if "messages" not in st.session_state: st.session_state.messages = load_history()

with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø© v25")
    
    # Ù…ÙŠØ²Ø© Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ (ØªØµÙÙŠØ± ÙƒØ§Ù…Ù„)
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ ÙˆØªØµÙÙŠØ± Ø§Ù„Ø°Ø§ÙƒØ±Ø©"):
        st.session_state.messages = []
        if os.path.exists("history.json"): os.remove("history.json")
        st.success("ØªÙ… ØªØµÙÙŠØ± Ø§Ù„Ù…Ù†ØµØ©!")
        st.rerun()

    st.divider()
    # Ù…ÙŠØ²Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Speech to Text)
    st.write("ğŸ™ï¸ Ø§Ù„ØªÙˆØ§ØµÙ„ Ø§Ù„ØµÙˆØªÙŠ:")
    audio_text = speech_to_text(language='ar', start_prompt="Ø§Ø¨Ø¯Ø£ Ø§Ù„ÙƒÙ„Ø§Ù…", stop_prompt="Ø¥Ù†Ù‡Ø§Ø¡", key='mic_final')
    
    st.divider()
    # Ù…ÙŠØ²Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…ÙÙ‚ÙˆØ¯Ø©
    web_on = st.toggle("ğŸŒ ØªÙØ¹ÙŠÙ„ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ù…Ø¨Ø§Ø´Ø± (Ø§Ù„Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ù…ÙØªÙˆØ­)", value=True)
    
    persona = st.radio("ğŸ‘¤ Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ ğŸ‘¨â€ğŸ«", "Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ğŸ› ï¸", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø®ØµÙŠ ğŸ¤–"])
    engine_choice = st.selectbox("ğŸ¯ Ø§Ù„Ø¹Ù‚Ù„ Ø§Ù„Ù†Ø´Ø·:", list(MODELS_GRID.keys()))
    uploaded_file = st.file_uploader("ğŸ“Š Ø±ÙØ¹ Ù…Ù„ÙØ§Øª", type=['csv', 'png', 'jpg'])

# --- 5. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¹Ø±Ø¶ ÙˆØ§Ù„Ø±Ø§Ø¯Ø§Ø± ---
for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

chat_input = st.chat_input("Ø§ÙƒØªØ¨ Ø£Ù…Ø±Ùƒ Ù‡Ù†Ø§...")
# Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ© Ù„Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡ØŒ ÙˆØ¥Ù„Ø§ ÙØ§Ù„Ù†Øµ
final_prompt = audio_text if audio_text else chat_input

if final_prompt:
    st.session_state.messages.append({"role": "user", "content": final_prompt})
    with st.chat_message("user"): st.markdown(final_prompt)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª..."):
            res = get_super_response(engine_choice, final_prompt, persona, use_search=web_on)
            st.markdown(res)
            
            # Ø§Ù„Ø±Ø§Ø¯Ø§Ø± (ÙƒØ´Ù Ø§Ù„Ù…Ø³Ø§Ø±)
            code_match = re.search(r'```python(.*?)```', res, flags=re.DOTALL)
            if code_match:
                with open("auto_fix.py", "w", encoding="utf-8") as f: f.write(code_match.group(1).strip())
                st.info(f"ğŸ“‚ Ø§Ù„Ø±Ø§Ø¯Ø§Ø±: ØªÙ… Ø­ÙØ¸ Ø§Ù„ÙƒÙˆØ¯ ÙÙŠ {os.path.abspath('auto_fix.py')}")

            st.session_state.messages.append({"role": "assistant", "content": res})
            save_history(st.session_state.messages)
