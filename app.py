import streamlit as st
import os
import time
import io
import base64
from google import genai
from google.genai import types
from openai import OpenAI
from PIL import Image
import arabic_reshaper
from bidi.algorithm import get_display
import fitz  # Ù…ÙƒØªØ¨Ø© PyMuPDF Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„ÙØ§Øª PDF
from gtts import gTTS  # Ù…ÙŠØ²Ø© Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ

# --- [1] Ø£Ø³Ø·ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª ÙˆÙ…Ø¬Ù„Ø³ Ø§Ù„Ø®Ø¨Ø±Ø§Ø¡ Ø§Ù„ÙƒØ§Ù…Ù„ ---
model_map = {
    "Gemini 3 Flash": "gemini-3-flash-preview",
    "Gemini 3 Pro": "gemini-3-pro-preview",
    "Gemini 2.5 Pro": "gemini-2.5-pro",
    "Gemini 1.5 Flash": "gemini-flash-latest"
}

expert_map = {
    "ğŸŒ Ø®Ø¨ÙŠØ± Ø¹Ø§Ù…": "Ø£Ù†Øª Ù…Ø³ØªØ´Ø§Ø± Ø¹Ø§Ù… Ø°ÙƒÙŠØŒ ØªØ¬ÙŠØ¨ Ø¨Ø¯Ù‚Ø© ÙˆÙˆØ¶ÙˆØ­ ÙˆÙ„Ø¨Ø§Ù‚Ø©. ØªØ°ÙƒØ± Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø­ÙˆØ§Ø± Ø§Ù„Ø³Ø§Ø¨Ù‚.",
    "ğŸ’» Ø®Ø¨ÙŠØ± ØªÙ‚Ù†ÙŠ": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§ØªØŒ ØªØ±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ø­Ù„ÙˆÙ„ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© ÙˆØ§ÙƒØªØ´Ø§Ù Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØªØ·ÙˆÙŠØ± Ø§Ù„Ø£ÙƒÙˆØ§Ø¯.",
    "ğŸ“ˆ Ù…Ø­Ù„Ù„ Ø£Ø³ÙˆØ§Ù‚": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù…Ø§Ù„ÙŠØŒ Ø§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ Ù„Ø¬Ù„Ø¨ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø°Ù‡Ø¨ ÙˆØ§Ù„Ø¨ÙˆØ±ØµØ© ÙˆØ§Ù„Ø¹Ù…Ù„Ø§Øª ÙˆØªØ­Ù„ÙŠÙ„Ù‡Ø§.",
    "ğŸ“§ Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…Ø±Ø§Ø³Ù„Ø§Øª": "Ø£Ù†Øª Ø³ÙƒØ±ØªÙŠØ± ØªÙ†ÙÙŠØ°ÙŠØŒ ØµØº Ø¥ÙŠÙ…ÙŠÙ„Ø§Øª Ø§Ø­ØªØ±Ø§ÙÙŠØ© ÙˆØ±Ø¯ÙˆØ¯ Ø¯Ø¨Ù„ÙˆÙ…Ø§Ø³ÙŠØ© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ù…Ø¹Ø·ÙŠØ§Øª.",
    "ğŸ“Š Ù…Ø­Ù„Ù„ Ø¥Ø­ØµØ§Ø¦ÙŠ": "Ø£Ù†Øª Ø¨Ø±ÙˆÙÙŠØ³ÙˆØ± Ø¨ÙŠØ§Ù†Ø§ØªØŒ Ø­Ù„Ù„ Ø§Ù„Ø£Ø±Ù‚Ø§Ù… ÙˆØ§Ù„Ø¬Ø¯Ø§ÙˆÙ„ Ø§Ù„Ù…Ø³ØªØ®Ø±Ø¬Ø© ÙˆÙ‚Ø¯Ù… Ø±Ø¤ÙŠØ© Ø¥Ø­ØµØ§Ø¦ÙŠØ© Ø¯Ù‚ÙŠÙ‚Ø©.",
    "âœï¸ Ø®Ø¨ÙŠØ± Ù…Ø­ØªÙˆÙ‰": "Ø£Ù†Øª ÙƒØ§ØªØ¨ Ù…Ø­ØªØ±ÙØŒ Ø­ÙˆÙ„ Ø§Ù„Ø£ÙÙƒØ§Ø± ÙˆØ§Ù„Ù…Ø³ÙˆØ¯Ø§Øª Ø¥Ù„Ù‰ ØªÙ‚Ø§Ø±ÙŠØ± ÙˆÙ…Ù‚Ø§Ù„Ø§Øª Ù…ØªÙƒØ§Ù…Ù„Ø©.",
    "ğŸ“š Ø®Ø¨ÙŠØ± Ù„ØºÙˆÙŠ": "Ø£Ù†Øª Ø¨Ø±ÙˆÙÙŠØ³ÙˆØ± Ù„ØºÙˆÙŠØŒ Ø±ÙƒØ² Ø¹Ù„Ù‰ Ø§Ù„Ù†Ø­Ùˆ ÙˆØ§Ù„Ø¨Ù„Ø§ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© ÙˆØ§Ù„ØªØ¯Ù‚ÙŠÙ‚ Ø§Ù„Ù„ØºÙˆÙŠ.",
    "ğŸ›¡ï¸ Ø®Ø¨ÙŠØ± Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ": "Ø£Ù†Øª Ù…Ø­Ù„Ù„ Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ Ø¬ÙŠÙˆØ³ÙŠØ§Ø³ÙŠ ÙˆØ¹Ø³ÙƒØ±ÙŠØŒ Ø­Ù„Ù„ Ø§Ù„Ù…ÙˆØ§Ù‚Ù Ù…Ù† Ù…Ù†Ø¸ÙˆØ± Ù‚ÙŠØ§Ø¯ÙŠ.",
    "âš–ï¸ Ù…Ø³ØªØ´Ø§Ø± Ù‚Ø§Ù†ÙˆÙ†ÙŠ": "Ø£Ù†Øª Ø®Ø¨ÙŠØ± Ù‚Ø§Ù†ÙˆÙ†ÙŠØŒ Ù…Ø±Ø§Ø¬Ø¹ Ù„Ù„Ø¹Ù‚ÙˆØ¯ ÙˆØ§Ù„ÙˆØ«Ø§Ø¦Ù‚ Ø§Ù„Ø±Ø³Ù…ÙŠØ© ÙˆØ§Ù„Ø§Ù…ØªØ«Ø§Ù„."
}

# Ø¯Ø§Ù„Ø© ØªØµØ­ÙŠØ­ Ø¹Ø±Ø¶ Ø§Ù„Ù„ØºØ© Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©
def fix_ar(text):
    try:
        reshaped_text = arabic_reshaper.reshape(text)
        return get_display(reshaped_text)
    except:
        return text

# Ø¯Ø§Ù„Ø© Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù†Øµ Ù…Ù† Ù…Ù„ÙØ§Øª PDF
def extract_pdf_content(file_bytes):
    doc = fitz.open(stream=file_bytes, filetype="pdf")
    text = ""
    for page in doc:
        text += page.get_text()
    return text

# Ø¯Ø§Ù„Ø© ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ
def text_to_speech_ar(text):
    try:
        tts = gTTS(text=text, lang='ar')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except Exception as e:
        st.error(f"Ø®Ø·Ø£ ÙÙŠ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØª: {e}")
        return None

if "request_count" not in st.session_state: st.session_state.request_count = 0
if "messages" not in st.session_state: st.session_state.messages = []

# --- [2] Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø§ØªØµØ§Ù„ ÙˆØ§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ Ø§Ù„Ù…Ø·ÙˆØ± ---
def get_gemini_client():
    try:
        return genai.Client(api_key=st.secrets["GEMINI_API_KEY"])
    except:
        return None

def run_engine(prompt_data, is_voice=False, image_data=None, pdf_text=None):
    target_model = model_map.get(selected_model, "gemini-flash-latest")
    
    # ØªØ­Ø³ÙŠÙ† Ø£Ù…Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ Ù„Ø¶Ù…Ø§Ù† Ø§Ø³ØªØ¬Ø§Ø¨Ø© Ø§Ù„Ø±Ø§Ø¯Ø§Ø±
    search_instruction = "\nØ§Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ (Google Search) Ø¯Ø§Ø¦Ù…Ø§Ù‹ Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£Ø¯Ù‚ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø­Ø§Ù„ÙŠØ©." if live_search else ""
    expert_instruction = expert_map.get(selected_expert, "Ø®Ø¨ÙŠØ± Ø¹Ø§Ù…") + search_instruction

    try:
        if provider == "Google Gemini":
            client = get_gemini_client()
            if not client: return "ğŸš¨ ÙØ´Ù„ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ø§Ù„Ø®Ø§Ø¯Ù…."

            # ØªÙ‚Ù„ÙŠÙ„ Ø³ÙŠØ§Ù‚ Ø§Ù„Ø°Ø§ÙƒØ±Ø© Ù„ØªÙ‚Ù„ÙŠÙ„ Ø¶ØºØ· Ø§Ù„Ù€ 429
            history = []
            for msg in st.session_state.messages[-3:]: 
                role = "user" if msg["role"] == "user" else "model"
                history.append(types.Content(role=role, parts=[types.Part.from_text(text=msg["content"])]))

            config = types.GenerateContentConfig(
                system_instruction=expert_instruction,
                tools=[types.Tool(google_search=types.GoogleSearch())] if live_search else None,
                temperature=0.3 # ØªÙ‚Ù„ÙŠÙ„ Ø§Ù„Ø­Ø±Ø§Ø±Ø© Ù„Ø²ÙŠØ§Ø¯Ø© Ø¯Ù‚Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ
            )

            content_list = []
            if pdf_text:
                content_list.append(f"Ù…Ø­ØªÙˆÙ‰ Ù…Ø³ØªÙ†Ø¯ PDF Ø§Ù„Ù…Ø±ÙÙ‚:\n{pdf_text}\n\nØ§Ù„Ø³Ø¤Ø§Ù„ Ø§Ù„Ù…Ø·Ù„ÙˆØ¨ Ø­ÙˆÙ„ Ø§Ù„Ù…Ø³ØªÙ†Ø¯:")
            if image_data and not pdf_text:
                content_list.append(Image.open(image_data))
            
            if is_voice:
                content_list.append(types.Part.from_bytes(data=prompt_data['bytes'], mime_type="audio/wav"))
            else:
                content_list.append(prompt_data)

            # ØªØ´ØºÙŠÙ„ Ø§Ù„Ø¬Ù„Ø³Ø©
            chat = client.chats.create(model=target_model, config=config, history=history)
            response = chat.send_message(content_list)
            
            st.session_state.request_count += 1 
            return response.text

        elif provider == "DeepSeek AI":
            client = OpenAI(api_key=st.secrets.get("DEEPSEEK_API_KEY"), base_url="https://api.deepseek.com")
            ds_messages = [{"role": "system", "content": expert_instruction}]
            for msg in st.session_state.messages[-5:]:
                ds_messages.append({"role": msg["role"], "content": msg["content"]})
            ds_messages.append({"role": "user", "content": str(prompt_data)})

            response = client.chat.completions.create(model="deepseek-chat", messages=ds_messages)
            st.session_state.request_count += 1
            return response.choices[0].message.content

    except Exception as e:
        if "429" in str(e):
            return "ğŸš« ÙˆØµÙ„Øª Ù„Ù„Ø­Ø¯ Ø§Ù„Ø£Ù‚ØµÙ‰ Ù„Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù…Ø¬Ø§Ù†ÙŠØ© Ø­Ø§Ù„ÙŠØ§Ù‹. ÙŠØ±Ø¬Ù‰ Ø§Ù„Ø§Ù†ØªØ¸Ø§Ø± Ø¯Ù‚ÙŠÙ‚Ø© ÙˆØ§Ø­Ø¯Ø© Ø«Ù… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„Ù…Ø­Ø§ÙˆÙ„Ø©."
        return f"âŒ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {str(e)}"

# --- [3] ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø§Ø­ØªØ±Ø§ÙÙŠØ© ---
st.set_page_config(page_title="Ø¥Ù…Ø¨Ø±Ø§Ø·ÙˆØ±ÙŠØ© Ø§Ù„ØªØ­Ø§Ù„Ù 2026", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #0e1117; color: #ffffff !important; direction: rtl; text-align: right; }
    .stChatMessage { background-color: #262730 !important; border-right: 5px solid #007bff !important; border-radius: 15px !important; color: #ffffff !important; margin-bottom: 10px; }
    .stMarkdown p, .stMarkdown h1, .stMarkdown h2, .stMarkdown h3 { color: #ffffff !important; }
    .stDownloadButton button { background-color: #155724 !important; color: #d4edda !important; border: 1px solid #c3e6cb !important; font-weight: bold !important; }
    </style>
    """, unsafe_allow_html=True) 

with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„Ù‚ÙŠØ§Ø¯Ø©")
    st.progress(min(st.session_state.request_count / 50, 1.0))
    st.caption(f"Ø§Ù„Ø·Ù„Ø¨Ø§Øª Ø§Ù„Ù†Ø§Ø¬Ø­Ø©: {st.session_state.request_count} / 50")
    
    st.divider()
    provider = st.radio("Ø§Ù„Ù…Ø²ÙˆØ¯ Ø§Ù„Ø§Ø³ØªØ±Ø§ØªÙŠØ¬ÙŠ:", ["Google Gemini", "DeepSeek AI"])
    selected_model = st.selectbox("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„:", list(model_map.keys()), index=0)
    selected_expert = st.selectbox("Ø§Ù„ÙˆÙƒÙŠÙ„ Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ:", list(expert_map.keys()))
    
    st.divider()
    live_search = st.toggle("Ø±Ø§Ø¯Ø§Ø± Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ ğŸ“¡", value=True)
    speak_response = st.toggle("Ù†Ø·Ù‚ Ø§Ù„Ø¥Ø¬Ø§Ø¨Ø© Ø¢Ù„ÙŠØ§Ù‹ ğŸ”Š", value=True)
    uploaded_file = st.file_uploader("ğŸ“¦ Ø±ÙØ¹ (PNG, JPG, PDF)", type=['png', 'jpg', 'jpeg', 'pdf'])
    
    if st.button("ğŸ—‘ï¸ ØªØ·Ù‡ÙŠØ± Ø§Ù„Ø³Ø¬Ù„"):
        st.session_state.messages = []
        st.rerun()

# Ø¹Ø±Ø¶ Ø§Ù„Ø±Ø³Ø§Ø¦Ù„
for m in st.session_state.messages:
    with st.chat_message(m["role"]): 
        st.markdown(m["content"])
        if m["role"] == "assistant" and "audio" in m:
            st.audio(m["audio"], format="audio/mp3")

# --- [4] Ù…Ù†Ø·Ù‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„ Ø§Ù„Ø°ÙƒÙŠØ© ---
from streamlit_mic_recorder import mic_recorder
col_mic, col_txt = st.columns([1, 10])

with col_mic:
    audio = mic_recorder(start_prompt="ğŸ¤", stop_prompt="ğŸ“¤", key='unified_mic_v7')

with col_txt:
    text_input = st.chat_input("Ø£ØµØ¯Ø± Ø£ÙˆØ§Ù…Ø±Ùƒ Ù‡Ù†Ø§ ÙŠØ§ Ù‚Ø§Ø¦Ø¯...")

input_val = None
voice_flag = False

if audio:
    input_val, voice_flag = audio, True
elif text_input:
    input_val = text_input

if input_val:
    pdf_text = None
    if uploaded_file and uploaded_file.type == "application/pdf":
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø³Ø­ Ø§Ù„Ù…Ø³ØªÙ†Ø¯ Ø¶ÙˆØ¦ÙŠØ§Ù‹..."):
            pdf_text = extract_pdf_content(uploaded_file.read())

    label = "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ]" if voice_flag else input_val
    st.session_state.messages.append({"role": "user", "content": label})
    
    with st.chat_message("user"):
        st.markdown(label)
        if uploaded_file and uploaded_file.type != "application/pdf": 
            st.image(uploaded_file, width=300)

    with st.chat_message("assistant"):
        # Ø¥Ø¸Ù‡Ø§Ø± Ø­Ø§Ù„Ø© Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø­ÙŠ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…ÙØ¹Ù„Ø§Ù‹
        if live_search:
            with st.status("ğŸ“¡ Ø¬Ø§Ø±ÙŠ ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø§Ø¯Ø§Ø± ÙˆØ§Ù„Ø¨Ø­Ø« ÙÙŠ Ø§Ù„ÙˆÙŠØ¨...", expanded=True) as status:
                st.write("ğŸ” Ø¬Ø§Ø±ÙŠ Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù„Ø­Ø¸ÙŠØ©...")
                res = run_engine(input_val, is_voice=voice_flag, image_data=uploaded_file, pdf_text=pdf_text)
                status.update(label="âœ… ØªÙ… Ø§ÙƒØªÙ…Ø§Ù„ Ø§Ù„Ø¨Ø­Ø« ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„!", state="complete", expanded=False)
        else:
            with st.spinner(f"Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙ†ÙÙŠØ° Ø¨ÙˆØ§Ø³Ø·Ø© {selected_expert}..."):
                res = run_engine(input_val, is_voice=voice_flag, image_data=uploaded_file, pdf_text=pdf_text)
        
        st.markdown(res)
        
        # Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØª
        msg_data = {"role": "assistant", "content": res}
        if speak_response:
            audio_fp = text_to_speech_ar(res)
            if audio_fp:
                st.audio(audio_fp, format="audio/mp3")
                msg_data["audio"] = audio_fp
        
        st.session_state.messages.append(msg_data)
        st.download_button("ğŸ’¾ ØªØµØ¯ÙŠØ± Ø§Ù„ØªÙ‚Ø±ÙŠØ± Ø§Ù„ØªÙ†ÙÙŠØ°ÙŠ", res, file_name="alliance_empire_report.txt")
