import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, time, json
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 
from PIL import Image

# --- 1. Ø¥Ø¯Ø§Ø±Ø© Ø§Ù„Ø°Ø§ÙƒØ±Ø© ---
def load_history():
    if os.path.exists("history.json"):
        with open("history.json", "r", encoding="utf-8") as f: return json.load(f)
    return []

st.set_page_config(page_title="ØªØ­Ø§Ù„Ù Ù…ØµØ¹Ø¨ v16.46.18", layout="wide", page_icon="ğŸ›¡ï¸")

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„ÙƒØ§Ù…Ù„Ø© ÙˆØ§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ© Ù„Ù„Ù…Ø­Ø±ÙƒØ§Øª (Ø¨Ø¯ÙˆÙ† Ù†ÙˆØ§Ù‚Øµ) ---
MODELS_GRID = {
    "Gemini 3 Flash (Ø§Ù„Ø¬Ø¯ÙŠØ¯)": "gemini-3-flash",
    "Gemini 2.5 Flash (Ø§Ù„Ø°ÙŠ ØªØ¨Ø­Ø« Ø¹Ù†Ù‡)": "gemini-2.5-flash", 
    "Gemini 2.0 Flash": "gemini-2.0-flash",
    "Gemini 1.5 Pro": "gemini-1.5-pro",
    "DeepSeek R1": "deepseek-reasoner",
    "Ernie 5.0": "ernie-5.0",
    "Kimi Latest": "moonshot-v1-8k"
}

# --- 3. Ø²Ø± Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ (Ø§Ù„Ù…Ø«Ø¨Øª) ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ù‚ÙŠØ§Ø¯Ø© Ù…ØµØ¹Ø¨")
    if st.button("ğŸ§¹ Ù…Ø³Ø­ Ø§Ù„Ø³Ø¬Ù„ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„", type="primary"):
        if os.path.exists("history.json"): os.remove("history.json")
        st.session_state.messages = []
        st.rerun()
    
    st.divider()
    persona = st.radio("ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ø´Ø®ØµÙŠØ©:", ["Ø§Ù„Ù…Ø¯Ø±Ø³ Ø§Ù„Ø°ÙƒÙŠ ğŸ‘¨â€ğŸ«", "Ø§Ù„Ø®Ø¨ÙŠØ± Ø§Ù„ØªÙ‚Ù†ÙŠ ğŸ› ï¸", "Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ø´Ø®ØµÙŠ ğŸ¤–"])
    # Ù‡Ù†Ø§ ØªÙ… ØªØ«Ø¨ÙŠØª Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ø°ÙŠ Ø³Ø£Ù„Øª Ø¹Ù†Ù‡
    engine_choice = st.selectbox("ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù‚Ù„:", list(MODELS_GRID.keys()))
    st.divider()
    uploaded_file = st.file_uploader("ğŸ–¼ï¸ Ø±ÙØ¹ ÙˆØ³Ø§Ø¦Ø·", type=['jpg', 'png', 'csv'])

# --- 4. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø© (get_super_response) ---
def get_super_response(engine_label, user_input, persona_type, image=None):
    api_key = st.secrets.get("GEMINI_API_KEY")
    client = genai.Client(api_key=api_key)
    engine_id = MODELS_GRID[engine_label]
    
    try:
        if "Gemini" in engine_label:
            config = types.GenerateContentConfig(system_instruction=f"Ø£Ù†Øª {persona_type}")
            contents = [user_input]
            if image: contents.append(image)
            return client.models.generate_content(model=engine_id, contents=contents, config=config).text
        # Ø¥Ø¶Ø§ÙØ© Ù…Ù†Ø·Ù‚ Kimi Ùˆ Ernie Ù‡Ù†Ø§ Ø¨Ù†ÙØ³ Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø³Ø§Ø¨Ù‚Ø©...
    except Exception as e:
        return f"âš ï¸ Ø®Ø·Ø£ ÙÙŠ {engine_label}: {str(e)}"

# --- 5. Ø§Ù„Ø±Ø§Ø¯Ø§Ø± ÙˆØªØ­Ø¯ÙŠØ« Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ---
if "messages" not in st.session_state: st.session_state.messages = load_history()

for m in st.session_state.messages:
    with st.chat_message(m["role"]): st.markdown(m["content"])

if prompt := st.chat_input("ØªØ­Ø¯Ø« Ù…Ø¹ Gemini 2.5 Flash Ø§Ù„Ø¢Ù†..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"): st.markdown(prompt)
    
    with st.chat_message("assistant"):
        response = get_super_response(engine_choice, prompt, persona)
        st.markdown(response)
        st.session_state.messages.append({"role": "assistant", "content": response})
