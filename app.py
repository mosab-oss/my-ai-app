import streamlit as st
from google import genai
from google.genai import types
from openai import OpenAI  
import io, re, os, subprocess, requests
from gtts import gTTS
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© ÙˆØ§Ù„Ø³Ù…Ø§Øª ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.24.0", layout="wide", page_icon="âš¡")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    [data-testid="stSidebar"] { background-color: #000c18; direction: rtl; border-left: 2px solid #00d4ff; }
    .exec-box { background-color: #000; color: #00ffcc; padding: 15px; border-radius: 10px; border: 1px solid #00ffcc; font-family: 'Courier New', monospace; }
    </style>
    """, unsafe_allow_html=True)

API_KEY = st.secrets.get("GEMINI_API_KEY")

# --- 2. Ù…Ø­Ø±Ùƒ Ø§Ù„ØªÙ†ÙÙŠØ° Ø§Ù„ØµØ§Ù…Øª Ù„Ù„Ø£ÙƒÙˆØ§Ø¯ ---
def execute_logic(text):
    display_text = re.sub(r'<think>.*?</think>', '', text, flags=re.DOTALL).strip()
    file_pattern = r'SAVE_FILE:\s*([\w\.-]+)\s*\|\s*content=\{(.*?)\}'
    match = re.search(file_pattern, text, flags=re.DOTALL)
    exec_output = ""
    if match:
        fname, fcontent = match.group(1).strip(), match.group(2).strip()
        fcontent = re.sub(r'```python|```', '', fcontent).strip()
        try:
            with open(fname, 'w', encoding='utf-8') as f: f.write(fcontent)
            if fname.endswith('.py'):
                res = subprocess.run(['python3', fname], capture_output=True, text=True, timeout=10)
                exec_output = f"ğŸ–¥ï¸ Ù†Ø§ØªØ¬ Ø§Ù„ØªÙ†ÙÙŠØ°:\n{res.stdout}\n{res.stderr}"
        except Exception as e: exec_output = f"âŒ Ø®Ø·Ø£: {e}"
    return display_text, exec_output

# --- 3. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ« Ù„Ù€ 2.5 Flash) ---
with st.sidebar:
    st.title("ğŸ›¡ï¸ Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ… v16.24")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù†", stop_prompt="Ø¥Ø±Ø³Ø§Ù„", key='v24_mic')
    st.divider()

    # ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©: Ø¬Ø¹Ù„ gemini-2.5-flash Ù‡Ùˆ Ø§Ù„Ø®ÙŠØ§Ø± Ø§Ù„Ø£ÙˆÙ„
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ø®ØªØ± Ø§Ù„Ù…Ø­Ø±Ùƒ:", 
        ["gemini-2.5-flash", "gemini-3-pro-preview", "gemini-3-flash", "deepseek-r1", "kimi-latest", "ernie-5.0"]
    )

    persona = st.selectbox("ğŸ‘¤ Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ø®Ø¨ÙŠØ±:", ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ†", "Ù…Ø¯Ø±Ø³ Ø§Ù„Ù„ØºØ©", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ°"])
    st.divider()

    # Ø²Ø± Ø§Ù„ÙØ­Øµ Ø§Ù„Ù…Ø·ÙˆØ±
    col_check, col_clear = st.columns(2)
    with col_check:
        if st.button("ğŸ” ÙØ­Øµ Ø§Ù„Ø£Ù†Ø¸Ù…Ø©"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ÙØ­Øµ..."):
                try:
                    c_test = genai.Client(api_key=API_KEY)
                    # ÙØ­Øµ Ø¬Ø§Ù‡Ø²ÙŠØ© Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¬Ø¯ÙŠØ¯
                    c_test.models.get(model="gemini-2.5-flash")
                    st.toast("âœ… Gemini 2.5 Flash: Ø¬Ø§Ù‡Ø²")
                except: st.toast("âŒ Google API: ÙØ´Ù„ Ø§Ù„Ø§ØªØµØ§Ù„")
                
                if "deepseek" in engine_choice:
                    try:
                        resp = requests.get("http://localhost:1234/v1/models", timeout=2)
                        st.toast("âœ… DeepSeek (Local): Ù†Ø´Ø·") if resp.status_code == 200 else st.toast("âš ï¸ DeepSeek: Ø§Ù„Ø³ÙŠØ±ÙØ± ÙŠØ¹Ù…Ù„ Ø¨Ù„Ø§ Ù…ÙˆØ¯ÙŠÙ„")
                    except: st.toast("âŒ DeepSeek: Ø´ØºÙ„ LM Studio")
    
    with col_clear:
        if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­", type="primary"):
            st.session_state.messages = []
            st.rerun()

# --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ Ø¨ØªÙˆØ¬ÙŠÙ‡ Ø§Ù„Ù…Ø³Ø§Ø±Ø§Øª ---
if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

if prompt := st.chat_input("Ø§Ø³Ø£Ù„ Ø§Ù„ØªØ­Ø§Ù„Ù Ø§Ù„Ø¹Ø§Ù„Ù…ÙŠ...") or audio_record:
    user_txt = prompt if prompt else "ğŸ¤ [Ø£Ù…Ø± ØµÙˆØªÙŠ]"
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"): st.markdown(user_txt)

    with st.chat_message("assistant"):
        try:
            final_response = ""
            sys_instruct = f"Ø£Ù†Øª {persona}. Ø¥Ø°Ø§ Ø·Ù„Ø¨Øª ÙƒÙˆØ¯ Ø§Ø³ØªØ®Ø¯Ù… SAVE_FILE: name | content={{}}."

            # Ù…Ø³Ø§Ø± Gemini Ø§Ù„Ø¬Ø¯ÙŠØ¯ (2.5 ÙˆÙ…Ø§ ÙÙˆÙ‚)
            if "gemini" in engine_choice or "gemma" in engine_choice:
                client = genai.Client(api_key=API_KEY)
                res = client.models.generate_content(
                    model=engine_choice,
                    contents=user_txt,
                    config=types.GenerateContentConfig(system_instruction=sys_instruct)
                )
                final_response = res.text

            # Ù…Ø³Ø§Ø± DeepSeek (Ù…Ø­Ù„ÙŠ)
            elif "deepseek" in engine_choice:
                local_client = OpenAI(base_url="http://localhost:1234/v1", api_key="lm-studio")
                res = local_client.chat.completions.create(
                    model="deepseek-r1",
                    messages=[{"role": "system", "content": sys_instruct}, {"role": "user", "content": user_txt}]
                )
                final_response = res.choices[0].message.content

            clean_txt, exec_res = execute_logic(final_response)
            st.markdown(clean_txt)
            if exec_res: st.markdown(f'<div class="exec-box">{exec_res}</div>', unsafe_allow_html=True)
            
            # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ
            tts = gTTS(text=clean_txt[:250], lang='ar')
            fp = io.BytesIO(); tts.write_to_fp(fp); st.audio(fp)
            st.session_state.messages.append({"role": "assistant", "content": clean_txt})

        except Exception as e:
            st.error(f"Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø§ØªØµØ§Ù„: {e}")
