import streamlit as st
import google.generativeai as genai
from openai import OpenAI
import io, re, os, subprocess
from gtts import gTTS
from PIL import Image
from streamlit_mic_recorder import mic_recorder 

# --- 1. Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ÙˆØ§Ø¬Ù‡Ø© (RTL) ---
st.set_page_config(page_title="Ù…Ù†ØµØ© Ù…ØµØ¹Ø¨ v16.11.8", layout="wide", page_icon="ğŸ¤")

st.markdown("""
    <style>
    .stApp { direction: rtl; text-align: right; }
    /* ØªÙ…ÙŠÙŠØ² Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† Ø¨Ù„ÙˆÙ† ÙˆØ§Ø¶Ø­ */
    .stButton button { background-color: #ff4b4b; color: white; border-radius: 20px; }
    section[data-testid="stSidebar"] { direction: rtl; text-align: right; }
    </style>
    """, unsafe_allow_html=True)

# Ø§Ù„Ø±Ø¨Ø· Ø§Ù„Ù…Ø­Ù„ÙŠ ÙˆÙ…Ø­Ø±ÙƒØ§Øª Ø¬ÙˆØ¬Ù„
local_client = OpenAI(base_url="http://127.0.0.1:1234/v1", api_key="lm-studio")
api_key = st.secrets.get("GEMINI_API_KEY")
if api_key:
    genai.configure(api_key=api_key)

# --- 2. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ© (ÙƒÙ„ Ø§Ù„Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªÙŠ Ø³Ø£Ù„Øª Ø¹Ù†Ù‡Ø§) ---
with st.sidebar:
    st.header("ğŸ® Ù…Ø±ÙƒØ² Ø§Ù„ØªØ­ÙƒÙ… v16.11.8")
    
    # Ø®Ø¨ÙŠØ± Ø§Ù„Ù…Ø¹Ø±ÙØ© (Ø§Ù„Ø°ÙŠÙ† ÙŠØ¹Ù„Ù…ÙˆÙ†)
    persona = st.selectbox(
        "ğŸ‘¤ Ø§Ø®ØªØ± Ø§Ù„Ø´Ø®ØµÙŠØ©:", 
        ["Ø§Ù„Ù…Ø¹Ø±ÙÙˆÙ† (Ø®Ø¨ÙŠØ± Ø§Ù„Ø¹Ù„Ù…)", "Ø®Ø¨ÙŠØ± Ø§Ù„Ù„ØºØ§Øª", "ÙˆÙƒÙŠÙ„ ØªÙ†ÙÙŠØ°ÙŠ", "Ù…Ø³Ø§Ø¹Ø¯ Ù…Ø¨Ø±Ù…Ø¬"]
    )

    # Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ± (Thinking) - Ø¹Ø§Ø¯ Ù„Ù…ÙƒØ§Ù†Ù‡
    thinking_level = st.select_slider(
        "ğŸ§  Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±:", 
        options=["Low", "Medium", "High"], 
        value="High"
    )
    
    st.divider()
    
    # Ø§Ø®ØªÙŠØ§Ø± Ø§Ù„Ù…Ø­Ø±Ùƒ
    engine_choice = st.selectbox(
        "ğŸ¯ Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:",
        ["Gemini 2.5 Flash", "Gemini 3 Pro", "Gemma 3 27B", "DeepSeek R1"]
    )
    
    # Ø±ÙØ¹ Ø§Ù„Ù…Ù„ÙØ§Øª (Ù…ÙˆØ¬ÙˆØ¯ ÙˆØ´ØºØ§Ù„)
    uploaded_file = st.file_uploader("ğŸ“‚ Ø§Ø±ÙØ¹ Ù…Ù„Ù (ØµÙˆØ±Ø©/PDF):", type=["pdf", "csv", "txt", "jpg", "png", "jpeg"])
    
    st.divider()
    
    # Ø²Ø± ÙØ­Øµ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©
    st.subheader("ğŸ› ï¸ Ø§Ù„ØµÙŠØ§Ù†Ø©")
    if st.button("ğŸ” ÙØ­Øµ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù†Ø´Ø·Ø©"):
        try:
            models = [m.name for m in genai.list_models() if 'generateContent' in m.supported_generation_methods]
            st.info("Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ø§Ù„Ù…ØªØ§Ø­Ø©:")
            st.code("\n".join(models))
        except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")

# --- 3. Ù‚Ø³Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Ø§Ù„Ù…ØºØ±ÙÙˆÙ†) ÙÙŠ Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ---
st.title("ğŸ¤ Ù…Ù†ØµØ© Ø§Ù„ØªÙƒÙ„Ù… Ø§Ù„ØµÙˆØªÙŠ")
st.write("Ø§Ø³ØªØ®Ø¯Ù… **Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†** Ù„Ù„ØªØ­Ø¯Ø« Ù…Ø¨Ø§Ø´Ø±Ø© Ù…Ø¹ Ø§Ù„Ù†Ø¸Ø§Ù…:")

# Ø£Ø¯Ø§Ø© Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Ø§Ù„Ù…ØºØ±ÙÙˆÙ† ÙƒÙ…Ø§ ØªØ³Ù…ÙŠÙ‡)
audio_record = mic_recorder(
    start_prompt="ğŸ¤ Ø§Ø¶ØºØ· Ù‡Ù†Ø§ Ù„Ù„ØªÙƒÙ„Ù… (Ø§Ù„Ù…ØºØ±ÙÙˆÙ†)", 
    stop_prompt="ğŸ›‘ ØªÙˆÙ‚Ù ÙˆØ£Ø±Ø³Ù„", 
    just_once=True, 
    key='main_mic'
)

# --- 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª ---
if "messages" not in st.session_state: st.session_state.messages = []
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]): st.markdown(msg["content"])

prompt = st.chat_input("Ø£Ùˆ Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ù‡Ù†Ø§...")

# Ø§Ù„ØªØ­Ù‚Ù‚ Ù…Ù† ÙˆØ¬ÙˆØ¯ Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØªÙŠ Ø£Ùˆ Ù†ØµÙŠ Ø£Ùˆ Ù…Ù„Ù
if prompt or audio_record or uploaded_file:
    # Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ù†Ø§Ùƒ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠØŒ Ù†Ø­ØªØ§Ø¬ Ù„ØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ù†Øµ (Ø£Ùˆ Ø¥Ø±Ø³Ø§Ù„Ù‡ ÙƒÙ…Ù„Ù Ù„Ø¬ÙŠÙ…Ù†Ø§ÙŠ)
    user_txt = prompt if prompt else "ğŸ¤ [Ø¥Ø¯Ø®Ø§Ù„ ØµÙˆØªÙŠ Ù…Ù† Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ†]"
    
    st.session_state.messages.append({"role": "user", "content": user_txt})
    with st.chat_message("user"): st.markdown(user_txt)

    with st.chat_message("assistant"):
        try:
            model_map = {"Gemini 3 Pro": "models/gemini-3-pro-preview", "Gemini 2.5 Flash": "models/gemini-2.5-flash"}
            model = genai.GenerativeModel(model_map.get(engine_choice, "models/gemini-2.5-flash"))
            
            # Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØªØ¹Ù„ÙŠÙ…Ø§Øª Ù…Ø¹ Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªÙÙƒÙŠØ±
            full_prompt = f"Ø¨ØµÙØªÙƒ {persona} ÙˆØ¨Ù…Ø³ØªÙˆÙ‰ ØªÙÙƒÙŠØ± {thinking_level}: {user_txt}"
            
            content_parts = [full_prompt]
            if uploaded_file:
                if uploaded_file.type.startswith("image"):
                    content_parts.append(Image.open(uploaded_file))
                else:
                    content_parts.append(uploaded_file.read().decode())

            # Ø¥Ø°Ø§ ØªÙ… Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…ÙŠÙƒØ±ÙˆÙÙˆÙ† (Ø§Ù„Ù…ØºØ±ÙÙˆÙ†)
            if audio_record:
                # Ù‡Ù†Ø§ ÙŠÙ…ÙƒÙ† Ø¥Ø±Ø³Ø§Ù„ Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø© Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Gemini 2.5 Ø§Ù„ØªÙŠ ØªØ¯Ø¹Ù… Ø§Ù„ØµÙˆØª
                content_parts.append({"mime_type": "audio/wav", "data": audio_record['bytes']})

            response = model.generate_content(content_parts)
            st.markdown(response.text)
            
            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø¯ Ù„ØµÙˆØª Ù…Ø³Ù…ÙˆØ¹ (ØªÙƒÙ„Ù… Ø§Ù„Ù…Ù†ØµØ©)
            tts = gTTS(text=response.text[:300], lang='ar')
            audio_fp = io.BytesIO()
            tts.write_to_fp(audio_fp)
            st.audio(audio_fp, format='audio/mp3')
            
            st.session_state.messages.append({"role": "assistant", "content": response.text})
        except Exception as e: st.error(f"Ø®Ø·Ø£: {e}")
