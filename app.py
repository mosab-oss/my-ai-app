import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io
import re

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø© ÙˆØ§Ù„Ø¨ÙŠØ¦Ø©
st.set_page_config(page_title="Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„ V3", layout="wide", page_icon="ğŸŒ„")
load_dotenv()

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ø§ØªØµØ§Ù„ Ø¨Ù…ÙØªØ§Ø­ Ø§Ù„Ù€ API
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("âŒ Ø§Ù„Ù…ÙØªØ§Ø­ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯ ÙÙŠ Ù…Ù„Ù .env")
    st.stop()

genai.configure(api_key=api_key)

# 3. Ø¯Ø§Ù„Ø© Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø°ÙƒÙŠØ© (ØªØ¬Ø§ÙˆØ² Ø§Ù„Ø£Ø®Ø·Ø§Ø¡ ÙˆØ§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø§Ù„ØªÙ„Ù‚Ø§Ø¦ÙŠ)
def smart_generate(contents):
    # Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø¯Ø«Ø© Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø­Ø³Ø§Ø¨Ùƒ ÙÙŠ AI Studio Ù„ØªØ¬Ù†Ø¨ Ø®Ø·Ø£ 404
    models_to_try = [
        "gemini-3-flash-preview",  # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„ØªØ¬Ø±ÙŠØ¨ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯
        "gemini-2.0-flash-exp",    # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø¨Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø±ÙŠØ¹
        "gemini-1.5-flash"         # Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ Ø§Ù„Ø§Ø­ØªÙŠØ§Ø·ÙŠ Ø§Ù„Ù…Ø³ØªÙ‚Ø±
    ]
    
    for model_name in models_to_try:
        try:
            model = genai.GenerativeModel(model_name)
            response = model.generate_content(contents)
            return response.text, model_name
        except Exception as e:
            # ØªØ®Ø·ÙŠ Ø£Ø®Ø·Ø§Ø¡ Ø§Ù„Ø­ØµØ© (429) Ø£Ùˆ Ø¹Ø¯Ù… ÙˆØ¬ÙˆØ¯ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ (404)
            if "404" in str(e) or "429" in str(e) or "quota" in str(e).lower():
                continue 
            else:
                return f"âš ï¸ Ø®Ø·Ø£ ØªÙ‚Ù†ÙŠ: {e}", None
    return "ğŸš« Ø¹Ø°Ø±Ø§Ù‹ØŒ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª ØºÙŠØ± Ù…ØªØ§Ø­Ø© Ø­Ø§Ù„ÙŠØ§Ù‹.", None

# 4. Ø¯Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø±Ø¯ (Ù„ØªØ­ÙˆÙŠÙ„ Ø£ÙƒÙˆØ§Ø¯ JSON Ø¥Ù„Ù‰ Ù†ØµÙˆØµ Ù…ÙÙ‡ÙˆÙ…Ø©)
def clean_response(text):
    # Ø¥Ø°Ø§ Ø­Ø§ÙˆÙ„ Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„ ÙƒØªØ§Ø¨Ø© ÙƒÙˆØ¯ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©ØŒ Ù†Ø³ØªØ®Ø±Ø¬ Ø§Ù„ÙˆØµÙ ÙÙ‚Ø·
    if '"prompt":' in text:
        match = re.search(r'"prompt":\s*"([^"]+)"', text)
        if match:
            return f"ğŸ¨ **Ø·Ù„Ø¨ ØªÙˆÙ„ÙŠØ¯ ØµÙˆØ±Ø©:** {match.group(1)}"
    
    # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù†ØµÙˆØµ Ù…Ù† Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ø·ÙˆÙŠÙ„Ø© Ø£Ùˆ Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ù…Ø²Ø¹Ø¬Ø©
    clean_text = re.sub(r'\{.*?\}', '', text, flags=re.DOTALL)
    return clean_text if clean_text.strip() else text

# 5. Ø¯Ø§Ù„Ø© Ø§Ù„Ù†Ø·Ù‚ Ø§Ù„ØµÙˆØªÙŠ
def speak(text):
    try:
        clean_for_audio = re.sub(r'[*#_]', '', text[:250])
        tts = gTTS(text=clean_for_audio, lang='ar')
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except:
        return None

# 6. ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ (Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©)
with st.sidebar:
    st.header("ğŸ¨ Ø£Ø¯ÙˆØ§Øª Ø§Ù„ØªØ­ÙƒÙ…")
    st.subheader("ğŸ™ï¸ ØªØ³Ø¬ÙŠÙ„ ØµÙˆØªÙŠ")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« Ø§Ù„Ø¢Ù† ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    
    st.divider()
    st.subheader("ğŸ–¼ï¸ ØªØ­Ù„ÙŠÙ„ Ø§Ù„ØµÙˆØ±")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù†Ø­Ù„Ù„Ù‡Ø§:", type=["jpg", "png", "jpeg"])
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# 7. Ø§Ù„ÙˆØ§Ø¬Ù‡Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© ÙˆØ¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©
st.title("âš¡ Ù…Ø³Ø§Ø¹Ø¯ Ù…ØµØ¹Ø¨ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„")
st.info("ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ÙˆØ¯ÙŠÙ„Ø§Øª Ù„ØªØ¹Ù…Ù„ Ù…Ø¹ Gemini 3 Preview ÙˆÙ…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹.")

if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Ø§Ø³ØªÙ‚Ø¨Ø§Ù„ Ø§Ù„Ù…Ø¯Ø®Ù„Ø§Øª
user_input = st.chat_input("Ø§ÙƒØªØ¨ Ø³Ø¤Ø§Ù„Ùƒ Ø£Ùˆ Ø§Ø·Ù„Ø¨ ØµÙˆØ±Ø©...")
current_audio = audio_record['bytes'] if audio_record else None

if user_input or current_audio or uploaded_file:
    prompt = user_input if user_input else "Ø­Ù„Ù„ Ø§Ù„Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù…Ø±ÙÙ‚"
    
    with st.chat_message("user"):
        st.markdown(prompt)
        if uploaded_file: st.image(uploaded_file, width=300)

    with st.chat_message("assistant"):
        with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªÙÙƒÙŠØ± ÙˆØ§Ù„ØªØ¨Ø¯ÙŠÙ„ Ø¨ÙŠÙ† Ø§Ù„Ù…Ø­Ø±ÙƒØ§Øª..."):
            content_list = [prompt]
            if uploaded_file: content_list.append(Image.open(uploaded_file))
            if current_audio: content_list.append({"mime_type": "audio/wav", "data": current_audio})
            
            raw_answer, used_model = smart_generate(content_list)
            
            if used_model:
                # ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø±Ø¯ Ù…Ù† Ø§Ù„Ø£ÙƒÙˆØ§Ø¯ Ø§Ù„Ø¨Ø±Ù…Ø¬ÙŠØ© Ù‚Ø¨Ù„ Ø¹Ø±Ø¶Ù‡
                final_text = clean_response(raw_answer)
                
                st.markdown(final_text)
                st.caption(f"ğŸ¤– Ø§Ù„Ù…Ø­Ø±Ùƒ Ø§Ù„Ù†Ø´Ø·: {used_model}")
                
                # Ø§Ù„Ø±Ø¯ Ø§Ù„ØµÙˆØªÙŠ
                audio_fp = speak(final_text)
                if audio_fp: st.audio(audio_fp, autoplay=True)
                
                st.session_state.messages.append({"role": "assistant", "content": final_text})
            else:
                st.error(raw_answer)
