import streamlit as st
import google.generativeai as genai
import os
from dotenv import load_dotenv
from PIL import Image
from streamlit_mic_recorder import mic_recorder
from gtts import gTTS
import io

# 1. Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„ØµÙØ­Ø©
st.set_page_config(page_title="Ù…ØµØ¹Ø¨ AI - Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„Ù…ØªÙƒØ§Ù…Ù„", page_icon="ğŸš€", layout="wide")

# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù…ÙØ§ØªÙŠØ­
load_dotenv()
api_key = os.getenv("GEMINI_API_KEY")
if not api_key:
    st.error("ÙŠØ±Ø¬Ù‰ Ø¥Ø¶Ø§ÙØ© GEMINI_API_KEY ÙÙŠ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª.")
    st.stop()

genai.configure(api_key=api_key)

# 3. Ø¯Ø§Ù„Ø© Ø§Ù„ØµÙˆØª
def speak_text(text):
    try:
        clean_text = text.replace('*', '').replace('#', '')
        tts = gTTS(text=clean_text, lang='ar', slow=False)
        fp = io.BytesIO()
        tts.write_to_fp(fp)
        return fp
    except: return None

# 4. Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø¬Ø§Ù†Ø¨ÙŠØ©
with st.sidebar:
    st.title("âš™ï¸ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª ÙˆØ§Ù„ÙˆØ³Ø§Ø¦Ø·")
    persona = st.selectbox("Ø´Ø®ØµÙŠØ© Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:", ["Ù…Ø³Ø§Ø¹Ø¯ Ø¹Ø§Ù…", "Ø®Ø¨ÙŠØ± Ø¨Ø±Ù…Ø¬ÙŠØ§Øª", "Ù…Ø¯Ø±Ø³ Ù„ØºØ§Øª"])
    model_choice = st.radio("Ø§Ù„Ù…Ø­Ø±Ùƒ:", ["gemini-2.5-flash", "gemma-3-27b-it", "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen)"])
    
    st.divider()
    st.subheader("ğŸ–¼ï¸ Ø§Ù„Ø±Ø¤ÙŠØ© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ (Vision)")
    uploaded_file = st.file_uploader("Ø§Ø±ÙØ¹ ØµÙˆØ±Ø© Ù„Ù†Ø­Ù„Ù„Ù‡Ø§:", type=["jpg", "jpeg", "png"])
    
    st.divider()
    st.subheader("ğŸ™ï¸ Ø§Ù„Ø£ÙˆØ§Ù…Ø± Ø§Ù„ØµÙˆØªÙŠØ©")
    audio_record = mic_recorder(start_prompt="ØªØ­Ø¯Ø« ğŸ¤", stop_prompt="Ø¥Ø±Ø³Ø§Ù„ ğŸ“¤", key='recorder')
    
    if st.button("ğŸ—‘ï¸ Ù…Ø³Ø­ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
        st.session_state.messages = []
        st.rerun()

# 5. Ù…Ù†Ø·Ù‚ ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (ØªÙ… Ø¥ØµÙ„Ø§Ø­ Ø§Ù„Ø®Ø·Ø£ Ù‡Ù†Ø§)
if model_choice == "ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ± (Imagen)":
    st.header("ğŸ¨ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… Ø§Ù„Ø°ÙƒÙŠ")
    prompt = st.text_area("ØµÙ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© (Ù…Ø«Ø§Ù„: A futuristic city at sunset):")
    if st.button("Ø¥Ø¨Ø¯Ø£ Ø§Ù„Ø±Ø³Ù… ğŸ–Œï¸"):
        if prompt:
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„Ø±Ø³Ù…..."):
                try:
                    # Ø§Ù„Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø£ÙƒØ«Ø± Ø§Ø³ØªÙ‚Ø±Ø§Ø±Ø§Ù‹ Ù„ØªÙˆÙ„ÙŠØ¯ Ø§Ù„ØµÙˆØ±
                    model = genai.GenerativeModel('imagen-3.0-generate-001')
                    response = model.generate_content(prompt)
                    # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„ØµÙˆØ±Ø© Ù…Ù† Ø§Ù„Ø§Ø³ØªØ¬Ø§Ø¨Ø©
                    image_data = response.candidates[0].content.parts[0].inline_data.data
                    st.image(image_data, caption="ØªÙ… Ø§Ù„ØªÙˆÙ„ÙŠØ¯ Ø¨ÙˆØ§Ø³Ø·Ø© Ù…ØµØ¹Ø¨ AI")
                except Exception as e:
                    st.error(f"Ø¹Ø°Ø±Ø§Ù‹ØŒ Ù…Ø­Ø±Ùƒ Ø§Ù„Ø±Ø³Ù… ÙŠØ­ØªØ§Ø¬ Ù„ØµÙ„Ø§Ø­ÙŠØ§Øª Ø®Ø§ØµØ© ÙÙŠ Ø¨Ø¹Ø¶ Ø§Ù„Ø­Ø³Ø§Ø¨Ø§Øª. Ø§Ù„Ø®Ø·Ø£: {e}")
        else: st.warning("ÙŠØ±Ø¬Ù‰ ÙƒØªØ§Ø¨Ø© ÙˆØµÙ.")

# 6. Ù…Ù†Ø·Ù‚ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© Ø§Ù„Ø´Ø§Ù…Ù„ (Ø§Ù„Ø±Ø¤ÙŠØ© + Ø§Ù„ØµÙˆØª + Ø§Ù„Ù†Øµ)
else:
    st.header(f"ğŸ’¬ Ø§Ù„Ø¯Ø±Ø¯Ø´Ø© ÙˆØ§Ù„ØªØ­Ù„ÙŠÙ„ ({model_choice})")
    if "messages" not in st.session_state: st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]): st.markdown(msg["content"])

    user_input = st.chat_input("Ø§Ø³Ø£Ù„ Ø¹Ù† Ø§Ù„ØµÙˆØ±Ø© Ø£Ùˆ Ø§Ø·Ù„Ø¨ Ø­Ù„ ÙƒÙˆØ¯...")
    current_audio = audio_record['bytes'] if audio_record else None
    
    if user_input or current_audio or uploaded_file:
        query = user_input if user_input else ("Ø­Ù„Ù„ Ø§Ù„ØµÙˆØ±Ø©" if uploaded_file else "Ø­Ù„Ù„ Ø§Ù„ØµÙˆØª")
        
        st.session_state.messages.append({"role": "user", "content": query})
        with st.chat_message("user"):
            st.markdown(query)
            if uploaded_file: st.image(uploaded_file, width=300)
            if current_audio: st.audio(current_audio)

        with st.chat_message("assistant"):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ø§Ù„ØªØ­Ù„ÙŠÙ„ ÙˆØ§Ù„Ù†Ø·Ù‚..."):
                try:
                    model = genai.GenerativeModel(model_choice)
                    content_list = [f"ØªÙ‚Ù…Øµ Ø¯ÙˆØ± {persona}: {query}"]
                    if uploaded_file: content_list.append(Image.open(uploaded_file))
                    if current_audio: content_list.append({"mime_type": "audio/wav", "data": current_audio})
                    
                    response = model.generate_content(content_list)
                    st.markdown(response.text)
                    
                    audio_fp = speak_text(response.text)
                    if audio_fp: st.audio(audio_fp, format='audio/mp3', autoplay=True)
                    st.session_state.messages.append({"role": "assistant", "content": response_text})
                except Exception as e: st.error(f"Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")
